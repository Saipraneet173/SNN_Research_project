{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# Explicitly use CPU for now to verify it works\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Reduced hyperparameters\n",
        "batch_size = 32\n",
        "time_steps = 20\n",
        "input_size = 784\n",
        "hidden_size = 200  # Reduced significantly\n",
        "output_size = 10\n",
        "beta = 0.99\n",
        "theta = 1.0\n",
        "lr = 1e-4\n",
        "epochs = 15\n",
        "model_type = 'imsnn'  # 'imsnn' or 'snn'\n",
        "\n",
        "# For tracking metrics\n",
        "metrics = {\n",
        "    'epoch': [], 'train_loss': [], 'train_acc': [], 'test_acc': [],\n",
        "    'train_spikes': [], 'test_spikes': [], 'layer_spikes': []\n",
        "}\n",
        "\n",
        "# Data Loading - use a smaller subset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "# # Use a much smaller subset for testing\n",
        "# train_size = 5000  # Just 5000 samples\n",
        "# test_size = 1000   # Just 1000 samples\n",
        "# indices = list(range(len(train_dataset)))\n",
        "# test_indices = list(range(len(test_dataset)))\n",
        "# train_dataset = torch.utils.data.Subset(train_dataset, indices[:train_size])\n",
        "# test_dataset = torch.utils.data.Subset(test_dataset, test_indices[:test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "print(f\"Training on {len(train_dataset)} samples, testing on {len(test_dataset)} samples\")\n",
        "\n",
        "# Very simple Poisson Encoder\n",
        "def poisson_encoder(image, time_steps, fr_min=28.5, fr_max=100.0):\n",
        "    dt = 1e-3\n",
        "    rates = (fr_min + (fr_max - fr_min) * image) * dt\n",
        "    spikes = torch.rand(time_steps, *image.shape) < rates.unsqueeze(0)\n",
        "    return spikes.float()\n",
        "\n",
        "# Simplified Surrogate Gradient Function\n",
        "class SurrGradSpike(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return (input > theta).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad = grad_output * 0.3 * torch.exp(-0.5 * torch.abs(input - theta))\n",
        "        return grad\n",
        "\n",
        "spike_fn = SurrGradSpike.apply\n",
        "\n",
        "# Simple implementation of ISI Layer\n",
        "class ISILayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)  # Use standard linear layer internally\n",
        "        self.mu = nn.Parameter(torch.ones(output_size) * 12.0)  # Single mu per output neuron\n",
        "        self.sigma = nn.Parameter(torch.ones(output_size) * 4.0)  # Single sigma per output neuron\n",
        "\n",
        "    def forward(self, s_in, phi_prev):\n",
        "        # Regular linear transformation\n",
        "        output = self.linear(s_in)\n",
        "\n",
        "        # Calculate average ISI for each input\n",
        "        avg_phi = phi_prev.mean(dim=1, keepdim=True)\n",
        "\n",
        "        # Simple modulation\n",
        "        # Calculate Gaussian factor - one per output neuron\n",
        "        phi_factors = torch.exp(-2.0 * ((avg_phi - self.mu.unsqueeze(0)) / self.sigma.unsqueeze(0))**2)\n",
        "\n",
        "        # Modulate output\n",
        "        modulated_output = output * phi_factors\n",
        "\n",
        "        return modulated_output\n",
        "\n",
        "# LIF Neuron\n",
        "class LIFNeuron(nn.Module):\n",
        "    def __init__(self, layer_size):\n",
        "        super().__init__()\n",
        "        self.layer_size = layer_size\n",
        "        self.mem = None\n",
        "        self.phi = None\n",
        "\n",
        "    def reset_state(self, batch_size):\n",
        "        self.mem = torch.zeros(batch_size, self.layer_size)\n",
        "        self.phi = torch.zeros(batch_size, self.layer_size)\n",
        "\n",
        "    def forward(self, I):\n",
        "        self.mem = beta * self.mem + I\n",
        "        spikes = spike_fn(self.mem)\n",
        "        self.mem = self.mem * (1 - spikes)\n",
        "        self.phi = (1 + self.phi) * (1 - spikes)\n",
        "        return spikes\n",
        "\n",
        "# Neural Network Model\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, model_type='imsnn'):\n",
        "        super().__init__()\n",
        "        self.model_type = model_type\n",
        "\n",
        "        if model_type == 'imsnn':\n",
        "            self.fc1 = ISILayer(input_size, hidden_size)\n",
        "        else:\n",
        "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        self.lif1 = LIFNeuron(hidden_size)\n",
        "\n",
        "        if model_type == 'imsnn':\n",
        "            self.fc2 = ISILayer(hidden_size, output_size)\n",
        "        else:\n",
        "            self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(1)\n",
        "        self.lif1.reset_state(batch_size)\n",
        "\n",
        "        if self.model_type == 'imsnn':\n",
        "            input_phi = torch.zeros(batch_size, input_size)\n",
        "\n",
        "        outputs = []\n",
        "        spike_counts = 0\n",
        "\n",
        "        for t in range(x.size(0)):\n",
        "            s_in = x[t]\n",
        "\n",
        "            if self.model_type == 'imsnn':\n",
        "                input_phi = (1 + input_phi) * (1 - s_in)\n",
        "                I1 = self.fc1(s_in, input_phi)\n",
        "            else:\n",
        "                I1 = self.fc1(s_in)\n",
        "\n",
        "            s1 = self.lif1(I1)\n",
        "            spike_counts += s1.sum()\n",
        "\n",
        "            if self.model_type == 'imsnn':\n",
        "                I2 = self.fc2(s1, self.lif1.phi)\n",
        "            else:\n",
        "                I2 = self.fc2(s1)\n",
        "\n",
        "            outputs.append(I2)\n",
        "\n",
        "        avg_spikes_per_neuron = spike_counts / (batch_size * hidden_size * x.size(0))\n",
        "        return torch.stack(outputs).mean(dim=0), avg_spikes_per_neuron\n",
        "\n",
        "# Initialize Model and Optimizer\n",
        "print(f\"Creating {model_type} model...\")\n",
        "model = SNN(model_type).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "print(\"Model created successfully!\")\n",
        "\n",
        "# Training Loop\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "best_accuracy = 0\n",
        "\n",
        "try:\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        train_spikes = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Generate spikes\n",
        "            spikes = poisson_encoder(images, time_steps)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs, avg_spikes = model(spikes)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Add spike regularization\n",
        "            if model_type == 'imsnn':\n",
        "                loss += 0.2 * avg_spikes\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track metrics\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            train_spikes += avg_spikes.item()\n",
        "\n",
        "            # Print progress\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: Loss = {loss.item():.4f}, Acc = {100*correct/total:.2f}%, Spikes = {avg_spikes.item():.4f}\")\n",
        "\n",
        "        # Epoch stats\n",
        "        train_loss_avg = train_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "        train_spikes_avg = train_spikes / len(train_loader)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        test_spikes = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Generate spikes\n",
        "                spikes = poisson_encoder(images, time_steps)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs, avg_spikes = model(spikes)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Track metrics\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "                test_spikes += avg_spikes.item()\n",
        "\n",
        "        # Test stats\n",
        "        test_acc = 100 * correct / total\n",
        "        test_spikes_avg = test_spikes / len(test_loader)\n",
        "        test_loss_avg = test_loss / len(test_loader)\n",
        "\n",
        "        scheduler.step(test_loss_avg)\n",
        "\n",
        "        # Store metrics\n",
        "        metrics['epoch'].append(epoch + 1)\n",
        "        metrics['train_loss'].append(train_loss_avg)\n",
        "        metrics['train_acc'].append(train_acc)\n",
        "        metrics['test_acc'].append(test_acc)\n",
        "        metrics['train_spikes'].append(train_spikes_avg)\n",
        "        metrics['test_spikes'].append(test_spikes_avg)\n",
        "        metrics['layer_spikes'].append(test_spikes_avg)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"Train Loss: {train_loss_avg:.4f} | Train Acc: {train_acc:.2f}% | Train Spikes: {train_spikes_avg:.4f}\")\n",
        "        print(f\"Test Acc: {test_acc:.2f}% | Test Spikes: {test_spikes_avg:.4f}\")\n",
        "        print('-' * 60)\n",
        "\n",
        "        # Update best accuracy\n",
        "        if test_acc > best_accuracy:\n",
        "            best_accuracy = test_acc\n",
        "            best_epoch = epoch\n",
        "except Exception as e:\n",
        "    print(f\"Training error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Calculate total time and print final results\n",
        "total_time = time.time() - start_time\n",
        "print(f'\\nTraining completed in {total_time:.2f} seconds')\n",
        "\n",
        "if len(metrics['train_acc']) > 0:\n",
        "    print(f'Final train accuracy: {metrics[\"train_acc\"][-1]:.2f}%')\n",
        "    print(f'Final test accuracy: {metrics[\"test_acc\"][-1]:.2f}%')\n",
        "    print(f'Average spikes per neuron: {metrics[\"test_spikes\"][-1]:.4f}')\n",
        "    print(f'Best accuracy: {max(metrics[\"test_acc\"]):.2f}%')\n",
        "else:\n",
        "    print(\"No training completed.\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "if len(metrics['epoch']) > 0:\n",
        "    # Accuracy and loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['epoch'], metrics['train_acc'], 'b-', label='Train Accuracy')\n",
        "    plt.plot(metrics['epoch'], metrics['test_acc'], 'r-', label='Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Testing Accuracy')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Spike activity plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(metrics['epoch'], metrics['train_spikes'], 'g-', label='Train Spikes/Neuron')\n",
        "    plt.plot(metrics['epoch'], metrics['test_spikes'], 'm-', label='Test Spikes/Neuron')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Spikes per Neuron')\n",
        "    plt.legend()\n",
        "    plt.title('Spike Activity During Training')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{model_type}_results.png', dpi=300)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data to plot.\")\n",
        "\n",
        "# Save model if we have data\n",
        "if len(metrics['train_acc']) > 0:\n",
        "    try:\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'model_type': model_type\n",
        "        }, f'{model_type}_model.pth')\n",
        "        print(f\"Model saved to {model_type}_model.pth\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Y-vwJrAaFIt",
        "outputId": "6a2bbff5-2040-4a13-e23c-38b9c1be77e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "Using device: cpu\n",
            "Training on 60000 samples, testing on 10000 samples\n",
            "Creating imsnn model...\n",
            "Model created successfully!\n",
            "Starting training...\n",
            "Epoch 1, Batch 0: Loss = 2.3039, Acc = 6.25%, Spikes = 0.0001\n",
            "Epoch 1, Batch 10: Loss = 2.3028, Acc = 7.95%, Spikes = 0.0000\n",
            "Epoch 1, Batch 20: Loss = 2.3037, Acc = 9.08%, Spikes = 0.0000\n",
            "Epoch 1, Batch 30: Loss = 2.3039, Acc = 8.77%, Spikes = 0.0000\n",
            "Epoch 1, Batch 40: Loss = 2.3041, Acc = 8.84%, Spikes = 0.0000\n",
            "Epoch 1, Batch 50: Loss = 2.3012, Acc = 8.64%, Spikes = 0.0000\n",
            "Epoch 1, Batch 60: Loss = 2.3032, Acc = 8.76%, Spikes = 0.0000\n",
            "Epoch 1, Batch 70: Loss = 2.3003, Acc = 8.89%, Spikes = 0.0000\n",
            "Epoch 1, Batch 80: Loss = 2.2993, Acc = 9.07%, Spikes = 0.0000\n",
            "Epoch 1, Batch 90: Loss = 2.3057, Acc = 9.24%, Spikes = 0.0000\n",
            "Epoch 1, Batch 100: Loss = 2.3016, Acc = 9.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 110: Loss = 2.2999, Acc = 9.74%, Spikes = 0.0000\n",
            "Epoch 1, Batch 120: Loss = 2.3049, Acc = 9.61%, Spikes = 0.0000\n",
            "Epoch 1, Batch 130: Loss = 2.3049, Acc = 9.59%, Spikes = 0.0000\n",
            "Epoch 1, Batch 140: Loss = 2.3003, Acc = 9.69%, Spikes = 0.0000\n",
            "Epoch 1, Batch 150: Loss = 2.3039, Acc = 9.89%, Spikes = 0.0000\n",
            "Epoch 1, Batch 160: Loss = 2.3032, Acc = 9.92%, Spikes = 0.0000\n",
            "Epoch 1, Batch 170: Loss = 2.3036, Acc = 10.01%, Spikes = 0.0000\n",
            "Epoch 1, Batch 180: Loss = 2.3060, Acc = 9.96%, Spikes = 0.0000\n",
            "Epoch 1, Batch 190: Loss = 2.3033, Acc = 9.98%, Spikes = 0.0000\n",
            "Epoch 1, Batch 200: Loss = 2.3033, Acc = 9.95%, Spikes = 0.0000\n",
            "Epoch 1, Batch 210: Loss = 2.3026, Acc = 9.89%, Spikes = 0.0000\n",
            "Epoch 1, Batch 220: Loss = 2.3012, Acc = 9.90%, Spikes = 0.0000\n",
            "Epoch 1, Batch 230: Loss = 2.3022, Acc = 9.89%, Spikes = 0.0000\n",
            "Epoch 1, Batch 240: Loss = 2.2995, Acc = 9.89%, Spikes = 0.0000\n",
            "Epoch 1, Batch 250: Loss = 2.3018, Acc = 9.94%, Spikes = 0.0000\n",
            "Epoch 1, Batch 260: Loss = 2.3032, Acc = 9.95%, Spikes = 0.0000\n",
            "Epoch 1, Batch 270: Loss = 2.3044, Acc = 9.91%, Spikes = 0.0000\n",
            "Epoch 1, Batch 280: Loss = 2.3056, Acc = 9.93%, Spikes = 0.0000\n",
            "Epoch 1, Batch 290: Loss = 2.3039, Acc = 9.92%, Spikes = 0.0000\n",
            "Epoch 1, Batch 300: Loss = 2.3040, Acc = 9.90%, Spikes = 0.0000\n",
            "Epoch 1, Batch 310: Loss = 2.3026, Acc = 9.88%, Spikes = 0.0000\n",
            "Epoch 1, Batch 320: Loss = 2.3030, Acc = 9.94%, Spikes = 0.0000\n",
            "Epoch 1, Batch 330: Loss = 2.3033, Acc = 9.88%, Spikes = 0.0000\n",
            "Epoch 1, Batch 340: Loss = 2.3046, Acc = 9.84%, Spikes = 0.0000\n",
            "Epoch 1, Batch 350: Loss = 2.3042, Acc = 9.83%, Spikes = 0.0000\n",
            "Epoch 1, Batch 360: Loss = 2.3003, Acc = 9.93%, Spikes = 0.0000\n",
            "Epoch 1, Batch 370: Loss = 2.3023, Acc = 10.04%, Spikes = 0.0000\n",
            "Epoch 1, Batch 380: Loss = 2.3063, Acc = 10.06%, Spikes = 0.0000\n",
            "Epoch 1, Batch 390: Loss = 2.3044, Acc = 10.04%, Spikes = 0.0000\n",
            "Epoch 1, Batch 400: Loss = 2.3036, Acc = 10.02%, Spikes = 0.0000\n",
            "Epoch 1, Batch 410: Loss = 2.3038, Acc = 10.04%, Spikes = 0.0000\n",
            "Epoch 1, Batch 420: Loss = 2.3035, Acc = 10.01%, Spikes = 0.0000\n",
            "Epoch 1, Batch 430: Loss = 2.3034, Acc = 10.07%, Spikes = 0.0000\n",
            "Epoch 1, Batch 440: Loss = 2.3037, Acc = 10.05%, Spikes = 0.0000\n",
            "Epoch 1, Batch 450: Loss = 2.3029, Acc = 10.07%, Spikes = 0.0000\n",
            "Epoch 1, Batch 460: Loss = 2.3033, Acc = 10.08%, Spikes = 0.0000\n",
            "Epoch 1, Batch 470: Loss = 2.3017, Acc = 10.08%, Spikes = 0.0000\n",
            "Epoch 1, Batch 480: Loss = 2.3021, Acc = 10.04%, Spikes = 0.0000\n",
            "Epoch 1, Batch 490: Loss = 2.3044, Acc = 10.02%, Spikes = 0.0000\n",
            "Epoch 1, Batch 500: Loss = 2.3041, Acc = 10.07%, Spikes = 0.0000\n",
            "Epoch 1, Batch 510: Loss = 2.3024, Acc = 10.06%, Spikes = 0.0000\n",
            "Epoch 1, Batch 520: Loss = 2.3046, Acc = 10.11%, Spikes = 0.0000\n",
            "Epoch 1, Batch 530: Loss = 2.3038, Acc = 10.08%, Spikes = 0.0000\n",
            "Epoch 1, Batch 540: Loss = 2.3026, Acc = 10.07%, Spikes = 0.0000\n",
            "Epoch 1, Batch 550: Loss = 2.3033, Acc = 10.10%, Spikes = 0.0000\n",
            "Epoch 1, Batch 560: Loss = 2.2983, Acc = 10.12%, Spikes = 0.0000\n",
            "Epoch 1, Batch 570: Loss = 2.3028, Acc = 10.10%, Spikes = 0.0000\n",
            "Epoch 1, Batch 580: Loss = 2.3039, Acc = 10.06%, Spikes = 0.0000\n",
            "Epoch 1, Batch 590: Loss = 2.3007, Acc = 10.07%, Spikes = 0.0000\n",
            "Epoch 1, Batch 600: Loss = 2.3015, Acc = 10.10%, Spikes = 0.0000\n",
            "Epoch 1, Batch 610: Loss = 2.3022, Acc = 10.12%, Spikes = 0.0000\n",
            "Epoch 1, Batch 620: Loss = 2.3011, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 1, Batch 630: Loss = 2.3019, Acc = 10.21%, Spikes = 0.0000\n",
            "Epoch 1, Batch 640: Loss = 2.3014, Acc = 10.23%, Spikes = 0.0000\n",
            "Epoch 1, Batch 650: Loss = 2.3031, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 660: Loss = 2.3029, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 670: Loss = 2.2996, Acc = 10.21%, Spikes = 0.0000\n",
            "Epoch 1, Batch 680: Loss = 2.3025, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 1, Batch 690: Loss = 2.3038, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 1, Batch 700: Loss = 2.3029, Acc = 10.20%, Spikes = 0.0000\n",
            "Epoch 1, Batch 710: Loss = 2.3012, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 1, Batch 720: Loss = 2.3037, Acc = 10.20%, Spikes = 0.0000\n",
            "Epoch 1, Batch 730: Loss = 2.3082, Acc = 10.20%, Spikes = 0.0000\n",
            "Epoch 1, Batch 740: Loss = 2.3012, Acc = 10.20%, Spikes = 0.0000\n",
            "Epoch 1, Batch 750: Loss = 2.3048, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 1, Batch 760: Loss = 2.3046, Acc = 10.16%, Spikes = 0.0000\n",
            "Epoch 1, Batch 770: Loss = 2.3026, Acc = 10.15%, Spikes = 0.0000\n",
            "Epoch 1, Batch 780: Loss = 2.3006, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 1, Batch 790: Loss = 2.3022, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 1, Batch 800: Loss = 2.3056, Acc = 10.14%, Spikes = 0.0000\n",
            "Epoch 1, Batch 810: Loss = 2.3034, Acc = 10.16%, Spikes = 0.0000\n",
            "Epoch 1, Batch 820: Loss = 2.3023, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 1, Batch 830: Loss = 2.3021, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 1, Batch 840: Loss = 2.2998, Acc = 10.18%, Spikes = 0.0000\n",
            "Epoch 1, Batch 850: Loss = 2.3002, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 1, Batch 860: Loss = 2.3001, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 1, Batch 870: Loss = 2.3013, Acc = 10.18%, Spikes = 0.0000\n",
            "Epoch 1, Batch 880: Loss = 2.3016, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 1, Batch 890: Loss = 2.3045, Acc = 10.18%, Spikes = 0.0000\n",
            "Epoch 1, Batch 900: Loss = 2.3026, Acc = 10.21%, Spikes = 0.0000\n",
            "Epoch 1, Batch 910: Loss = 2.3019, Acc = 10.21%, Spikes = 0.0000\n",
            "Epoch 1, Batch 920: Loss = 2.3004, Acc = 10.24%, Spikes = 0.0000\n",
            "Epoch 1, Batch 930: Loss = 2.3046, Acc = 10.24%, Spikes = 0.0000\n",
            "Epoch 1, Batch 940: Loss = 2.3018, Acc = 10.24%, Spikes = 0.0000\n",
            "Epoch 1, Batch 950: Loss = 2.2996, Acc = 10.23%, Spikes = 0.0000\n",
            "Epoch 1, Batch 960: Loss = 2.3010, Acc = 10.25%, Spikes = 0.0000\n",
            "Epoch 1, Batch 970: Loss = 2.3003, Acc = 10.29%, Spikes = 0.0000\n",
            "Epoch 1, Batch 980: Loss = 2.3041, Acc = 10.27%, Spikes = 0.0000\n",
            "Epoch 1, Batch 990: Loss = 2.2986, Acc = 10.27%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1000: Loss = 2.3019, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1010: Loss = 2.3041, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1020: Loss = 2.3042, Acc = 10.25%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1030: Loss = 2.3005, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1040: Loss = 2.3047, Acc = 10.27%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1050: Loss = 2.3026, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1060: Loss = 2.3027, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1070: Loss = 2.3048, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1080: Loss = 2.3025, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1090: Loss = 2.3045, Acc = 10.29%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1100: Loss = 2.2992, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1110: Loss = 2.3037, Acc = 10.30%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1120: Loss = 2.3041, Acc = 10.29%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1130: Loss = 2.3010, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1140: Loss = 2.3024, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1150: Loss = 2.3028, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1160: Loss = 2.3003, Acc = 10.27%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1170: Loss = 2.3037, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1180: Loss = 2.2997, Acc = 10.27%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1190: Loss = 2.3059, Acc = 10.26%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1200: Loss = 2.3010, Acc = 10.24%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1210: Loss = 2.3006, Acc = 10.25%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1220: Loss = 2.3024, Acc = 10.27%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1230: Loss = 2.3021, Acc = 10.28%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1240: Loss = 2.3000, Acc = 10.30%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1250: Loss = 2.3027, Acc = 10.30%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1260: Loss = 2.3032, Acc = 10.30%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1270: Loss = 2.3020, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1280: Loss = 2.3034, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1290: Loss = 2.3026, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1300: Loss = 2.3049, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1310: Loss = 2.3038, Acc = 10.32%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1320: Loss = 2.3030, Acc = 10.29%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1330: Loss = 2.2991, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1340: Loss = 2.2984, Acc = 10.33%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1350: Loss = 2.3007, Acc = 10.33%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1360: Loss = 2.3005, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1370: Loss = 2.3076, Acc = 10.33%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1380: Loss = 2.3025, Acc = 10.32%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1390: Loss = 2.3039, Acc = 10.31%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1400: Loss = 2.3034, Acc = 10.33%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1410: Loss = 2.3016, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1420: Loss = 2.3050, Acc = 10.35%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1430: Loss = 2.3012, Acc = 10.35%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1440: Loss = 2.3026, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1450: Loss = 2.3029, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1460: Loss = 2.3000, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1470: Loss = 2.3038, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1480: Loss = 2.3010, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1490: Loss = 2.3027, Acc = 10.35%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1500: Loss = 2.3001, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1510: Loss = 2.3038, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1520: Loss = 2.3015, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1530: Loss = 2.3021, Acc = 10.35%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1540: Loss = 2.3040, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1550: Loss = 2.3014, Acc = 10.33%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1560: Loss = 2.3035, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1570: Loss = 2.3028, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1580: Loss = 2.3026, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1590: Loss = 2.3065, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1600: Loss = 2.3007, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1610: Loss = 2.3029, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1620: Loss = 2.3020, Acc = 10.38%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1630: Loss = 2.3017, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1640: Loss = 2.3040, Acc = 10.38%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1650: Loss = 2.3014, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1660: Loss = 2.3049, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1670: Loss = 2.3020, Acc = 10.35%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1680: Loss = 2.3045, Acc = 10.35%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1690: Loss = 2.3028, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1700: Loss = 2.3003, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1710: Loss = 2.3024, Acc = 10.38%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1720: Loss = 2.3004, Acc = 10.38%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1730: Loss = 2.3003, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1740: Loss = 2.3029, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1750: Loss = 2.2975, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1760: Loss = 2.3050, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1770: Loss = 2.3018, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1780: Loss = 2.3004, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1790: Loss = 2.2976, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1800: Loss = 2.3028, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1810: Loss = 2.3046, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1820: Loss = 2.3019, Acc = 10.41%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1830: Loss = 2.3029, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1840: Loss = 2.3058, Acc = 10.39%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1850: Loss = 2.3004, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1860: Loss = 2.2969, Acc = 10.43%, Spikes = 0.0000\n",
            "Epoch 1, Batch 1870: Loss = 2.2978, Acc = 10.44%, Spikes = 0.0000\n",
            "Epoch 1/15:\n",
            "Train Loss: 2.3024 | Train Acc: 10.44% | Train Spikes: 0.0000\n",
            "Test Acc: 10.28% | Test Spikes: 0.0000\n",
            "------------------------------------------------------------\n",
            "Epoch 2, Batch 0: Loss = 2.2976, Acc = 21.88%, Spikes = 0.0000\n",
            "Epoch 2, Batch 10: Loss = 2.3018, Acc = 11.08%, Spikes = 0.0000\n",
            "Epoch 2, Batch 20: Loss = 2.3012, Acc = 10.86%, Spikes = 0.0000\n",
            "Epoch 2, Batch 30: Loss = 2.3009, Acc = 10.99%, Spikes = 0.0000\n",
            "Epoch 2, Batch 40: Loss = 2.3017, Acc = 10.75%, Spikes = 0.0000\n",
            "Epoch 2, Batch 50: Loss = 2.3034, Acc = 10.17%, Spikes = 0.0000\n",
            "Epoch 2, Batch 60: Loss = 2.3038, Acc = 10.04%, Spikes = 0.0000\n",
            "Epoch 2, Batch 70: Loss = 2.2998, Acc = 9.73%, Spikes = 0.0000\n",
            "Epoch 2, Batch 80: Loss = 2.2986, Acc = 9.76%, Spikes = 0.0000\n",
            "Epoch 2, Batch 90: Loss = 2.3003, Acc = 9.79%, Spikes = 0.0000\n",
            "Epoch 2, Batch 100: Loss = 2.3014, Acc = 9.59%, Spikes = 0.0000\n",
            "Epoch 2, Batch 110: Loss = 2.3016, Acc = 9.49%, Spikes = 0.0000\n",
            "Epoch 2, Batch 120: Loss = 2.3033, Acc = 9.32%, Spikes = 0.0000\n",
            "Epoch 2, Batch 130: Loss = 2.3028, Acc = 9.42%, Spikes = 0.0000\n",
            "Epoch 2, Batch 140: Loss = 2.3007, Acc = 9.53%, Spikes = 0.0000\n",
            "Epoch 2, Batch 150: Loss = 2.3029, Acc = 9.56%, Spikes = 0.0000\n",
            "Epoch 2, Batch 160: Loss = 2.3011, Acc = 9.69%, Spikes = 0.0000\n",
            "Epoch 2, Batch 170: Loss = 2.3057, Acc = 9.85%, Spikes = 0.0000\n",
            "Epoch 2, Batch 180: Loss = 2.2997, Acc = 9.94%, Spikes = 0.0000\n",
            "Epoch 2, Batch 190: Loss = 2.3015, Acc = 9.82%, Spikes = 0.0000\n",
            "Epoch 2, Batch 200: Loss = 2.3023, Acc = 9.72%, Spikes = 0.0000\n",
            "Epoch 2, Batch 210: Loss = 2.3031, Acc = 9.77%, Spikes = 0.0000\n",
            "Epoch 2, Batch 220: Loss = 2.3046, Acc = 9.80%, Spikes = 0.0000\n",
            "Epoch 2, Batch 230: Loss = 2.2996, Acc = 9.98%, Spikes = 0.0000\n",
            "Epoch 2, Batch 240: Loss = 2.3011, Acc = 10.02%, Spikes = 0.0000\n",
            "Epoch 2, Batch 250: Loss = 2.3022, Acc = 10.11%, Spikes = 0.0000\n",
            "Epoch 2, Batch 260: Loss = 2.3026, Acc = 10.19%, Spikes = 0.0000\n",
            "Epoch 2, Batch 270: Loss = 2.2992, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 2, Batch 280: Loss = 2.3026, Acc = 10.34%, Spikes = 0.0000\n",
            "Epoch 2, Batch 290: Loss = 2.3026, Acc = 10.38%, Spikes = 0.0000\n",
            "Epoch 2, Batch 300: Loss = 2.2997, Acc = 10.48%, Spikes = 0.0000\n",
            "Epoch 2, Batch 310: Loss = 2.3005, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 2, Batch 320: Loss = 2.3028, Acc = 10.45%, Spikes = 0.0000\n",
            "Epoch 2, Batch 330: Loss = 2.3033, Acc = 10.52%, Spikes = 0.0000\n",
            "Epoch 2, Batch 340: Loss = 2.3012, Acc = 10.50%, Spikes = 0.0000\n",
            "Epoch 2, Batch 350: Loss = 2.3017, Acc = 10.51%, Spikes = 0.0000\n",
            "Epoch 2, Batch 360: Loss = 2.3024, Acc = 10.58%, Spikes = 0.0000\n",
            "Epoch 2, Batch 370: Loss = 2.2982, Acc = 10.61%, Spikes = 0.0000\n",
            "Epoch 2, Batch 380: Loss = 2.3029, Acc = 10.56%, Spikes = 0.0000\n",
            "Epoch 2, Batch 390: Loss = 2.3039, Acc = 10.56%, Spikes = 0.0000\n",
            "Epoch 2, Batch 400: Loss = 2.3043, Acc = 10.50%, Spikes = 0.0000\n",
            "Epoch 2, Batch 410: Loss = 2.3005, Acc = 10.50%, Spikes = 0.0000\n",
            "Epoch 2, Batch 420: Loss = 2.3046, Acc = 10.47%, Spikes = 0.0000\n",
            "Epoch 2, Batch 430: Loss = 2.3045, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 2, Batch 440: Loss = 2.3048, Acc = 10.39%, Spikes = 0.0000\n",
            "Epoch 2, Batch 450: Loss = 2.3041, Acc = 10.43%, Spikes = 0.0000\n",
            "Epoch 2, Batch 460: Loss = 2.2990, Acc = 10.48%, Spikes = 0.0000\n",
            "Epoch 2, Batch 470: Loss = 2.3035, Acc = 10.53%, Spikes = 0.0000\n",
            "Epoch 2, Batch 480: Loss = 2.3033, Acc = 10.52%, Spikes = 0.0000\n",
            "Epoch 2, Batch 490: Loss = 2.2998, Acc = 10.51%, Spikes = 0.0000\n",
            "Epoch 2, Batch 500: Loss = 2.3028, Acc = 10.52%, Spikes = 0.0000\n",
            "Epoch 2, Batch 510: Loss = 2.3052, Acc = 10.54%, Spikes = 0.0000\n",
            "Epoch 2, Batch 520: Loss = 2.2986, Acc = 10.58%, Spikes = 0.0000\n",
            "Epoch 2, Batch 530: Loss = 2.2992, Acc = 10.55%, Spikes = 0.0000\n",
            "Epoch 2, Batch 540: Loss = 2.3005, Acc = 10.56%, Spikes = 0.0000\n",
            "Epoch 2, Batch 550: Loss = 2.3031, Acc = 10.50%, Spikes = 0.0000\n",
            "Epoch 2, Batch 560: Loss = 2.3014, Acc = 10.50%, Spikes = 0.0000\n",
            "Epoch 2, Batch 570: Loss = 2.3016, Acc = 10.49%, Spikes = 0.0000\n",
            "Epoch 2, Batch 580: Loss = 2.3022, Acc = 10.56%, Spikes = 0.0000\n",
            "Epoch 2, Batch 590: Loss = 2.3025, Acc = 10.54%, Spikes = 0.0000\n",
            "Epoch 2, Batch 600: Loss = 2.2982, Acc = 10.55%, Spikes = 0.0000\n",
            "Epoch 2, Batch 610: Loss = 2.3035, Acc = 10.52%, Spikes = 0.0000\n",
            "Epoch 2, Batch 620: Loss = 2.3014, Acc = 10.51%, Spikes = 0.0000\n",
            "Epoch 2, Batch 630: Loss = 2.3042, Acc = 10.51%, Spikes = 0.0000\n",
            "Epoch 2, Batch 640: Loss = 2.3062, Acc = 10.49%, Spikes = 0.0000\n",
            "Epoch 2, Batch 650: Loss = 2.3002, Acc = 10.48%, Spikes = 0.0000\n",
            "Epoch 2, Batch 660: Loss = 2.2997, Acc = 10.45%, Spikes = 0.0000\n",
            "Epoch 2, Batch 670: Loss = 2.2994, Acc = 10.43%, Spikes = 0.0000\n",
            "Epoch 2, Batch 680: Loss = 2.3022, Acc = 10.41%, Spikes = 0.0000\n",
            "Epoch 2, Batch 690: Loss = 2.3010, Acc = 10.45%, Spikes = 0.0000\n",
            "Epoch 2, Batch 700: Loss = 2.3023, Acc = 10.46%, Spikes = 0.0000\n",
            "Epoch 2, Batch 710: Loss = 2.3004, Acc = 10.43%, Spikes = 0.0000\n",
            "Epoch 2, Batch 720: Loss = 2.3036, Acc = 10.41%, Spikes = 0.0000\n",
            "Epoch 2, Batch 730: Loss = 2.3004, Acc = 10.41%, Spikes = 0.0000\n",
            "Epoch 2, Batch 740: Loss = 2.3035, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 2, Batch 750: Loss = 2.2994, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 2, Batch 760: Loss = 2.3024, Acc = 10.37%, Spikes = 0.0000\n",
            "Epoch 2, Batch 770: Loss = 2.3011, Acc = 10.36%, Spikes = 0.0000\n",
            "Epoch 2, Batch 780: Loss = 2.3054, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 2, Batch 790: Loss = 2.3045, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 2, Batch 800: Loss = 2.3033, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 2, Batch 810: Loss = 2.3080, Acc = 10.40%, Spikes = 0.0000\n",
            "Epoch 2, Batch 820: Loss = 2.3037, Acc = 10.41%, Spikes = 0.0000\n",
            "Epoch 2, Batch 830: Loss = 2.3015, Acc = 10.42%, Spikes = 0.0000\n",
            "Epoch 2, Batch 840: Loss = 2.2998, Acc = 10.45%, Spikes = 0.0001\n",
            "Epoch 2, Batch 850: Loss = 2.2982, Acc = 10.45%, Spikes = 0.0001\n",
            "Epoch 2, Batch 860: Loss = 2.2993, Acc = 10.48%, Spikes = 0.0002\n",
            "Epoch 2, Batch 870: Loss = 2.3045, Acc = 10.47%, Spikes = 0.0001\n",
            "Epoch 2, Batch 880: Loss = 2.3016, Acc = 10.43%, Spikes = 0.0002\n",
            "Epoch 2, Batch 890: Loss = 2.3005, Acc = 10.41%, Spikes = 0.0001\n",
            "Epoch 2, Batch 900: Loss = 2.3060, Acc = 10.40%, Spikes = 0.0001\n",
            "Epoch 2, Batch 910: Loss = 2.2992, Acc = 10.39%, Spikes = 0.0003\n",
            "Epoch 2, Batch 920: Loss = 2.2996, Acc = 10.42%, Spikes = 0.0002\n",
            "Epoch 2, Batch 930: Loss = 2.3026, Acc = 10.43%, Spikes = 0.0002\n",
            "Epoch 2, Batch 940: Loss = 2.3016, Acc = 10.45%, Spikes = 0.0003\n",
            "Epoch 2, Batch 950: Loss = 2.3055, Acc = 10.44%, Spikes = 0.0002\n",
            "Epoch 2, Batch 960: Loss = 2.3053, Acc = 10.42%, Spikes = 0.0001\n",
            "Epoch 2, Batch 970: Loss = 2.3053, Acc = 10.45%, Spikes = 0.0002\n",
            "Epoch 2, Batch 980: Loss = 2.2971, Acc = 10.45%, Spikes = 0.0005\n",
            "Epoch 2, Batch 990: Loss = 2.2995, Acc = 10.46%, Spikes = 0.0005\n",
            "Epoch 2, Batch 1000: Loss = 2.3011, Acc = 10.47%, Spikes = 0.0004\n",
            "Epoch 2, Batch 1010: Loss = 2.2997, Acc = 10.48%, Spikes = 0.0004\n",
            "Epoch 2, Batch 1020: Loss = 2.2995, Acc = 10.47%, Spikes = 0.0006\n",
            "Epoch 2, Batch 1030: Loss = 2.2972, Acc = 10.49%, Spikes = 0.0005\n",
            "Epoch 2, Batch 1040: Loss = 2.2963, Acc = 10.54%, Spikes = 0.0006\n",
            "Epoch 2, Batch 1050: Loss = 2.3032, Acc = 10.54%, Spikes = 0.0005\n",
            "Epoch 2, Batch 1060: Loss = 2.2992, Acc = 10.56%, Spikes = 0.0006\n",
            "Epoch 2, Batch 1070: Loss = 2.2998, Acc = 10.56%, Spikes = 0.0006\n",
            "Epoch 2, Batch 1080: Loss = 2.2962, Acc = 10.61%, Spikes = 0.0007\n",
            "Epoch 2, Batch 1090: Loss = 2.2937, Acc = 10.62%, Spikes = 0.0011\n",
            "Epoch 2, Batch 1100: Loss = 2.2968, Acc = 10.65%, Spikes = 0.0008\n",
            "Epoch 2, Batch 1110: Loss = 2.3044, Acc = 10.64%, Spikes = 0.0006\n",
            "Epoch 2, Batch 1120: Loss = 2.2924, Acc = 10.69%, Spikes = 0.0013\n",
            "Epoch 2, Batch 1130: Loss = 2.2950, Acc = 10.76%, Spikes = 0.0009\n",
            "Epoch 2, Batch 1140: Loss = 2.2946, Acc = 10.83%, Spikes = 0.0012\n",
            "Epoch 2, Batch 1150: Loss = 2.2932, Acc = 10.87%, Spikes = 0.0014\n",
            "Epoch 2, Batch 1160: Loss = 2.3026, Acc = 10.94%, Spikes = 0.0011\n",
            "Epoch 2, Batch 1170: Loss = 2.2962, Acc = 10.97%, Spikes = 0.0012\n",
            "Epoch 2, Batch 1180: Loss = 2.2934, Acc = 11.02%, Spikes = 0.0013\n",
            "Epoch 2, Batch 1190: Loss = 2.2912, Acc = 11.10%, Spikes = 0.0018\n",
            "Epoch 2, Batch 1200: Loss = 2.2837, Acc = 11.18%, Spikes = 0.0024\n",
            "Epoch 2, Batch 1210: Loss = 2.2810, Acc = 11.25%, Spikes = 0.0029\n",
            "Epoch 2, Batch 1220: Loss = 2.2896, Acc = 11.33%, Spikes = 0.0028\n",
            "Epoch 2, Batch 1230: Loss = 2.2785, Acc = 11.38%, Spikes = 0.0028\n",
            "Epoch 2, Batch 1240: Loss = 2.2748, Acc = 11.43%, Spikes = 0.0038\n",
            "Epoch 2, Batch 1250: Loss = 2.2644, Acc = 11.51%, Spikes = 0.0043\n",
            "Epoch 2, Batch 1260: Loss = 2.2855, Acc = 11.57%, Spikes = 0.0052\n",
            "Epoch 2, Batch 1270: Loss = 2.2486, Acc = 11.63%, Spikes = 0.0081\n",
            "Epoch 2, Batch 1280: Loss = 2.2261, Acc = 11.68%, Spikes = 0.0096\n",
            "Epoch 2, Batch 1290: Loss = 2.2373, Acc = 11.75%, Spikes = 0.0109\n",
            "Epoch 2, Batch 1300: Loss = 2.2390, Acc = 11.81%, Spikes = 0.0161\n",
            "Epoch 2, Batch 1310: Loss = 2.2045, Acc = 11.87%, Spikes = 0.0190\n",
            "Epoch 2, Batch 1320: Loss = 2.1536, Acc = 11.96%, Spikes = 0.0236\n",
            "Epoch 2, Batch 1330: Loss = 2.1354, Acc = 12.09%, Spikes = 0.0248\n",
            "Epoch 2, Batch 1340: Loss = 2.1526, Acc = 12.20%, Spikes = 0.0215\n",
            "Epoch 2, Batch 1350: Loss = 2.1435, Acc = 12.30%, Spikes = 0.0229\n",
            "Epoch 2, Batch 1360: Loss = 2.1041, Acc = 12.41%, Spikes = 0.0234\n",
            "Epoch 2, Batch 1370: Loss = 2.1724, Acc = 12.54%, Spikes = 0.0219\n",
            "Epoch 2, Batch 1380: Loss = 2.1130, Acc = 12.71%, Spikes = 0.0228\n",
            "Epoch 2, Batch 1390: Loss = 2.0510, Acc = 12.86%, Spikes = 0.0259\n",
            "Epoch 2, Batch 1400: Loss = 2.0635, Acc = 13.03%, Spikes = 0.0253\n",
            "Epoch 2, Batch 1410: Loss = 2.0829, Acc = 13.21%, Spikes = 0.0244\n",
            "Epoch 2, Batch 1420: Loss = 2.1223, Acc = 13.39%, Spikes = 0.0243\n",
            "Epoch 2, Batch 1430: Loss = 2.0189, Acc = 13.60%, Spikes = 0.0272\n",
            "Epoch 2, Batch 1440: Loss = 2.1208, Acc = 13.80%, Spikes = 0.0227\n",
            "Epoch 2, Batch 1450: Loss = 2.1087, Acc = 14.05%, Spikes = 0.0240\n",
            "Epoch 2, Batch 1460: Loss = 2.0894, Acc = 14.25%, Spikes = 0.0246\n",
            "Epoch 2, Batch 1470: Loss = 2.0302, Acc = 14.50%, Spikes = 0.0251\n",
            "Epoch 2, Batch 1480: Loss = 1.9847, Acc = 14.76%, Spikes = 0.0273\n",
            "Epoch 2, Batch 1490: Loss = 2.0190, Acc = 15.00%, Spikes = 0.0265\n",
            "Epoch 2, Batch 1500: Loss = 2.0016, Acc = 15.25%, Spikes = 0.0265\n",
            "Epoch 2, Batch 1510: Loss = 1.9943, Acc = 15.51%, Spikes = 0.0251\n",
            "Epoch 2, Batch 1520: Loss = 1.9350, Acc = 15.78%, Spikes = 0.0268\n",
            "Epoch 2, Batch 1530: Loss = 1.9606, Acc = 16.03%, Spikes = 0.0265\n",
            "Epoch 2, Batch 1540: Loss = 2.0094, Acc = 16.27%, Spikes = 0.0241\n",
            "Epoch 2, Batch 1550: Loss = 2.0257, Acc = 16.49%, Spikes = 0.0236\n",
            "Epoch 2, Batch 1560: Loss = 1.9927, Acc = 16.71%, Spikes = 0.0252\n",
            "Epoch 2, Batch 1570: Loss = 2.0023, Acc = 16.93%, Spikes = 0.0253\n",
            "Epoch 2, Batch 1580: Loss = 1.9653, Acc = 17.12%, Spikes = 0.0250\n",
            "Epoch 2, Batch 1590: Loss = 2.0119, Acc = 17.34%, Spikes = 0.0254\n",
            "Epoch 2, Batch 1600: Loss = 1.9755, Acc = 17.53%, Spikes = 0.0265\n",
            "Epoch 2, Batch 1610: Loss = 2.0137, Acc = 17.74%, Spikes = 0.0259\n",
            "Epoch 2, Batch 1620: Loss = 1.9485, Acc = 17.95%, Spikes = 0.0252\n",
            "Epoch 2, Batch 1630: Loss = 1.9518, Acc = 18.17%, Spikes = 0.0259\n",
            "Epoch 2, Batch 1640: Loss = 2.0068, Acc = 18.38%, Spikes = 0.0231\n",
            "Epoch 2, Batch 1650: Loss = 2.0273, Acc = 18.59%, Spikes = 0.0234\n",
            "Epoch 2, Batch 1660: Loss = 1.9894, Acc = 18.81%, Spikes = 0.0248\n",
            "Epoch 2, Batch 1670: Loss = 1.9537, Acc = 19.04%, Spikes = 0.0259\n",
            "Epoch 2, Batch 1680: Loss = 1.8655, Acc = 19.25%, Spikes = 0.0270\n",
            "Epoch 2, Batch 1690: Loss = 1.9816, Acc = 19.47%, Spikes = 0.0250\n",
            "Epoch 2, Batch 1700: Loss = 1.9274, Acc = 19.67%, Spikes = 0.0264\n",
            "Epoch 2, Batch 1710: Loss = 1.9618, Acc = 19.88%, Spikes = 0.0260\n",
            "Epoch 2, Batch 1720: Loss = 1.9253, Acc = 20.08%, Spikes = 0.0254\n",
            "Epoch 2, Batch 1730: Loss = 1.9568, Acc = 20.31%, Spikes = 0.0261\n",
            "Epoch 2, Batch 1740: Loss = 2.0356, Acc = 20.53%, Spikes = 0.0215\n",
            "Epoch 2, Batch 1750: Loss = 1.8878, Acc = 20.73%, Spikes = 0.0266\n",
            "Epoch 2, Batch 1760: Loss = 1.8937, Acc = 20.94%, Spikes = 0.0255\n",
            "Epoch 2, Batch 1770: Loss = 1.8158, Acc = 21.14%, Spikes = 0.0294\n",
            "Epoch 2, Batch 1780: Loss = 1.8860, Acc = 21.34%, Spikes = 0.0263\n",
            "Epoch 2, Batch 1790: Loss = 1.8919, Acc = 21.54%, Spikes = 0.0252\n",
            "Epoch 2, Batch 1800: Loss = 1.9410, Acc = 21.76%, Spikes = 0.0280\n",
            "Epoch 2, Batch 1810: Loss = 1.8046, Acc = 21.96%, Spikes = 0.0267\n",
            "Epoch 2, Batch 1820: Loss = 1.9346, Acc = 22.14%, Spikes = 0.0267\n",
            "Epoch 2, Batch 1830: Loss = 1.7336, Acc = 22.31%, Spikes = 0.0292\n",
            "Epoch 2, Batch 1840: Loss = 1.8428, Acc = 22.48%, Spikes = 0.0281\n",
            "Epoch 2, Batch 1850: Loss = 1.8694, Acc = 22.65%, Spikes = 0.0265\n",
            "Epoch 2, Batch 1860: Loss = 1.9060, Acc = 22.83%, Spikes = 0.0278\n",
            "Epoch 2, Batch 1870: Loss = 1.8563, Acc = 23.00%, Spikes = 0.0263\n",
            "Epoch 2/15:\n",
            "Train Loss: 2.2074 | Train Acc: 23.07% | Train Spikes: 0.0081\n",
            "Test Acc: 56.07% | Test Spikes: 0.0268\n",
            "------------------------------------------------------------\n",
            "Epoch 3, Batch 0: Loss = 1.9137, Acc = 46.88%, Spikes = 0.0265\n",
            "Epoch 3, Batch 10: Loss = 1.7633, Acc = 56.82%, Spikes = 0.0296\n",
            "Epoch 3, Batch 20: Loss = 1.9453, Acc = 55.21%, Spikes = 0.0287\n",
            "Epoch 3, Batch 30: Loss = 1.8695, Acc = 54.23%, Spikes = 0.0254\n",
            "Epoch 3, Batch 40: Loss = 1.8210, Acc = 54.34%, Spikes = 0.0265\n",
            "Epoch 3, Batch 50: Loss = 1.9528, Acc = 55.02%, Spikes = 0.0253\n",
            "Epoch 3, Batch 60: Loss = 1.8564, Acc = 54.56%, Spikes = 0.0270\n",
            "Epoch 3, Batch 70: Loss = 1.8467, Acc = 54.80%, Spikes = 0.0257\n",
            "Epoch 3, Batch 80: Loss = 1.8238, Acc = 54.48%, Spikes = 0.0279\n",
            "Epoch 3, Batch 90: Loss = 1.8514, Acc = 55.05%, Spikes = 0.0249\n",
            "Epoch 3, Batch 100: Loss = 1.7351, Acc = 55.32%, Spikes = 0.0288\n",
            "Epoch 3, Batch 110: Loss = 1.9223, Acc = 55.26%, Spikes = 0.0258\n",
            "Epoch 3, Batch 120: Loss = 1.7614, Acc = 55.22%, Spikes = 0.0264\n",
            "Epoch 3, Batch 130: Loss = 1.8997, Acc = 55.20%, Spikes = 0.0275\n",
            "Epoch 3, Batch 140: Loss = 1.7434, Acc = 55.36%, Spikes = 0.0282\n",
            "Epoch 3, Batch 150: Loss = 1.8784, Acc = 55.46%, Spikes = 0.0257\n",
            "Epoch 3, Batch 160: Loss = 1.7830, Acc = 55.53%, Spikes = 0.0266\n",
            "Epoch 3, Batch 170: Loss = 1.7967, Acc = 55.57%, Spikes = 0.0253\n",
            "Epoch 3, Batch 180: Loss = 1.8628, Acc = 55.28%, Spikes = 0.0254\n",
            "Epoch 3, Batch 190: Loss = 1.8446, Acc = 55.12%, Spikes = 0.0299\n",
            "Epoch 3, Batch 200: Loss = 1.7290, Acc = 55.02%, Spikes = 0.0276\n",
            "Epoch 3, Batch 210: Loss = 1.6979, Acc = 54.95%, Spikes = 0.0301\n",
            "Epoch 3, Batch 220: Loss = 1.8522, Acc = 55.22%, Spikes = 0.0258\n",
            "Epoch 3, Batch 230: Loss = 1.7391, Acc = 55.37%, Spikes = 0.0268\n",
            "Epoch 3, Batch 240: Loss = 1.8887, Acc = 55.43%, Spikes = 0.0263\n",
            "Epoch 3, Batch 250: Loss = 1.8410, Acc = 55.55%, Spikes = 0.0271\n",
            "Epoch 3, Batch 260: Loss = 1.9392, Acc = 55.53%, Spikes = 0.0249\n",
            "Epoch 3, Batch 270: Loss = 1.7017, Acc = 55.52%, Spikes = 0.0299\n",
            "Epoch 3, Batch 280: Loss = 1.7774, Acc = 55.57%, Spikes = 0.0269\n",
            "Epoch 3, Batch 290: Loss = 1.6627, Acc = 55.61%, Spikes = 0.0291\n",
            "Epoch 3, Batch 300: Loss = 1.8290, Acc = 55.55%, Spikes = 0.0260\n",
            "Epoch 3, Batch 310: Loss = 1.9395, Acc = 55.67%, Spikes = 0.0264\n",
            "Epoch 3, Batch 320: Loss = 1.7805, Acc = 55.63%, Spikes = 0.0271\n",
            "Epoch 3, Batch 330: Loss = 1.8074, Acc = 55.72%, Spikes = 0.0249\n",
            "Epoch 3, Batch 340: Loss = 1.7292, Acc = 55.74%, Spikes = 0.0313\n",
            "Epoch 3, Batch 350: Loss = 1.6099, Acc = 55.81%, Spikes = 0.0272\n",
            "Epoch 3, Batch 360: Loss = 1.6644, Acc = 55.99%, Spikes = 0.0273\n",
            "Epoch 3, Batch 370: Loss = 1.9625, Acc = 55.88%, Spikes = 0.0248\n",
            "Epoch 3, Batch 380: Loss = 1.8297, Acc = 55.86%, Spikes = 0.0265\n",
            "Epoch 3, Batch 390: Loss = 1.8063, Acc = 55.83%, Spikes = 0.0261\n",
            "Epoch 3, Batch 400: Loss = 1.8375, Acc = 55.88%, Spikes = 0.0281\n",
            "Epoch 3, Batch 410: Loss = 1.6836, Acc = 55.96%, Spikes = 0.0299\n",
            "Epoch 3, Batch 420: Loss = 1.7906, Acc = 55.84%, Spikes = 0.0282\n",
            "Epoch 3, Batch 430: Loss = 1.7840, Acc = 55.84%, Spikes = 0.0273\n",
            "Epoch 3, Batch 440: Loss = 1.7829, Acc = 55.83%, Spikes = 0.0259\n",
            "Epoch 3, Batch 450: Loss = 1.7593, Acc = 55.89%, Spikes = 0.0256\n",
            "Epoch 3, Batch 460: Loss = 1.7769, Acc = 55.88%, Spikes = 0.0253\n",
            "Epoch 3, Batch 470: Loss = 1.8117, Acc = 55.82%, Spikes = 0.0247\n",
            "Epoch 3, Batch 480: Loss = 1.8096, Acc = 55.85%, Spikes = 0.0250\n",
            "Epoch 3, Batch 490: Loss = 1.8206, Acc = 55.89%, Spikes = 0.0256\n",
            "Epoch 3, Batch 500: Loss = 1.6738, Acc = 55.87%, Spikes = 0.0300\n",
            "Epoch 3, Batch 510: Loss = 1.7718, Acc = 55.90%, Spikes = 0.0269\n",
            "Epoch 3, Batch 520: Loss = 1.7554, Acc = 55.82%, Spikes = 0.0270\n",
            "Epoch 3, Batch 530: Loss = 1.9217, Acc = 55.86%, Spikes = 0.0261\n",
            "Epoch 3, Batch 540: Loss = 1.7228, Acc = 55.93%, Spikes = 0.0269\n",
            "Epoch 3, Batch 550: Loss = 1.8185, Acc = 55.95%, Spikes = 0.0284\n",
            "Epoch 3, Batch 560: Loss = 1.6411, Acc = 56.06%, Spikes = 0.0287\n",
            "Epoch 3, Batch 570: Loss = 1.7754, Acc = 56.07%, Spikes = 0.0253\n",
            "Epoch 3, Batch 580: Loss = 1.7261, Acc = 56.11%, Spikes = 0.0282\n",
            "Epoch 3, Batch 590: Loss = 1.6363, Acc = 56.12%, Spikes = 0.0292\n",
            "Epoch 3, Batch 600: Loss = 1.7279, Acc = 56.14%, Spikes = 0.0266\n",
            "Epoch 3, Batch 610: Loss = 1.8093, Acc = 56.21%, Spikes = 0.0266\n",
            "Epoch 3, Batch 620: Loss = 1.5336, Acc = 56.27%, Spikes = 0.0335\n",
            "Epoch 3, Batch 630: Loss = 1.7005, Acc = 56.29%, Spikes = 0.0292\n",
            "Epoch 3, Batch 640: Loss = 1.7575, Acc = 56.30%, Spikes = 0.0282\n",
            "Epoch 3, Batch 650: Loss = 1.5907, Acc = 56.32%, Spikes = 0.0294\n",
            "Epoch 3, Batch 660: Loss = 1.7488, Acc = 56.35%, Spikes = 0.0281\n",
            "Epoch 3, Batch 670: Loss = 1.6726, Acc = 56.36%, Spikes = 0.0292\n",
            "Epoch 3, Batch 680: Loss = 1.6237, Acc = 56.47%, Spikes = 0.0318\n",
            "Epoch 3, Batch 690: Loss = 1.7247, Acc = 56.48%, Spikes = 0.0279\n",
            "Epoch 3, Batch 700: Loss = 1.6960, Acc = 56.46%, Spikes = 0.0264\n",
            "Epoch 3, Batch 710: Loss = 1.6896, Acc = 56.55%, Spikes = 0.0277\n",
            "Epoch 3, Batch 720: Loss = 1.6157, Acc = 56.55%, Spikes = 0.0291\n",
            "Epoch 3, Batch 730: Loss = 1.7770, Acc = 56.57%, Spikes = 0.0255\n",
            "Epoch 3, Batch 740: Loss = 1.5720, Acc = 56.67%, Spikes = 0.0298\n",
            "Epoch 3, Batch 750: Loss = 1.5518, Acc = 56.74%, Spikes = 0.0300\n",
            "Epoch 3, Batch 760: Loss = 1.6300, Acc = 56.77%, Spikes = 0.0297\n",
            "Epoch 3, Batch 770: Loss = 1.7506, Acc = 56.72%, Spikes = 0.0260\n",
            "Epoch 3, Batch 780: Loss = 1.5351, Acc = 56.73%, Spikes = 0.0301\n",
            "Epoch 3, Batch 790: Loss = 1.6809, Acc = 56.75%, Spikes = 0.0312\n",
            "Epoch 3, Batch 800: Loss = 1.6018, Acc = 56.72%, Spikes = 0.0291\n",
            "Epoch 3, Batch 810: Loss = 1.5515, Acc = 56.80%, Spikes = 0.0289\n",
            "Epoch 3, Batch 820: Loss = 1.6677, Acc = 56.86%, Spikes = 0.0283\n",
            "Epoch 3, Batch 830: Loss = 1.7999, Acc = 56.85%, Spikes = 0.0266\n",
            "Epoch 3, Batch 840: Loss = 1.7392, Acc = 56.87%, Spikes = 0.0261\n",
            "Epoch 3, Batch 850: Loss = 1.6985, Acc = 56.89%, Spikes = 0.0277\n",
            "Epoch 3, Batch 860: Loss = 1.5720, Acc = 56.91%, Spikes = 0.0308\n",
            "Epoch 3, Batch 870: Loss = 1.5692, Acc = 56.92%, Spikes = 0.0312\n",
            "Epoch 3, Batch 880: Loss = 1.6047, Acc = 56.84%, Spikes = 0.0296\n",
            "Epoch 3, Batch 890: Loss = 1.8184, Acc = 56.84%, Spikes = 0.0254\n",
            "Epoch 3, Batch 900: Loss = 1.5625, Acc = 56.88%, Spikes = 0.0314\n",
            "Epoch 3, Batch 910: Loss = 1.5463, Acc = 56.88%, Spikes = 0.0308\n",
            "Epoch 3, Batch 920: Loss = 1.6467, Acc = 56.84%, Spikes = 0.0296\n",
            "Epoch 3, Batch 930: Loss = 1.5971, Acc = 56.85%, Spikes = 0.0300\n",
            "Epoch 3, Batch 940: Loss = 1.6734, Acc = 56.89%, Spikes = 0.0283\n",
            "Epoch 3, Batch 950: Loss = 1.6142, Acc = 56.89%, Spikes = 0.0289\n",
            "Epoch 3, Batch 960: Loss = 1.6455, Acc = 56.92%, Spikes = 0.0285\n",
            "Epoch 3, Batch 970: Loss = 1.6585, Acc = 56.95%, Spikes = 0.0288\n",
            "Epoch 3, Batch 980: Loss = 1.5894, Acc = 56.94%, Spikes = 0.0296\n",
            "Epoch 3, Batch 990: Loss = 1.8048, Acc = 56.98%, Spikes = 0.0256\n",
            "Epoch 3, Batch 1000: Loss = 1.6950, Acc = 56.97%, Spikes = 0.0289\n",
            "Epoch 3, Batch 1010: Loss = 1.6427, Acc = 57.00%, Spikes = 0.0306\n",
            "Epoch 3, Batch 1020: Loss = 1.6122, Acc = 57.02%, Spikes = 0.0287\n",
            "Epoch 3, Batch 1030: Loss = 1.6598, Acc = 57.05%, Spikes = 0.0281\n",
            "Epoch 3, Batch 1040: Loss = 1.6372, Acc = 57.06%, Spikes = 0.0291\n",
            "Epoch 3, Batch 1050: Loss = 1.7610, Acc = 57.11%, Spikes = 0.0289\n",
            "Epoch 3, Batch 1060: Loss = 1.6283, Acc = 57.14%, Spikes = 0.0298\n",
            "Epoch 3, Batch 1070: Loss = 1.5280, Acc = 57.17%, Spikes = 0.0302\n",
            "Epoch 3, Batch 1080: Loss = 1.6800, Acc = 57.17%, Spikes = 0.0270\n",
            "Epoch 3, Batch 1090: Loss = 1.5895, Acc = 57.17%, Spikes = 0.0301\n",
            "Epoch 3, Batch 1100: Loss = 1.5016, Acc = 57.20%, Spikes = 0.0303\n",
            "Epoch 3, Batch 1110: Loss = 1.7693, Acc = 57.13%, Spikes = 0.0266\n",
            "Epoch 3, Batch 1120: Loss = 1.4662, Acc = 57.20%, Spikes = 0.0325\n",
            "Epoch 3, Batch 1130: Loss = 1.5746, Acc = 57.18%, Spikes = 0.0315\n",
            "Epoch 3, Batch 1140: Loss = 1.5692, Acc = 57.19%, Spikes = 0.0330\n",
            "Epoch 3, Batch 1150: Loss = 1.6316, Acc = 57.22%, Spikes = 0.0285\n",
            "Epoch 3, Batch 1160: Loss = 1.5163, Acc = 57.23%, Spikes = 0.0288\n",
            "Epoch 3, Batch 1170: Loss = 1.5872, Acc = 57.26%, Spikes = 0.0280\n",
            "Epoch 3, Batch 1180: Loss = 1.7122, Acc = 57.28%, Spikes = 0.0287\n",
            "Epoch 3, Batch 1190: Loss = 1.5937, Acc = 57.28%, Spikes = 0.0318\n",
            "Epoch 3, Batch 1200: Loss = 1.7309, Acc = 57.29%, Spikes = 0.0272\n",
            "Epoch 3, Batch 1210: Loss = 1.6675, Acc = 57.30%, Spikes = 0.0306\n",
            "Epoch 3, Batch 1220: Loss = 1.5504, Acc = 57.30%, Spikes = 0.0273\n",
            "Epoch 3, Batch 1230: Loss = 1.6642, Acc = 57.34%, Spikes = 0.0285\n",
            "Epoch 3, Batch 1240: Loss = 1.5623, Acc = 57.37%, Spikes = 0.0294\n",
            "Epoch 3, Batch 1250: Loss = 1.8711, Acc = 57.36%, Spikes = 0.0270\n",
            "Epoch 3, Batch 1260: Loss = 1.4168, Acc = 57.41%, Spikes = 0.0329\n",
            "Epoch 3, Batch 1270: Loss = 1.6031, Acc = 57.43%, Spikes = 0.0310\n",
            "Epoch 3, Batch 1280: Loss = 1.5554, Acc = 57.46%, Spikes = 0.0326\n",
            "Epoch 3, Batch 1290: Loss = 1.7036, Acc = 57.48%, Spikes = 0.0268\n",
            "Epoch 3, Batch 1300: Loss = 1.6540, Acc = 57.48%, Spikes = 0.0266\n",
            "Epoch 3, Batch 1310: Loss = 1.5720, Acc = 57.48%, Spikes = 0.0298\n",
            "Epoch 3, Batch 1320: Loss = 1.5854, Acc = 57.55%, Spikes = 0.0288\n",
            "Epoch 3, Batch 1330: Loss = 1.5466, Acc = 57.56%, Spikes = 0.0300\n",
            "Epoch 3, Batch 1340: Loss = 1.6000, Acc = 57.55%, Spikes = 0.0285\n",
            "Epoch 3, Batch 1350: Loss = 1.4671, Acc = 57.52%, Spikes = 0.0324\n",
            "Epoch 3, Batch 1360: Loss = 1.4180, Acc = 57.56%, Spikes = 0.0323\n",
            "Epoch 3, Batch 1370: Loss = 1.7800, Acc = 57.55%, Spikes = 0.0296\n",
            "Epoch 3, Batch 1380: Loss = 1.6109, Acc = 57.56%, Spikes = 0.0293\n",
            "Epoch 3, Batch 1390: Loss = 1.4693, Acc = 57.59%, Spikes = 0.0325\n",
            "Epoch 3, Batch 1400: Loss = 1.5524, Acc = 57.60%, Spikes = 0.0307\n",
            "Epoch 3, Batch 1410: Loss = 1.5544, Acc = 57.62%, Spikes = 0.0288\n",
            "Epoch 3, Batch 1420: Loss = 1.3950, Acc = 57.65%, Spikes = 0.0335\n",
            "Epoch 3, Batch 1430: Loss = 1.5992, Acc = 57.67%, Spikes = 0.0310\n",
            "Epoch 3, Batch 1440: Loss = 1.4399, Acc = 57.72%, Spikes = 0.0312\n",
            "Epoch 3, Batch 1450: Loss = 1.5576, Acc = 57.72%, Spikes = 0.0304\n",
            "Epoch 3, Batch 1460: Loss = 1.4516, Acc = 57.73%, Spikes = 0.0286\n",
            "Epoch 3, Batch 1470: Loss = 1.4348, Acc = 57.76%, Spikes = 0.0309\n",
            "Epoch 3, Batch 1480: Loss = 1.6423, Acc = 57.76%, Spikes = 0.0291\n",
            "Epoch 3, Batch 1490: Loss = 1.5737, Acc = 57.78%, Spikes = 0.0289\n",
            "Epoch 3, Batch 1500: Loss = 1.5635, Acc = 57.78%, Spikes = 0.0320\n",
            "Epoch 3, Batch 1510: Loss = 1.4875, Acc = 57.76%, Spikes = 0.0309\n",
            "Epoch 3, Batch 1520: Loss = 1.5438, Acc = 57.81%, Spikes = 0.0300\n",
            "Epoch 3, Batch 1530: Loss = 1.5077, Acc = 57.83%, Spikes = 0.0302\n",
            "Epoch 3, Batch 1540: Loss = 1.6644, Acc = 57.86%, Spikes = 0.0292\n",
            "Epoch 3, Batch 1550: Loss = 1.5556, Acc = 57.86%, Spikes = 0.0313\n",
            "Epoch 3, Batch 1560: Loss = 1.3444, Acc = 57.86%, Spikes = 0.0335\n",
            "Epoch 3, Batch 1570: Loss = 1.5605, Acc = 57.86%, Spikes = 0.0315\n",
            "Epoch 3, Batch 1580: Loss = 1.6087, Acc = 57.89%, Spikes = 0.0306\n",
            "Epoch 3, Batch 1590: Loss = 1.6012, Acc = 57.90%, Spikes = 0.0292\n",
            "Epoch 3, Batch 1600: Loss = 1.4836, Acc = 57.94%, Spikes = 0.0303\n",
            "Epoch 3, Batch 1610: Loss = 1.4925, Acc = 57.95%, Spikes = 0.0304\n",
            "Epoch 3, Batch 1620: Loss = 1.4861, Acc = 57.98%, Spikes = 0.0327\n",
            "Epoch 3, Batch 1630: Loss = 1.5107, Acc = 57.96%, Spikes = 0.0292\n",
            "Epoch 3, Batch 1640: Loss = 1.5925, Acc = 57.97%, Spikes = 0.0270\n",
            "Epoch 3, Batch 1650: Loss = 1.4913, Acc = 57.99%, Spikes = 0.0329\n",
            "Epoch 3, Batch 1660: Loss = 1.6625, Acc = 58.02%, Spikes = 0.0279\n",
            "Epoch 3, Batch 1670: Loss = 1.3683, Acc = 58.01%, Spikes = 0.0332\n",
            "Epoch 3, Batch 1680: Loss = 1.5109, Acc = 58.02%, Spikes = 0.0310\n",
            "Epoch 3, Batch 1690: Loss = 1.5820, Acc = 58.04%, Spikes = 0.0297\n",
            "Epoch 3, Batch 1700: Loss = 1.6337, Acc = 58.02%, Spikes = 0.0310\n",
            "Epoch 3, Batch 1710: Loss = 1.5867, Acc = 58.05%, Spikes = 0.0320\n",
            "Epoch 3, Batch 1720: Loss = 1.6406, Acc = 58.03%, Spikes = 0.0293\n",
            "Epoch 3, Batch 1730: Loss = 1.5588, Acc = 58.06%, Spikes = 0.0317\n",
            "Epoch 3, Batch 1740: Loss = 1.4976, Acc = 58.08%, Spikes = 0.0324\n",
            "Epoch 3, Batch 1750: Loss = 1.5901, Acc = 58.09%, Spikes = 0.0309\n",
            "Epoch 3, Batch 1760: Loss = 1.3551, Acc = 58.12%, Spikes = 0.0323\n",
            "Epoch 3, Batch 1770: Loss = 1.5957, Acc = 58.15%, Spikes = 0.0302\n",
            "Epoch 3, Batch 1780: Loss = 1.5013, Acc = 58.14%, Spikes = 0.0297\n",
            "Epoch 3, Batch 1790: Loss = 1.5158, Acc = 58.17%, Spikes = 0.0310\n",
            "Epoch 3, Batch 1800: Loss = 1.4419, Acc = 58.20%, Spikes = 0.0321\n",
            "Epoch 3, Batch 1810: Loss = 1.4453, Acc = 58.21%, Spikes = 0.0335\n",
            "Epoch 3, Batch 1820: Loss = 1.5712, Acc = 58.21%, Spikes = 0.0300\n",
            "Epoch 3, Batch 1830: Loss = 1.4332, Acc = 58.23%, Spikes = 0.0321\n",
            "Epoch 3, Batch 1840: Loss = 1.5189, Acc = 58.28%, Spikes = 0.0308\n",
            "Epoch 3, Batch 1850: Loss = 1.4543, Acc = 58.30%, Spikes = 0.0316\n",
            "Epoch 3, Batch 1860: Loss = 1.5906, Acc = 58.31%, Spikes = 0.0296\n",
            "Epoch 3, Batch 1870: Loss = 1.4545, Acc = 58.34%, Spikes = 0.0295\n",
            "Epoch 3/15:\n",
            "Train Loss: 1.6550 | Train Acc: 58.34% | Train Spikes: 0.0288\n",
            "Test Acc: 62.16% | Test Spikes: 0.0320\n",
            "------------------------------------------------------------\n",
            "Epoch 4, Batch 0: Loss = 1.7112, Acc = 50.00%, Spikes = 0.0265\n",
            "Epoch 4, Batch 10: Loss = 1.4450, Acc = 59.09%, Spikes = 0.0331\n",
            "Epoch 4, Batch 20: Loss = 1.3819, Acc = 60.42%, Spikes = 0.0315\n",
            "Epoch 4, Batch 30: Loss = 1.4289, Acc = 60.58%, Spikes = 0.0330\n",
            "Epoch 4, Batch 40: Loss = 1.5196, Acc = 60.98%, Spikes = 0.0292\n",
            "Epoch 4, Batch 50: Loss = 1.4924, Acc = 60.42%, Spikes = 0.0316\n",
            "Epoch 4, Batch 60: Loss = 1.6151, Acc = 60.81%, Spikes = 0.0299\n",
            "Epoch 4, Batch 70: Loss = 1.4516, Acc = 61.18%, Spikes = 0.0301\n",
            "Epoch 4, Batch 80: Loss = 1.5859, Acc = 61.27%, Spikes = 0.0271\n",
            "Epoch 4, Batch 90: Loss = 1.5641, Acc = 61.47%, Spikes = 0.0290\n",
            "Epoch 4, Batch 100: Loss = 1.4398, Acc = 61.45%, Spikes = 0.0334\n",
            "Epoch 4, Batch 110: Loss = 1.4060, Acc = 61.09%, Spikes = 0.0317\n",
            "Epoch 4, Batch 120: Loss = 1.7170, Acc = 61.08%, Spikes = 0.0295\n",
            "Epoch 4, Batch 130: Loss = 1.6269, Acc = 60.95%, Spikes = 0.0275\n",
            "Epoch 4, Batch 140: Loss = 1.5003, Acc = 60.93%, Spikes = 0.0292\n",
            "Epoch 4, Batch 150: Loss = 1.4983, Acc = 61.11%, Spikes = 0.0308\n",
            "Epoch 4, Batch 160: Loss = 1.4472, Acc = 61.32%, Spikes = 0.0310\n",
            "Epoch 4, Batch 170: Loss = 1.3842, Acc = 61.24%, Spikes = 0.0311\n",
            "Epoch 4, Batch 180: Loss = 1.2271, Acc = 61.27%, Spikes = 0.0335\n",
            "Epoch 4, Batch 190: Loss = 1.5172, Acc = 61.34%, Spikes = 0.0312\n",
            "Epoch 4, Batch 200: Loss = 1.4979, Acc = 61.41%, Spikes = 0.0299\n",
            "Epoch 4, Batch 210: Loss = 1.4235, Acc = 61.48%, Spikes = 0.0316\n",
            "Epoch 4, Batch 220: Loss = 1.4779, Acc = 61.40%, Spikes = 0.0300\n",
            "Epoch 4, Batch 230: Loss = 1.4926, Acc = 61.23%, Spikes = 0.0321\n",
            "Epoch 4, Batch 240: Loss = 1.4740, Acc = 61.27%, Spikes = 0.0303\n",
            "Epoch 4, Batch 250: Loss = 1.6077, Acc = 61.14%, Spikes = 0.0313\n",
            "Epoch 4, Batch 260: Loss = 1.3724, Acc = 61.24%, Spikes = 0.0329\n",
            "Epoch 4, Batch 270: Loss = 1.5512, Acc = 61.28%, Spikes = 0.0333\n",
            "Epoch 4, Batch 280: Loss = 1.4266, Acc = 61.31%, Spikes = 0.0328\n",
            "Epoch 4, Batch 290: Loss = 1.6302, Acc = 61.24%, Spikes = 0.0319\n",
            "Epoch 4, Batch 300: Loss = 1.5732, Acc = 61.20%, Spikes = 0.0279\n",
            "Epoch 4, Batch 310: Loss = 1.3401, Acc = 61.21%, Spikes = 0.0349\n",
            "Epoch 4, Batch 320: Loss = 1.3076, Acc = 61.20%, Spikes = 0.0373\n",
            "Epoch 4, Batch 330: Loss = 1.5161, Acc = 61.25%, Spikes = 0.0297\n",
            "Epoch 4, Batch 340: Loss = 1.4044, Acc = 61.37%, Spikes = 0.0314\n",
            "Epoch 4, Batch 350: Loss = 1.4850, Acc = 61.33%, Spikes = 0.0301\n",
            "Epoch 4, Batch 360: Loss = 1.4950, Acc = 61.31%, Spikes = 0.0323\n",
            "Epoch 4, Batch 370: Loss = 1.5961, Acc = 61.17%, Spikes = 0.0296\n",
            "Epoch 4, Batch 380: Loss = 1.3929, Acc = 61.27%, Spikes = 0.0356\n",
            "Epoch 4, Batch 390: Loss = 1.4072, Acc = 61.26%, Spikes = 0.0319\n",
            "Epoch 4, Batch 400: Loss = 1.2745, Acc = 61.25%, Spikes = 0.0311\n",
            "Epoch 4, Batch 410: Loss = 1.4227, Acc = 61.25%, Spikes = 0.0339\n",
            "Epoch 4, Batch 420: Loss = 1.4029, Acc = 61.22%, Spikes = 0.0318\n",
            "Epoch 4, Batch 430: Loss = 1.3610, Acc = 61.25%, Spikes = 0.0319\n",
            "Epoch 4, Batch 440: Loss = 1.4301, Acc = 61.29%, Spikes = 0.0331\n",
            "Epoch 4, Batch 450: Loss = 1.4416, Acc = 61.34%, Spikes = 0.0306\n",
            "Epoch 4, Batch 460: Loss = 1.4140, Acc = 61.44%, Spikes = 0.0363\n",
            "Epoch 4, Batch 470: Loss = 1.1622, Acc = 61.53%, Spikes = 0.0333\n",
            "Epoch 4, Batch 480: Loss = 1.4139, Acc = 61.55%, Spikes = 0.0337\n",
            "Epoch 4, Batch 490: Loss = 1.4170, Acc = 61.60%, Spikes = 0.0348\n",
            "Epoch 4, Batch 500: Loss = 1.2070, Acc = 61.65%, Spikes = 0.0340\n",
            "Epoch 4, Batch 510: Loss = 1.4155, Acc = 61.65%, Spikes = 0.0344\n",
            "Epoch 4, Batch 520: Loss = 1.4333, Acc = 61.75%, Spikes = 0.0334\n",
            "Epoch 4, Batch 530: Loss = 1.7297, Acc = 61.76%, Spikes = 0.0298\n",
            "Epoch 4, Batch 540: Loss = 1.5437, Acc = 61.72%, Spikes = 0.0305\n",
            "Epoch 4, Batch 550: Loss = 1.3498, Acc = 61.73%, Spikes = 0.0353\n",
            "Epoch 4, Batch 560: Loss = 1.2845, Acc = 61.69%, Spikes = 0.0367\n",
            "Epoch 4, Batch 570: Loss = 1.4513, Acc = 61.74%, Spikes = 0.0290\n",
            "Epoch 4, Batch 580: Loss = 1.3685, Acc = 61.69%, Spikes = 0.0346\n",
            "Epoch 4, Batch 590: Loss = 1.3927, Acc = 61.64%, Spikes = 0.0350\n",
            "Epoch 4, Batch 600: Loss = 1.4896, Acc = 61.67%, Spikes = 0.0333\n",
            "Epoch 4, Batch 610: Loss = 1.5313, Acc = 61.68%, Spikes = 0.0342\n",
            "Epoch 4, Batch 620: Loss = 1.3585, Acc = 61.68%, Spikes = 0.0326\n",
            "Epoch 4, Batch 630: Loss = 1.2493, Acc = 61.72%, Spikes = 0.0354\n",
            "Epoch 4, Batch 640: Loss = 1.2736, Acc = 61.77%, Spikes = 0.0326\n",
            "Epoch 4, Batch 650: Loss = 1.5053, Acc = 61.84%, Spikes = 0.0312\n",
            "Epoch 4, Batch 660: Loss = 1.2632, Acc = 61.88%, Spikes = 0.0339\n",
            "Epoch 4, Batch 670: Loss = 1.3999, Acc = 61.91%, Spikes = 0.0327\n",
            "Epoch 4, Batch 680: Loss = 1.3027, Acc = 61.88%, Spikes = 0.0329\n",
            "Epoch 4, Batch 690: Loss = 1.2580, Acc = 61.88%, Spikes = 0.0333\n",
            "Epoch 4, Batch 700: Loss = 1.6458, Acc = 61.88%, Spikes = 0.0292\n",
            "Epoch 4, Batch 710: Loss = 1.2599, Acc = 61.90%, Spikes = 0.0350\n",
            "Epoch 4, Batch 720: Loss = 1.4750, Acc = 61.94%, Spikes = 0.0307\n",
            "Epoch 4, Batch 730: Loss = 1.3367, Acc = 61.97%, Spikes = 0.0339\n",
            "Epoch 4, Batch 740: Loss = 1.2968, Acc = 62.02%, Spikes = 0.0341\n",
            "Epoch 4, Batch 750: Loss = 1.1745, Acc = 62.08%, Spikes = 0.0348\n",
            "Epoch 4, Batch 760: Loss = 1.1621, Acc = 62.08%, Spikes = 0.0346\n",
            "Epoch 4, Batch 770: Loss = 1.3146, Acc = 62.14%, Spikes = 0.0312\n",
            "Epoch 4, Batch 780: Loss = 1.3336, Acc = 62.12%, Spikes = 0.0337\n",
            "Epoch 4, Batch 790: Loss = 1.4273, Acc = 62.14%, Spikes = 0.0292\n",
            "Epoch 4, Batch 800: Loss = 1.3509, Acc = 62.15%, Spikes = 0.0313\n",
            "Epoch 4, Batch 810: Loss = 1.4391, Acc = 62.12%, Spikes = 0.0317\n",
            "Epoch 4, Batch 820: Loss = 1.2898, Acc = 62.15%, Spikes = 0.0327\n",
            "Epoch 4, Batch 830: Loss = 1.4438, Acc = 62.16%, Spikes = 0.0312\n",
            "Epoch 4, Batch 840: Loss = 1.4856, Acc = 62.20%, Spikes = 0.0315\n",
            "Epoch 4, Batch 850: Loss = 1.3649, Acc = 62.22%, Spikes = 0.0324\n",
            "Epoch 4, Batch 860: Loss = 1.5920, Acc = 62.29%, Spikes = 0.0343\n",
            "Epoch 4, Batch 870: Loss = 1.4451, Acc = 62.31%, Spikes = 0.0347\n",
            "Epoch 4, Batch 880: Loss = 1.7713, Acc = 62.31%, Spikes = 0.0283\n",
            "Epoch 4, Batch 890: Loss = 1.4460, Acc = 62.28%, Spikes = 0.0294\n",
            "Epoch 4, Batch 900: Loss = 1.3966, Acc = 62.32%, Spikes = 0.0342\n",
            "Epoch 4, Batch 910: Loss = 1.5126, Acc = 62.27%, Spikes = 0.0334\n",
            "Epoch 4, Batch 920: Loss = 1.2967, Acc = 62.32%, Spikes = 0.0374\n",
            "Epoch 4, Batch 930: Loss = 1.2696, Acc = 62.34%, Spikes = 0.0327\n",
            "Epoch 4, Batch 940: Loss = 1.2626, Acc = 62.29%, Spikes = 0.0368\n",
            "Epoch 4, Batch 950: Loss = 1.5325, Acc = 62.26%, Spikes = 0.0280\n",
            "Epoch 4, Batch 960: Loss = 1.5063, Acc = 62.26%, Spikes = 0.0331\n",
            "Epoch 4, Batch 970: Loss = 1.1380, Acc = 62.30%, Spikes = 0.0351\n",
            "Epoch 4, Batch 980: Loss = 1.1354, Acc = 62.34%, Spikes = 0.0335\n",
            "Epoch 4, Batch 990: Loss = 1.3645, Acc = 62.38%, Spikes = 0.0287\n",
            "Epoch 4, Batch 1000: Loss = 1.4298, Acc = 62.35%, Spikes = 0.0354\n",
            "Epoch 4, Batch 1010: Loss = 1.3847, Acc = 62.34%, Spikes = 0.0304\n",
            "Epoch 4, Batch 1020: Loss = 1.3823, Acc = 62.33%, Spikes = 0.0352\n",
            "Epoch 4, Batch 1030: Loss = 1.4624, Acc = 62.34%, Spikes = 0.0329\n",
            "Epoch 4, Batch 1040: Loss = 1.2483, Acc = 62.35%, Spikes = 0.0359\n",
            "Epoch 4, Batch 1050: Loss = 1.3484, Acc = 62.34%, Spikes = 0.0347\n",
            "Epoch 4, Batch 1060: Loss = 1.5486, Acc = 62.38%, Spikes = 0.0316\n",
            "Epoch 4, Batch 1070: Loss = 1.3499, Acc = 62.37%, Spikes = 0.0323\n",
            "Epoch 4, Batch 1080: Loss = 1.1370, Acc = 62.45%, Spikes = 0.0355\n",
            "Epoch 4, Batch 1090: Loss = 1.2302, Acc = 62.45%, Spikes = 0.0328\n",
            "Epoch 4, Batch 1100: Loss = 1.1857, Acc = 62.47%, Spikes = 0.0362\n",
            "Epoch 4, Batch 1110: Loss = 1.4340, Acc = 62.47%, Spikes = 0.0319\n",
            "Epoch 4, Batch 1120: Loss = 1.3063, Acc = 62.47%, Spikes = 0.0381\n",
            "Epoch 4, Batch 1130: Loss = 1.3711, Acc = 62.50%, Spikes = 0.0326\n",
            "Epoch 4, Batch 1140: Loss = 1.3859, Acc = 62.48%, Spikes = 0.0329\n",
            "Epoch 4, Batch 1150: Loss = 1.2843, Acc = 62.51%, Spikes = 0.0346\n",
            "Epoch 4, Batch 1160: Loss = 1.3095, Acc = 62.54%, Spikes = 0.0334\n",
            "Epoch 4, Batch 1170: Loss = 1.3996, Acc = 62.52%, Spikes = 0.0336\n",
            "Epoch 4, Batch 1180: Loss = 1.3077, Acc = 62.55%, Spikes = 0.0332\n",
            "Epoch 4, Batch 1190: Loss = 1.3170, Acc = 62.54%, Spikes = 0.0322\n",
            "Epoch 4, Batch 1200: Loss = 1.3025, Acc = 62.53%, Spikes = 0.0329\n",
            "Epoch 4, Batch 1210: Loss = 1.3093, Acc = 62.57%, Spikes = 0.0351\n",
            "Epoch 4, Batch 1220: Loss = 1.3017, Acc = 62.59%, Spikes = 0.0328\n",
            "Epoch 4, Batch 1230: Loss = 1.3702, Acc = 62.64%, Spikes = 0.0331\n",
            "Epoch 4, Batch 1240: Loss = 1.4392, Acc = 62.62%, Spikes = 0.0320\n",
            "Epoch 4, Batch 1250: Loss = 1.3350, Acc = 62.64%, Spikes = 0.0372\n",
            "Epoch 4, Batch 1260: Loss = 1.2851, Acc = 62.67%, Spikes = 0.0351\n",
            "Epoch 4, Batch 1270: Loss = 1.2535, Acc = 62.71%, Spikes = 0.0342\n",
            "Epoch 4, Batch 1280: Loss = 1.3816, Acc = 62.72%, Spikes = 0.0347\n",
            "Epoch 4, Batch 1290: Loss = 1.4689, Acc = 62.73%, Spikes = 0.0340\n",
            "Epoch 4, Batch 1300: Loss = 1.3236, Acc = 62.71%, Spikes = 0.0314\n",
            "Epoch 4, Batch 1310: Loss = 1.3140, Acc = 62.72%, Spikes = 0.0323\n",
            "Epoch 4, Batch 1320: Loss = 1.2657, Acc = 62.75%, Spikes = 0.0339\n",
            "Epoch 4, Batch 1330: Loss = 1.3299, Acc = 62.76%, Spikes = 0.0347\n",
            "Epoch 4, Batch 1340: Loss = 1.4391, Acc = 62.76%, Spikes = 0.0324\n",
            "Epoch 4, Batch 1350: Loss = 1.1468, Acc = 62.75%, Spikes = 0.0385\n",
            "Epoch 4, Batch 1360: Loss = 1.3890, Acc = 62.79%, Spikes = 0.0330\n",
            "Epoch 4, Batch 1370: Loss = 1.2603, Acc = 62.78%, Spikes = 0.0358\n",
            "Epoch 4, Batch 1380: Loss = 1.2955, Acc = 62.76%, Spikes = 0.0317\n",
            "Epoch 4, Batch 1390: Loss = 1.1148, Acc = 62.78%, Spikes = 0.0373\n",
            "Epoch 4, Batch 1400: Loss = 1.4165, Acc = 62.78%, Spikes = 0.0335\n",
            "Epoch 4, Batch 1410: Loss = 1.2213, Acc = 62.77%, Spikes = 0.0345\n",
            "Epoch 4, Batch 1420: Loss = 1.3583, Acc = 62.79%, Spikes = 0.0338\n",
            "Epoch 4, Batch 1430: Loss = 1.2958, Acc = 62.83%, Spikes = 0.0334\n",
            "Epoch 4, Batch 1440: Loss = 1.2984, Acc = 62.81%, Spikes = 0.0341\n",
            "Epoch 4, Batch 1450: Loss = 1.2603, Acc = 62.84%, Spikes = 0.0336\n",
            "Epoch 4, Batch 1460: Loss = 1.2653, Acc = 62.84%, Spikes = 0.0324\n",
            "Epoch 4, Batch 1470: Loss = 1.3835, Acc = 62.82%, Spikes = 0.0359\n",
            "Epoch 4, Batch 1480: Loss = 1.5091, Acc = 62.81%, Spikes = 0.0318\n",
            "Epoch 4, Batch 1490: Loss = 1.4642, Acc = 62.80%, Spikes = 0.0322\n",
            "Epoch 4, Batch 1500: Loss = 1.1699, Acc = 62.81%, Spikes = 0.0397\n",
            "Epoch 4, Batch 1510: Loss = 1.1729, Acc = 62.83%, Spikes = 0.0344\n",
            "Epoch 4, Batch 1520: Loss = 1.2242, Acc = 62.84%, Spikes = 0.0388\n",
            "Epoch 4, Batch 1530: Loss = 1.3710, Acc = 62.85%, Spikes = 0.0320\n",
            "Epoch 4, Batch 1540: Loss = 1.2562, Acc = 62.87%, Spikes = 0.0311\n",
            "Epoch 4, Batch 1550: Loss = 1.3182, Acc = 62.87%, Spikes = 0.0345\n",
            "Epoch 4, Batch 1560: Loss = 1.0681, Acc = 62.89%, Spikes = 0.0361\n",
            "Epoch 4, Batch 1570: Loss = 1.4391, Acc = 62.89%, Spikes = 0.0308\n",
            "Epoch 4, Batch 1580: Loss = 1.3283, Acc = 62.88%, Spikes = 0.0333\n",
            "Epoch 4, Batch 1590: Loss = 1.2216, Acc = 62.90%, Spikes = 0.0350\n",
            "Epoch 4, Batch 1600: Loss = 1.0994, Acc = 62.90%, Spikes = 0.0375\n",
            "Epoch 4, Batch 1610: Loss = 1.5036, Acc = 62.88%, Spikes = 0.0330\n",
            "Epoch 4, Batch 1620: Loss = 1.1181, Acc = 62.90%, Spikes = 0.0382\n",
            "Epoch 4, Batch 1630: Loss = 1.3129, Acc = 62.91%, Spikes = 0.0368\n",
            "Epoch 4, Batch 1640: Loss = 1.4134, Acc = 62.93%, Spikes = 0.0339\n",
            "Epoch 4, Batch 1650: Loss = 1.2244, Acc = 62.96%, Spikes = 0.0355\n",
            "Epoch 4, Batch 1660: Loss = 1.1677, Acc = 62.98%, Spikes = 0.0354\n",
            "Epoch 4, Batch 1670: Loss = 1.2047, Acc = 62.97%, Spikes = 0.0350\n",
            "Epoch 4, Batch 1680: Loss = 1.4123, Acc = 62.96%, Spikes = 0.0363\n",
            "Epoch 4, Batch 1690: Loss = 1.4329, Acc = 62.95%, Spikes = 0.0334\n",
            "Epoch 4, Batch 1700: Loss = 1.1294, Acc = 62.94%, Spikes = 0.0377\n",
            "Epoch 4, Batch 1710: Loss = 1.2801, Acc = 62.94%, Spikes = 0.0340\n",
            "Epoch 4, Batch 1720: Loss = 1.2266, Acc = 62.95%, Spikes = 0.0349\n",
            "Epoch 4, Batch 1730: Loss = 1.4541, Acc = 62.96%, Spikes = 0.0327\n",
            "Epoch 4, Batch 1740: Loss = 1.1954, Acc = 63.00%, Spikes = 0.0353\n",
            "Epoch 4, Batch 1750: Loss = 1.1787, Acc = 63.00%, Spikes = 0.0335\n",
            "Epoch 4, Batch 1760: Loss = 1.2583, Acc = 63.01%, Spikes = 0.0372\n",
            "Epoch 4, Batch 1770: Loss = 1.2562, Acc = 63.03%, Spikes = 0.0362\n",
            "Epoch 4, Batch 1780: Loss = 1.3192, Acc = 63.05%, Spikes = 0.0325\n",
            "Epoch 4, Batch 1790: Loss = 1.2729, Acc = 63.07%, Spikes = 0.0339\n",
            "Epoch 4, Batch 1800: Loss = 1.0487, Acc = 63.08%, Spikes = 0.0368\n",
            "Epoch 4, Batch 1810: Loss = 1.4394, Acc = 63.11%, Spikes = 0.0327\n",
            "Epoch 4, Batch 1820: Loss = 1.4162, Acc = 63.11%, Spikes = 0.0361\n",
            "Epoch 4, Batch 1830: Loss = 1.3544, Acc = 63.12%, Spikes = 0.0359\n",
            "Epoch 4, Batch 1840: Loss = 1.3772, Acc = 63.15%, Spikes = 0.0370\n",
            "Epoch 4, Batch 1850: Loss = 1.2207, Acc = 63.18%, Spikes = 0.0361\n",
            "Epoch 4, Batch 1860: Loss = 1.2591, Acc = 63.18%, Spikes = 0.0340\n",
            "Epoch 4, Batch 1870: Loss = 1.3146, Acc = 63.22%, Spikes = 0.0374\n",
            "Epoch 4/15:\n",
            "Train Loss: 1.3681 | Train Acc: 63.24% | Train Spikes: 0.0331\n",
            "Test Acc: 65.97% | Test Spikes: 0.0356\n",
            "------------------------------------------------------------\n",
            "Epoch 5, Batch 0: Loss = 1.2346, Acc = 78.12%, Spikes = 0.0339\n",
            "Epoch 5, Batch 10: Loss = 1.0788, Acc = 68.75%, Spikes = 0.0360\n",
            "Epoch 5, Batch 20: Loss = 1.2377, Acc = 66.82%, Spikes = 0.0372\n",
            "Epoch 5, Batch 30: Loss = 0.9856, Acc = 66.63%, Spikes = 0.0364\n",
            "Epoch 5, Batch 40: Loss = 1.3776, Acc = 65.93%, Spikes = 0.0327\n",
            "Epoch 5, Batch 50: Loss = 1.3125, Acc = 65.32%, Spikes = 0.0347\n",
            "Epoch 5, Batch 60: Loss = 1.2813, Acc = 65.98%, Spikes = 0.0349\n",
            "Epoch 5, Batch 70: Loss = 1.2092, Acc = 66.37%, Spikes = 0.0332\n",
            "Epoch 5, Batch 80: Loss = 1.2354, Acc = 65.86%, Spikes = 0.0355\n",
            "Epoch 5, Batch 90: Loss = 1.1985, Acc = 65.90%, Spikes = 0.0360\n",
            "Epoch 5, Batch 100: Loss = 1.4213, Acc = 65.84%, Spikes = 0.0326\n",
            "Epoch 5, Batch 110: Loss = 1.3268, Acc = 65.85%, Spikes = 0.0326\n",
            "Epoch 5, Batch 120: Loss = 1.3172, Acc = 66.09%, Spikes = 0.0335\n",
            "Epoch 5, Batch 130: Loss = 1.2609, Acc = 66.25%, Spikes = 0.0323\n",
            "Epoch 5, Batch 140: Loss = 1.3230, Acc = 65.98%, Spikes = 0.0344\n",
            "Epoch 5, Batch 150: Loss = 1.3298, Acc = 66.14%, Spikes = 0.0340\n",
            "Epoch 5, Batch 160: Loss = 1.1804, Acc = 66.05%, Spikes = 0.0362\n",
            "Epoch 5, Batch 170: Loss = 1.3142, Acc = 66.19%, Spikes = 0.0349\n",
            "Epoch 5, Batch 180: Loss = 1.2286, Acc = 66.11%, Spikes = 0.0392\n",
            "Epoch 5, Batch 190: Loss = 1.1290, Acc = 65.98%, Spikes = 0.0366\n",
            "Epoch 5, Batch 200: Loss = 1.4378, Acc = 65.90%, Spikes = 0.0341\n",
            "Epoch 5, Batch 210: Loss = 1.2662, Acc = 65.92%, Spikes = 0.0348\n",
            "Epoch 5, Batch 220: Loss = 1.1211, Acc = 65.85%, Spikes = 0.0366\n",
            "Epoch 5, Batch 230: Loss = 1.2216, Acc = 65.90%, Spikes = 0.0344\n",
            "Epoch 5, Batch 240: Loss = 1.1238, Acc = 65.98%, Spikes = 0.0360\n",
            "Epoch 5, Batch 250: Loss = 1.2239, Acc = 65.84%, Spikes = 0.0354\n",
            "Epoch 5, Batch 260: Loss = 1.2604, Acc = 65.71%, Spikes = 0.0347\n",
            "Epoch 5, Batch 270: Loss = 1.3630, Acc = 65.61%, Spikes = 0.0368\n",
            "Epoch 5, Batch 280: Loss = 1.3098, Acc = 65.66%, Spikes = 0.0351\n",
            "Epoch 5, Batch 290: Loss = 1.4163, Acc = 65.59%, Spikes = 0.0294\n",
            "Epoch 5, Batch 300: Loss = 1.2253, Acc = 65.55%, Spikes = 0.0353\n",
            "Epoch 5, Batch 310: Loss = 1.2845, Acc = 65.51%, Spikes = 0.0384\n",
            "Epoch 5, Batch 320: Loss = 1.4000, Acc = 65.51%, Spikes = 0.0324\n",
            "Epoch 5, Batch 330: Loss = 1.3007, Acc = 65.54%, Spikes = 0.0354\n",
            "Epoch 5, Batch 340: Loss = 1.2518, Acc = 65.56%, Spikes = 0.0342\n",
            "Epoch 5, Batch 350: Loss = 1.2575, Acc = 65.59%, Spikes = 0.0380\n",
            "Epoch 5, Batch 360: Loss = 1.1171, Acc = 65.56%, Spikes = 0.0343\n",
            "Epoch 5, Batch 370: Loss = 1.3585, Acc = 65.58%, Spikes = 0.0383\n",
            "Epoch 5, Batch 380: Loss = 1.0722, Acc = 65.61%, Spikes = 0.0368\n",
            "Epoch 5, Batch 390: Loss = 1.2588, Acc = 65.69%, Spikes = 0.0362\n",
            "Epoch 5, Batch 400: Loss = 1.3244, Acc = 65.73%, Spikes = 0.0335\n",
            "Epoch 5, Batch 410: Loss = 1.0730, Acc = 65.84%, Spikes = 0.0411\n",
            "Epoch 5, Batch 420: Loss = 1.2315, Acc = 65.77%, Spikes = 0.0399\n",
            "Epoch 5, Batch 430: Loss = 1.2232, Acc = 65.81%, Spikes = 0.0361\n",
            "Epoch 5, Batch 440: Loss = 1.1389, Acc = 65.78%, Spikes = 0.0358\n",
            "Epoch 5, Batch 450: Loss = 1.2528, Acc = 65.78%, Spikes = 0.0380\n",
            "Epoch 5, Batch 460: Loss = 1.1475, Acc = 65.67%, Spikes = 0.0352\n",
            "Epoch 5, Batch 470: Loss = 1.3359, Acc = 65.71%, Spikes = 0.0366\n",
            "Epoch 5, Batch 480: Loss = 1.4743, Acc = 65.74%, Spikes = 0.0316\n",
            "Epoch 5, Batch 490: Loss = 1.1749, Acc = 65.80%, Spikes = 0.0351\n",
            "Epoch 5, Batch 500: Loss = 1.2067, Acc = 65.79%, Spikes = 0.0376\n",
            "Epoch 5, Batch 510: Loss = 1.2071, Acc = 65.80%, Spikes = 0.0348\n",
            "Epoch 5, Batch 520: Loss = 1.1537, Acc = 65.82%, Spikes = 0.0359\n",
            "Epoch 5, Batch 530: Loss = 1.3185, Acc = 65.82%, Spikes = 0.0371\n",
            "Epoch 5, Batch 540: Loss = 1.2354, Acc = 65.87%, Spikes = 0.0340\n",
            "Epoch 5, Batch 550: Loss = 1.2512, Acc = 65.99%, Spikes = 0.0384\n",
            "Epoch 5, Batch 560: Loss = 1.4154, Acc = 65.94%, Spikes = 0.0361\n",
            "Epoch 5, Batch 570: Loss = 1.3243, Acc = 65.95%, Spikes = 0.0314\n",
            "Epoch 5, Batch 580: Loss = 1.2079, Acc = 65.98%, Spikes = 0.0347\n",
            "Epoch 5, Batch 590: Loss = 1.3578, Acc = 65.96%, Spikes = 0.0347\n",
            "Epoch 5, Batch 600: Loss = 1.3073, Acc = 65.90%, Spikes = 0.0343\n",
            "Epoch 5, Batch 610: Loss = 1.1275, Acc = 65.95%, Spikes = 0.0369\n",
            "Epoch 5, Batch 620: Loss = 1.1488, Acc = 65.98%, Spikes = 0.0328\n",
            "Epoch 5, Batch 630: Loss = 1.0733, Acc = 65.96%, Spikes = 0.0421\n",
            "Epoch 5, Batch 640: Loss = 1.0976, Acc = 66.00%, Spikes = 0.0368\n",
            "Epoch 5, Batch 650: Loss = 1.1383, Acc = 66.06%, Spikes = 0.0413\n",
            "Epoch 5, Batch 660: Loss = 1.3533, Acc = 66.08%, Spikes = 0.0350\n",
            "Epoch 5, Batch 670: Loss = 1.0358, Acc = 66.09%, Spikes = 0.0376\n",
            "Epoch 5, Batch 680: Loss = 1.1973, Acc = 66.08%, Spikes = 0.0334\n",
            "Epoch 5, Batch 690: Loss = 1.1355, Acc = 66.05%, Spikes = 0.0367\n",
            "Epoch 5, Batch 700: Loss = 1.1165, Acc = 66.12%, Spikes = 0.0389\n",
            "Epoch 5, Batch 710: Loss = 1.2653, Acc = 66.17%, Spikes = 0.0349\n",
            "Epoch 5, Batch 720: Loss = 1.1538, Acc = 66.17%, Spikes = 0.0381\n",
            "Epoch 5, Batch 730: Loss = 1.3728, Acc = 66.16%, Spikes = 0.0359\n",
            "Epoch 5, Batch 740: Loss = 1.3810, Acc = 66.12%, Spikes = 0.0346\n",
            "Epoch 5, Batch 750: Loss = 0.9854, Acc = 66.20%, Spikes = 0.0374\n",
            "Epoch 5, Batch 760: Loss = 1.2795, Acc = 66.18%, Spikes = 0.0332\n",
            "Epoch 5, Batch 770: Loss = 1.3471, Acc = 66.12%, Spikes = 0.0342\n",
            "Epoch 5, Batch 780: Loss = 1.1205, Acc = 66.17%, Spikes = 0.0359\n",
            "Epoch 5, Batch 790: Loss = 1.0865, Acc = 66.21%, Spikes = 0.0372\n",
            "Epoch 5, Batch 800: Loss = 1.0777, Acc = 66.28%, Spikes = 0.0374\n",
            "Epoch 5, Batch 810: Loss = 1.1477, Acc = 66.31%, Spikes = 0.0354\n",
            "Epoch 5, Batch 820: Loss = 1.2052, Acc = 66.27%, Spikes = 0.0360\n",
            "Epoch 5, Batch 830: Loss = 1.3602, Acc = 66.31%, Spikes = 0.0337\n",
            "Epoch 5, Batch 840: Loss = 1.2673, Acc = 66.26%, Spikes = 0.0345\n",
            "Epoch 5, Batch 850: Loss = 1.0619, Acc = 66.30%, Spikes = 0.0379\n",
            "Epoch 5, Batch 860: Loss = 1.3218, Acc = 66.34%, Spikes = 0.0364\n",
            "Epoch 5, Batch 870: Loss = 0.9749, Acc = 66.34%, Spikes = 0.0368\n",
            "Epoch 5, Batch 880: Loss = 0.9954, Acc = 66.38%, Spikes = 0.0398\n",
            "Epoch 5, Batch 890: Loss = 1.2811, Acc = 66.41%, Spikes = 0.0365\n",
            "Epoch 5, Batch 900: Loss = 1.2800, Acc = 66.40%, Spikes = 0.0334\n",
            "Epoch 5, Batch 910: Loss = 0.9903, Acc = 66.41%, Spikes = 0.0401\n",
            "Epoch 5, Batch 920: Loss = 1.2769, Acc = 66.46%, Spikes = 0.0332\n",
            "Epoch 5, Batch 930: Loss = 1.2306, Acc = 66.51%, Spikes = 0.0337\n",
            "Epoch 5, Batch 940: Loss = 1.2761, Acc = 66.57%, Spikes = 0.0337\n",
            "Epoch 5, Batch 950: Loss = 0.9499, Acc = 66.57%, Spikes = 0.0363\n",
            "Epoch 5, Batch 960: Loss = 1.2689, Acc = 66.62%, Spikes = 0.0330\n",
            "Epoch 5, Batch 970: Loss = 1.2137, Acc = 66.67%, Spikes = 0.0340\n",
            "Epoch 5, Batch 980: Loss = 1.0407, Acc = 66.71%, Spikes = 0.0359\n",
            "Epoch 5, Batch 990: Loss = 1.1947, Acc = 66.73%, Spikes = 0.0356\n",
            "Epoch 5, Batch 1000: Loss = 0.9090, Acc = 66.82%, Spikes = 0.0413\n",
            "Epoch 5, Batch 1010: Loss = 1.0445, Acc = 66.85%, Spikes = 0.0380\n",
            "Epoch 5, Batch 1020: Loss = 1.2596, Acc = 66.83%, Spikes = 0.0342\n",
            "Epoch 5, Batch 1030: Loss = 1.1168, Acc = 66.87%, Spikes = 0.0371\n",
            "Epoch 5, Batch 1040: Loss = 1.2165, Acc = 66.92%, Spikes = 0.0369\n",
            "Epoch 5, Batch 1050: Loss = 1.1939, Acc = 66.84%, Spikes = 0.0349\n",
            "Epoch 5, Batch 1060: Loss = 1.1623, Acc = 66.82%, Spikes = 0.0362\n",
            "Epoch 5, Batch 1070: Loss = 1.1027, Acc = 66.84%, Spikes = 0.0366\n",
            "Epoch 5, Batch 1080: Loss = 1.2044, Acc = 66.82%, Spikes = 0.0375\n",
            "Epoch 5, Batch 1090: Loss = 1.0192, Acc = 66.82%, Spikes = 0.0402\n",
            "Epoch 5, Batch 1100: Loss = 1.0020, Acc = 66.85%, Spikes = 0.0399\n",
            "Epoch 5, Batch 1110: Loss = 1.2235, Acc = 66.83%, Spikes = 0.0367\n",
            "Epoch 5, Batch 1120: Loss = 1.0354, Acc = 66.85%, Spikes = 0.0399\n",
            "Epoch 5, Batch 1130: Loss = 1.1061, Acc = 66.88%, Spikes = 0.0380\n",
            "Epoch 5, Batch 1140: Loss = 0.9597, Acc = 66.90%, Spikes = 0.0363\n",
            "Epoch 5, Batch 1150: Loss = 1.1699, Acc = 66.89%, Spikes = 0.0364\n",
            "Epoch 5, Batch 1160: Loss = 0.9773, Acc = 66.87%, Spikes = 0.0384\n",
            "Epoch 5, Batch 1170: Loss = 1.3030, Acc = 66.84%, Spikes = 0.0358\n",
            "Epoch 5, Batch 1180: Loss = 1.2370, Acc = 66.86%, Spikes = 0.0394\n",
            "Epoch 5, Batch 1190: Loss = 1.1848, Acc = 66.85%, Spikes = 0.0379\n",
            "Epoch 5, Batch 1200: Loss = 1.0453, Acc = 66.87%, Spikes = 0.0386\n",
            "Epoch 5, Batch 1210: Loss = 1.0902, Acc = 66.87%, Spikes = 0.0374\n",
            "Epoch 5, Batch 1220: Loss = 1.1312, Acc = 66.86%, Spikes = 0.0394\n",
            "Epoch 5, Batch 1230: Loss = 1.3539, Acc = 66.83%, Spikes = 0.0367\n",
            "Epoch 5, Batch 1240: Loss = 1.0876, Acc = 66.84%, Spikes = 0.0391\n",
            "Epoch 5, Batch 1250: Loss = 1.1658, Acc = 66.87%, Spikes = 0.0351\n",
            "Epoch 5, Batch 1260: Loss = 1.0506, Acc = 66.90%, Spikes = 0.0392\n",
            "Epoch 5, Batch 1270: Loss = 1.3207, Acc = 66.86%, Spikes = 0.0342\n",
            "Epoch 5, Batch 1280: Loss = 1.1071, Acc = 66.88%, Spikes = 0.0355\n",
            "Epoch 5, Batch 1290: Loss = 1.1095, Acc = 66.86%, Spikes = 0.0365\n",
            "Epoch 5, Batch 1300: Loss = 1.3905, Acc = 66.86%, Spikes = 0.0307\n",
            "Epoch 5, Batch 1310: Loss = 1.2806, Acc = 66.85%, Spikes = 0.0352\n",
            "Epoch 5, Batch 1320: Loss = 0.9188, Acc = 66.82%, Spikes = 0.0371\n",
            "Epoch 5, Batch 1330: Loss = 1.2946, Acc = 66.83%, Spikes = 0.0369\n",
            "Epoch 5, Batch 1340: Loss = 0.9929, Acc = 66.86%, Spikes = 0.0409\n",
            "Epoch 5, Batch 1350: Loss = 1.2949, Acc = 66.84%, Spikes = 0.0348\n",
            "Epoch 5, Batch 1360: Loss = 1.2560, Acc = 66.87%, Spikes = 0.0361\n",
            "Epoch 5, Batch 1370: Loss = 1.2222, Acc = 66.90%, Spikes = 0.0338\n",
            "Epoch 5, Batch 1380: Loss = 1.2287, Acc = 66.91%, Spikes = 0.0362\n",
            "Epoch 5, Batch 1390: Loss = 1.0836, Acc = 66.90%, Spikes = 0.0376\n",
            "Epoch 5, Batch 1400: Loss = 0.8725, Acc = 66.95%, Spikes = 0.0397\n",
            "Epoch 5, Batch 1410: Loss = 0.9847, Acc = 66.96%, Spikes = 0.0397\n",
            "Epoch 5, Batch 1420: Loss = 1.2588, Acc = 66.95%, Spikes = 0.0351\n",
            "Epoch 5, Batch 1430: Loss = 1.2669, Acc = 66.94%, Spikes = 0.0348\n",
            "Epoch 5, Batch 1440: Loss = 1.4224, Acc = 66.91%, Spikes = 0.0341\n",
            "Epoch 5, Batch 1450: Loss = 1.0058, Acc = 66.90%, Spikes = 0.0360\n",
            "Epoch 5, Batch 1460: Loss = 1.1602, Acc = 66.90%, Spikes = 0.0371\n",
            "Epoch 5, Batch 1470: Loss = 1.1905, Acc = 66.89%, Spikes = 0.0382\n",
            "Epoch 5, Batch 1480: Loss = 1.0506, Acc = 66.87%, Spikes = 0.0373\n",
            "Epoch 5, Batch 1490: Loss = 1.0954, Acc = 66.88%, Spikes = 0.0357\n",
            "Epoch 5, Batch 1500: Loss = 0.8459, Acc = 66.88%, Spikes = 0.0417\n",
            "Epoch 5, Batch 1510: Loss = 1.1278, Acc = 66.91%, Spikes = 0.0391\n",
            "Epoch 5, Batch 1520: Loss = 1.1233, Acc = 66.92%, Spikes = 0.0396\n",
            "Epoch 5, Batch 1530: Loss = 1.0046, Acc = 66.94%, Spikes = 0.0369\n",
            "Epoch 5, Batch 1540: Loss = 1.2071, Acc = 66.95%, Spikes = 0.0383\n",
            "Epoch 5, Batch 1550: Loss = 1.1113, Acc = 66.96%, Spikes = 0.0376\n",
            "Epoch 5, Batch 1560: Loss = 1.2017, Acc = 66.97%, Spikes = 0.0352\n",
            "Epoch 5, Batch 1570: Loss = 1.0046, Acc = 66.99%, Spikes = 0.0379\n",
            "Epoch 5, Batch 1580: Loss = 1.1416, Acc = 66.97%, Spikes = 0.0325\n",
            "Epoch 5, Batch 1590: Loss = 1.1838, Acc = 66.96%, Spikes = 0.0375\n",
            "Epoch 5, Batch 1600: Loss = 0.9185, Acc = 66.95%, Spikes = 0.0391\n",
            "Epoch 5, Batch 1610: Loss = 1.0683, Acc = 66.97%, Spikes = 0.0374\n",
            "Epoch 5, Batch 1620: Loss = 1.0778, Acc = 66.96%, Spikes = 0.0403\n",
            "Epoch 5, Batch 1630: Loss = 0.9965, Acc = 67.01%, Spikes = 0.0377\n",
            "Epoch 5, Batch 1640: Loss = 1.1129, Acc = 66.98%, Spikes = 0.0376\n",
            "Epoch 5, Batch 1650: Loss = 1.2812, Acc = 67.00%, Spikes = 0.0358\n",
            "Epoch 5, Batch 1660: Loss = 1.2859, Acc = 67.00%, Spikes = 0.0377\n",
            "Epoch 5, Batch 1670: Loss = 1.0820, Acc = 66.99%, Spikes = 0.0392\n",
            "Epoch 5, Batch 1680: Loss = 1.4011, Acc = 67.00%, Spikes = 0.0355\n",
            "Epoch 5, Batch 1690: Loss = 1.3495, Acc = 67.00%, Spikes = 0.0386\n",
            "Epoch 5, Batch 1700: Loss = 1.1569, Acc = 66.98%, Spikes = 0.0396\n",
            "Epoch 5, Batch 1710: Loss = 0.9334, Acc = 66.98%, Spikes = 0.0374\n",
            "Epoch 5, Batch 1720: Loss = 1.2515, Acc = 66.99%, Spikes = 0.0353\n",
            "Epoch 5, Batch 1730: Loss = 0.9077, Acc = 66.97%, Spikes = 0.0369\n",
            "Epoch 5, Batch 1740: Loss = 1.0822, Acc = 66.98%, Spikes = 0.0378\n",
            "Epoch 5, Batch 1750: Loss = 0.9793, Acc = 67.00%, Spikes = 0.0368\n",
            "Epoch 5, Batch 1760: Loss = 0.9303, Acc = 67.01%, Spikes = 0.0390\n",
            "Epoch 5, Batch 1770: Loss = 1.1909, Acc = 67.02%, Spikes = 0.0375\n",
            "Epoch 5, Batch 1780: Loss = 1.2233, Acc = 67.03%, Spikes = 0.0392\n",
            "Epoch 5, Batch 1790: Loss = 1.2593, Acc = 67.01%, Spikes = 0.0386\n",
            "Epoch 5, Batch 1800: Loss = 1.1555, Acc = 67.03%, Spikes = 0.0390\n",
            "Epoch 5, Batch 1810: Loss = 1.1371, Acc = 67.02%, Spikes = 0.0401\n",
            "Epoch 5, Batch 1820: Loss = 0.8590, Acc = 67.05%, Spikes = 0.0408\n",
            "Epoch 5, Batch 1830: Loss = 1.0113, Acc = 67.06%, Spikes = 0.0403\n",
            "Epoch 5, Batch 1840: Loss = 1.1220, Acc = 67.05%, Spikes = 0.0398\n",
            "Epoch 5, Batch 1850: Loss = 1.0068, Acc = 67.02%, Spikes = 0.0391\n",
            "Epoch 5, Batch 1860: Loss = 1.2514, Acc = 67.04%, Spikes = 0.0346\n",
            "Epoch 5, Batch 1870: Loss = 1.2974, Acc = 67.05%, Spikes = 0.0354\n",
            "Epoch 5/15:\n",
            "Train Loss: 1.1877 | Train Acc: 67.05% | Train Spikes: 0.0365\n",
            "Test Acc: 69.10% | Test Spikes: 0.0387\n",
            "------------------------------------------------------------\n",
            "Epoch 6, Batch 0: Loss = 1.0270, Acc = 75.00%, Spikes = 0.0376\n",
            "Epoch 6, Batch 10: Loss = 1.2023, Acc = 71.88%, Spikes = 0.0382\n",
            "Epoch 6, Batch 20: Loss = 0.9114, Acc = 70.09%, Spikes = 0.0387\n",
            "Epoch 6, Batch 30: Loss = 1.2770, Acc = 69.76%, Spikes = 0.0363\n",
            "Epoch 6, Batch 40: Loss = 1.1571, Acc = 69.59%, Spikes = 0.0403\n",
            "Epoch 6, Batch 50: Loss = 1.0393, Acc = 68.81%, Spikes = 0.0387\n",
            "Epoch 6, Batch 60: Loss = 1.2405, Acc = 68.55%, Spikes = 0.0333\n",
            "Epoch 6, Batch 70: Loss = 1.0682, Acc = 68.31%, Spikes = 0.0367\n",
            "Epoch 6, Batch 80: Loss = 1.0876, Acc = 68.90%, Spikes = 0.0368\n",
            "Epoch 6, Batch 90: Loss = 1.1605, Acc = 68.58%, Spikes = 0.0409\n",
            "Epoch 6, Batch 100: Loss = 1.1064, Acc = 68.44%, Spikes = 0.0362\n",
            "Epoch 6, Batch 110: Loss = 1.2051, Acc = 68.52%, Spikes = 0.0355\n",
            "Epoch 6, Batch 120: Loss = 0.9730, Acc = 68.29%, Spikes = 0.0407\n",
            "Epoch 6, Batch 130: Loss = 1.0865, Acc = 68.03%, Spikes = 0.0377\n",
            "Epoch 6, Batch 140: Loss = 1.3072, Acc = 67.69%, Spikes = 0.0360\n",
            "Epoch 6, Batch 150: Loss = 1.4144, Acc = 67.74%, Spikes = 0.0366\n",
            "Epoch 6, Batch 160: Loss = 1.2295, Acc = 67.76%, Spikes = 0.0371\n",
            "Epoch 6, Batch 170: Loss = 1.1706, Acc = 67.65%, Spikes = 0.0380\n",
            "Epoch 6, Batch 180: Loss = 1.1817, Acc = 67.61%, Spikes = 0.0400\n",
            "Epoch 6, Batch 190: Loss = 1.0708, Acc = 67.82%, Spikes = 0.0418\n",
            "Epoch 6, Batch 200: Loss = 1.3820, Acc = 67.96%, Spikes = 0.0380\n",
            "Epoch 6, Batch 210: Loss = 1.1188, Acc = 67.79%, Spikes = 0.0371\n",
            "Epoch 6, Batch 220: Loss = 1.0938, Acc = 67.82%, Spikes = 0.0367\n",
            "Epoch 6, Batch 230: Loss = 1.2250, Acc = 67.86%, Spikes = 0.0367\n",
            "Epoch 6, Batch 240: Loss = 1.1012, Acc = 68.01%, Spikes = 0.0407\n",
            "Epoch 6, Batch 250: Loss = 1.1039, Acc = 68.18%, Spikes = 0.0380\n",
            "Epoch 6, Batch 260: Loss = 1.0839, Acc = 68.14%, Spikes = 0.0382\n",
            "Epoch 6, Batch 270: Loss = 1.1839, Acc = 68.06%, Spikes = 0.0374\n",
            "Epoch 6, Batch 280: Loss = 1.2209, Acc = 67.98%, Spikes = 0.0367\n",
            "Epoch 6, Batch 290: Loss = 1.3591, Acc = 67.94%, Spikes = 0.0408\n",
            "Epoch 6, Batch 300: Loss = 0.9817, Acc = 67.99%, Spikes = 0.0363\n",
            "Epoch 6, Batch 310: Loss = 1.3041, Acc = 68.04%, Spikes = 0.0364\n",
            "Epoch 6, Batch 320: Loss = 1.0915, Acc = 68.06%, Spikes = 0.0414\n",
            "Epoch 6, Batch 330: Loss = 1.1784, Acc = 67.99%, Spikes = 0.0407\n",
            "Epoch 6, Batch 340: Loss = 1.0701, Acc = 67.96%, Spikes = 0.0369\n",
            "Epoch 6, Batch 350: Loss = 1.0784, Acc = 68.03%, Spikes = 0.0391\n",
            "Epoch 6, Batch 360: Loss = 0.8998, Acc = 68.01%, Spikes = 0.0417\n",
            "Epoch 6, Batch 370: Loss = 1.2092, Acc = 68.03%, Spikes = 0.0401\n",
            "Epoch 6, Batch 380: Loss = 1.2974, Acc = 67.98%, Spikes = 0.0408\n",
            "Epoch 6, Batch 390: Loss = 1.2177, Acc = 68.02%, Spikes = 0.0370\n",
            "Epoch 6, Batch 400: Loss = 1.0723, Acc = 68.05%, Spikes = 0.0380\n",
            "Epoch 6, Batch 410: Loss = 1.2558, Acc = 68.05%, Spikes = 0.0382\n",
            "Epoch 6, Batch 420: Loss = 1.2075, Acc = 68.09%, Spikes = 0.0378\n",
            "Epoch 6, Batch 430: Loss = 1.0379, Acc = 68.12%, Spikes = 0.0379\n",
            "Epoch 6, Batch 440: Loss = 1.0992, Acc = 68.15%, Spikes = 0.0369\n",
            "Epoch 6, Batch 450: Loss = 1.0771, Acc = 68.06%, Spikes = 0.0431\n",
            "Epoch 6, Batch 460: Loss = 1.1572, Acc = 68.01%, Spikes = 0.0379\n",
            "Epoch 6, Batch 470: Loss = 1.0204, Acc = 67.97%, Spikes = 0.0407\n",
            "Epoch 6, Batch 480: Loss = 1.0046, Acc = 68.02%, Spikes = 0.0406\n",
            "Epoch 6, Batch 490: Loss = 1.2916, Acc = 68.01%, Spikes = 0.0410\n",
            "Epoch 6, Batch 500: Loss = 0.9550, Acc = 68.05%, Spikes = 0.0421\n",
            "Epoch 6, Batch 510: Loss = 0.9361, Acc = 68.06%, Spikes = 0.0383\n",
            "Epoch 6, Batch 520: Loss = 0.8859, Acc = 68.14%, Spikes = 0.0372\n",
            "Epoch 6, Batch 530: Loss = 1.1590, Acc = 68.20%, Spikes = 0.0369\n",
            "Epoch 6, Batch 540: Loss = 1.0398, Acc = 68.17%, Spikes = 0.0375\n",
            "Epoch 6, Batch 550: Loss = 1.3560, Acc = 68.11%, Spikes = 0.0376\n",
            "Epoch 6, Batch 560: Loss = 0.9102, Acc = 68.15%, Spikes = 0.0421\n",
            "Epoch 6, Batch 570: Loss = 1.1197, Acc = 68.19%, Spikes = 0.0404\n",
            "Epoch 6, Batch 580: Loss = 0.7713, Acc = 68.14%, Spikes = 0.0421\n",
            "Epoch 6, Batch 590: Loss = 1.1888, Acc = 68.13%, Spikes = 0.0397\n",
            "Epoch 6, Batch 600: Loss = 1.1300, Acc = 68.17%, Spikes = 0.0357\n",
            "Epoch 6, Batch 610: Loss = 1.2015, Acc = 68.14%, Spikes = 0.0367\n",
            "Epoch 6, Batch 620: Loss = 0.8847, Acc = 68.14%, Spikes = 0.0455\n",
            "Epoch 6, Batch 630: Loss = 0.7968, Acc = 68.23%, Spikes = 0.0406\n",
            "Epoch 6, Batch 640: Loss = 1.1475, Acc = 68.29%, Spikes = 0.0350\n",
            "Epoch 6, Batch 650: Loss = 0.9336, Acc = 68.34%, Spikes = 0.0371\n",
            "Epoch 6, Batch 660: Loss = 1.1175, Acc = 68.39%, Spikes = 0.0368\n",
            "Epoch 6, Batch 670: Loss = 1.1309, Acc = 68.36%, Spikes = 0.0373\n",
            "Epoch 6, Batch 680: Loss = 1.0945, Acc = 68.39%, Spikes = 0.0375\n",
            "Epoch 6, Batch 690: Loss = 1.0146, Acc = 68.49%, Spikes = 0.0387\n",
            "Epoch 6, Batch 700: Loss = 1.1567, Acc = 68.46%, Spikes = 0.0351\n",
            "Epoch 6, Batch 710: Loss = 1.1184, Acc = 68.47%, Spikes = 0.0379\n",
            "Epoch 6, Batch 720: Loss = 1.1380, Acc = 68.46%, Spikes = 0.0386\n",
            "Epoch 6, Batch 730: Loss = 1.1418, Acc = 68.40%, Spikes = 0.0361\n",
            "Epoch 6, Batch 740: Loss = 1.0934, Acc = 68.40%, Spikes = 0.0375\n",
            "Epoch 6, Batch 750: Loss = 1.1292, Acc = 68.42%, Spikes = 0.0390\n",
            "Epoch 6, Batch 760: Loss = 1.0911, Acc = 68.42%, Spikes = 0.0385\n",
            "Epoch 6, Batch 770: Loss = 0.9345, Acc = 68.38%, Spikes = 0.0375\n",
            "Epoch 6, Batch 780: Loss = 0.9386, Acc = 68.32%, Spikes = 0.0410\n",
            "Epoch 6, Batch 790: Loss = 1.0529, Acc = 68.33%, Spikes = 0.0394\n",
            "Epoch 6, Batch 800: Loss = 1.2332, Acc = 68.37%, Spikes = 0.0351\n",
            "Epoch 6, Batch 810: Loss = 1.0445, Acc = 68.38%, Spikes = 0.0389\n",
            "Epoch 6, Batch 820: Loss = 1.0840, Acc = 68.38%, Spikes = 0.0357\n",
            "Epoch 6, Batch 830: Loss = 1.1921, Acc = 68.33%, Spikes = 0.0360\n",
            "Epoch 6, Batch 840: Loss = 1.0091, Acc = 68.34%, Spikes = 0.0396\n",
            "Epoch 6, Batch 850: Loss = 1.2097, Acc = 68.36%, Spikes = 0.0391\n",
            "Epoch 6, Batch 860: Loss = 0.9664, Acc = 68.36%, Spikes = 0.0423\n",
            "Epoch 6, Batch 870: Loss = 0.8153, Acc = 68.44%, Spikes = 0.0429\n",
            "Epoch 6, Batch 880: Loss = 1.1253, Acc = 68.47%, Spikes = 0.0385\n",
            "Epoch 6, Batch 890: Loss = 0.8611, Acc = 68.53%, Spikes = 0.0416\n",
            "Epoch 6, Batch 900: Loss = 0.8733, Acc = 68.51%, Spikes = 0.0430\n",
            "Epoch 6, Batch 910: Loss = 0.8321, Acc = 68.59%, Spikes = 0.0445\n",
            "Epoch 6, Batch 920: Loss = 1.1593, Acc = 68.61%, Spikes = 0.0389\n",
            "Epoch 6, Batch 930: Loss = 0.9845, Acc = 68.62%, Spikes = 0.0396\n",
            "Epoch 6, Batch 940: Loss = 1.1023, Acc = 68.68%, Spikes = 0.0357\n",
            "Epoch 6, Batch 950: Loss = 0.9299, Acc = 68.68%, Spikes = 0.0379\n",
            "Epoch 6, Batch 960: Loss = 0.9975, Acc = 68.68%, Spikes = 0.0378\n",
            "Epoch 6, Batch 970: Loss = 1.1994, Acc = 68.72%, Spikes = 0.0377\n",
            "Epoch 6, Batch 980: Loss = 0.9841, Acc = 68.73%, Spikes = 0.0429\n",
            "Epoch 6, Batch 990: Loss = 1.1607, Acc = 68.73%, Spikes = 0.0395\n",
            "Epoch 6, Batch 1000: Loss = 1.3736, Acc = 68.69%, Spikes = 0.0414\n",
            "Epoch 6, Batch 1010: Loss = 0.9049, Acc = 68.70%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1020: Loss = 1.1185, Acc = 68.70%, Spikes = 0.0370\n",
            "Epoch 6, Batch 1030: Loss = 0.8215, Acc = 68.72%, Spikes = 0.0393\n",
            "Epoch 6, Batch 1040: Loss = 1.0212, Acc = 68.69%, Spikes = 0.0400\n",
            "Epoch 6, Batch 1050: Loss = 1.0518, Acc = 68.66%, Spikes = 0.0401\n",
            "Epoch 6, Batch 1060: Loss = 1.0574, Acc = 68.71%, Spikes = 0.0398\n",
            "Epoch 6, Batch 1070: Loss = 0.9154, Acc = 68.74%, Spikes = 0.0388\n",
            "Epoch 6, Batch 1080: Loss = 0.9500, Acc = 68.76%, Spikes = 0.0385\n",
            "Epoch 6, Batch 1090: Loss = 0.9618, Acc = 68.76%, Spikes = 0.0385\n",
            "Epoch 6, Batch 1100: Loss = 1.0104, Acc = 68.75%, Spikes = 0.0393\n",
            "Epoch 6, Batch 1110: Loss = 1.3021, Acc = 68.75%, Spikes = 0.0398\n",
            "Epoch 6, Batch 1120: Loss = 0.9285, Acc = 68.73%, Spikes = 0.0407\n",
            "Epoch 6, Batch 1130: Loss = 1.0961, Acc = 68.74%, Spikes = 0.0372\n",
            "Epoch 6, Batch 1140: Loss = 0.9981, Acc = 68.71%, Spikes = 0.0407\n",
            "Epoch 6, Batch 1150: Loss = 1.0846, Acc = 68.71%, Spikes = 0.0406\n",
            "Epoch 6, Batch 1160: Loss = 1.1090, Acc = 68.72%, Spikes = 0.0374\n",
            "Epoch 6, Batch 1170: Loss = 1.1183, Acc = 68.72%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1180: Loss = 0.9360, Acc = 68.70%, Spikes = 0.0407\n",
            "Epoch 6, Batch 1190: Loss = 0.7537, Acc = 68.74%, Spikes = 0.0411\n",
            "Epoch 6, Batch 1200: Loss = 1.0164, Acc = 68.80%, Spikes = 0.0422\n",
            "Epoch 6, Batch 1210: Loss = 1.2659, Acc = 68.82%, Spikes = 0.0380\n",
            "Epoch 6, Batch 1220: Loss = 1.1240, Acc = 68.81%, Spikes = 0.0430\n",
            "Epoch 6, Batch 1230: Loss = 0.8437, Acc = 68.82%, Spikes = 0.0439\n",
            "Epoch 6, Batch 1240: Loss = 1.2131, Acc = 68.81%, Spikes = 0.0354\n",
            "Epoch 6, Batch 1250: Loss = 0.9786, Acc = 68.81%, Spikes = 0.0387\n",
            "Epoch 6, Batch 1260: Loss = 1.1711, Acc = 68.80%, Spikes = 0.0405\n",
            "Epoch 6, Batch 1270: Loss = 1.1419, Acc = 68.81%, Spikes = 0.0389\n",
            "Epoch 6, Batch 1280: Loss = 0.9787, Acc = 68.82%, Spikes = 0.0426\n",
            "Epoch 6, Batch 1290: Loss = 1.2868, Acc = 68.82%, Spikes = 0.0372\n",
            "Epoch 6, Batch 1300: Loss = 0.8952, Acc = 68.86%, Spikes = 0.0417\n",
            "Epoch 6, Batch 1310: Loss = 1.2495, Acc = 68.81%, Spikes = 0.0357\n",
            "Epoch 6, Batch 1320: Loss = 1.1659, Acc = 68.83%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1330: Loss = 0.9695, Acc = 68.83%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1340: Loss = 0.9346, Acc = 68.84%, Spikes = 0.0422\n",
            "Epoch 6, Batch 1350: Loss = 1.0123, Acc = 68.83%, Spikes = 0.0415\n",
            "Epoch 6, Batch 1360: Loss = 1.2984, Acc = 68.84%, Spikes = 0.0396\n",
            "Epoch 6, Batch 1370: Loss = 1.2398, Acc = 68.83%, Spikes = 0.0361\n",
            "Epoch 6, Batch 1380: Loss = 0.9499, Acc = 68.83%, Spikes = 0.0403\n",
            "Epoch 6, Batch 1390: Loss = 0.8933, Acc = 68.83%, Spikes = 0.0436\n",
            "Epoch 6, Batch 1400: Loss = 1.2455, Acc = 68.83%, Spikes = 0.0367\n",
            "Epoch 6, Batch 1410: Loss = 0.8905, Acc = 68.88%, Spikes = 0.0380\n",
            "Epoch 6, Batch 1420: Loss = 0.9381, Acc = 68.85%, Spikes = 0.0404\n",
            "Epoch 6, Batch 1430: Loss = 1.1238, Acc = 68.82%, Spikes = 0.0395\n",
            "Epoch 6, Batch 1440: Loss = 1.1187, Acc = 68.80%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1450: Loss = 0.8553, Acc = 68.83%, Spikes = 0.0417\n",
            "Epoch 6, Batch 1460: Loss = 0.9306, Acc = 68.83%, Spikes = 0.0413\n",
            "Epoch 6, Batch 1470: Loss = 1.0369, Acc = 68.82%, Spikes = 0.0406\n",
            "Epoch 6, Batch 1480: Loss = 0.9574, Acc = 68.84%, Spikes = 0.0410\n",
            "Epoch 6, Batch 1490: Loss = 1.4614, Acc = 68.83%, Spikes = 0.0381\n",
            "Epoch 6, Batch 1500: Loss = 1.0524, Acc = 68.85%, Spikes = 0.0388\n",
            "Epoch 6, Batch 1510: Loss = 1.1817, Acc = 68.87%, Spikes = 0.0395\n",
            "Epoch 6, Batch 1520: Loss = 0.9480, Acc = 68.89%, Spikes = 0.0399\n",
            "Epoch 6, Batch 1530: Loss = 0.9995, Acc = 68.92%, Spikes = 0.0412\n",
            "Epoch 6, Batch 1540: Loss = 0.8790, Acc = 68.96%, Spikes = 0.0386\n",
            "Epoch 6, Batch 1550: Loss = 1.0492, Acc = 68.99%, Spikes = 0.0393\n",
            "Epoch 6, Batch 1560: Loss = 1.1303, Acc = 68.99%, Spikes = 0.0375\n",
            "Epoch 6, Batch 1570: Loss = 0.9101, Acc = 69.02%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1580: Loss = 0.7623, Acc = 69.04%, Spikes = 0.0459\n",
            "Epoch 6, Batch 1590: Loss = 0.9639, Acc = 69.06%, Spikes = 0.0377\n",
            "Epoch 6, Batch 1600: Loss = 0.9457, Acc = 69.07%, Spikes = 0.0423\n",
            "Epoch 6, Batch 1610: Loss = 1.1276, Acc = 69.06%, Spikes = 0.0376\n",
            "Epoch 6, Batch 1620: Loss = 1.0539, Acc = 69.07%, Spikes = 0.0393\n",
            "Epoch 6, Batch 1630: Loss = 0.9582, Acc = 69.08%, Spikes = 0.0368\n",
            "Epoch 6, Batch 1640: Loss = 0.9777, Acc = 69.10%, Spikes = 0.0410\n",
            "Epoch 6, Batch 1650: Loss = 0.8931, Acc = 69.09%, Spikes = 0.0379\n",
            "Epoch 6, Batch 1660: Loss = 1.2488, Acc = 69.09%, Spikes = 0.0427\n",
            "Epoch 6, Batch 1670: Loss = 0.9013, Acc = 69.10%, Spikes = 0.0382\n",
            "Epoch 6, Batch 1680: Loss = 1.0328, Acc = 69.10%, Spikes = 0.0427\n",
            "Epoch 6, Batch 1690: Loss = 0.8372, Acc = 69.11%, Spikes = 0.0414\n",
            "Epoch 6, Batch 1700: Loss = 1.1504, Acc = 69.09%, Spikes = 0.0392\n",
            "Epoch 6, Batch 1710: Loss = 1.1181, Acc = 69.08%, Spikes = 0.0426\n",
            "Epoch 6, Batch 1720: Loss = 1.3499, Acc = 69.09%, Spikes = 0.0374\n",
            "Epoch 6, Batch 1730: Loss = 1.1906, Acc = 69.07%, Spikes = 0.0368\n",
            "Epoch 6, Batch 1740: Loss = 0.8643, Acc = 69.06%, Spikes = 0.0419\n",
            "Epoch 6, Batch 1750: Loss = 1.1530, Acc = 69.09%, Spikes = 0.0394\n",
            "Epoch 6, Batch 1760: Loss = 0.8545, Acc = 69.12%, Spikes = 0.0419\n",
            "Epoch 6, Batch 1770: Loss = 1.0676, Acc = 69.12%, Spikes = 0.0437\n",
            "Epoch 6, Batch 1780: Loss = 0.9498, Acc = 69.10%, Spikes = 0.0402\n",
            "Epoch 6, Batch 1790: Loss = 1.1515, Acc = 69.10%, Spikes = 0.0395\n",
            "Epoch 6, Batch 1800: Loss = 1.2411, Acc = 69.09%, Spikes = 0.0361\n",
            "Epoch 6, Batch 1810: Loss = 1.1133, Acc = 69.10%, Spikes = 0.0376\n",
            "Epoch 6, Batch 1820: Loss = 1.0102, Acc = 69.08%, Spikes = 0.0409\n",
            "Epoch 6, Batch 1830: Loss = 0.9965, Acc = 69.11%, Spikes = 0.0441\n",
            "Epoch 6, Batch 1840: Loss = 1.0107, Acc = 69.12%, Spikes = 0.0389\n",
            "Epoch 6, Batch 1850: Loss = 1.0130, Acc = 69.14%, Spikes = 0.0424\n",
            "Epoch 6, Batch 1860: Loss = 1.0554, Acc = 69.15%, Spikes = 0.0435\n",
            "Epoch 6, Batch 1870: Loss = 1.1435, Acc = 69.15%, Spikes = 0.0398\n",
            "Epoch 6/15:\n",
            "Train Loss: 1.0691 | Train Acc: 69.13% | Train Spikes: 0.0392\n",
            "Test Acc: 71.13% | Test Spikes: 0.0408\n",
            "------------------------------------------------------------\n",
            "Epoch 7, Batch 0: Loss = 1.0682, Acc = 68.75%, Spikes = 0.0420\n",
            "Epoch 7, Batch 10: Loss = 0.9335, Acc = 73.01%, Spikes = 0.0416\n",
            "Epoch 7, Batch 20: Loss = 0.7741, Acc = 72.92%, Spikes = 0.0413\n",
            "Epoch 7, Batch 30: Loss = 0.7710, Acc = 72.18%, Spikes = 0.0439\n",
            "Epoch 7, Batch 40: Loss = 0.9846, Acc = 71.80%, Spikes = 0.0439\n",
            "Epoch 7, Batch 50: Loss = 0.9833, Acc = 71.26%, Spikes = 0.0400\n",
            "Epoch 7, Batch 60: Loss = 1.1016, Acc = 71.26%, Spikes = 0.0396\n",
            "Epoch 7, Batch 70: Loss = 0.8490, Acc = 71.48%, Spikes = 0.0440\n",
            "Epoch 7, Batch 80: Loss = 0.8383, Acc = 71.41%, Spikes = 0.0420\n",
            "Epoch 7, Batch 90: Loss = 1.1442, Acc = 71.29%, Spikes = 0.0380\n",
            "Epoch 7, Batch 100: Loss = 1.0836, Acc = 71.35%, Spikes = 0.0388\n",
            "Epoch 7, Batch 110: Loss = 0.8930, Acc = 71.26%, Spikes = 0.0412\n",
            "Epoch 7, Batch 120: Loss = 0.9166, Acc = 71.10%, Spikes = 0.0408\n",
            "Epoch 7, Batch 130: Loss = 0.9827, Acc = 71.23%, Spikes = 0.0398\n",
            "Epoch 7, Batch 140: Loss = 0.9882, Acc = 71.12%, Spikes = 0.0415\n",
            "Epoch 7, Batch 150: Loss = 0.9090, Acc = 71.13%, Spikes = 0.0441\n",
            "Epoch 7, Batch 160: Loss = 0.7814, Acc = 71.14%, Spikes = 0.0399\n",
            "Epoch 7, Batch 170: Loss = 0.8314, Acc = 71.09%, Spikes = 0.0418\n",
            "Epoch 7, Batch 180: Loss = 0.9625, Acc = 71.01%, Spikes = 0.0418\n",
            "Epoch 7, Batch 190: Loss = 1.3352, Acc = 70.68%, Spikes = 0.0401\n",
            "Epoch 7, Batch 200: Loss = 0.9167, Acc = 70.82%, Spikes = 0.0402\n",
            "Epoch 7, Batch 210: Loss = 1.1083, Acc = 70.69%, Spikes = 0.0384\n",
            "Epoch 7, Batch 220: Loss = 1.1123, Acc = 70.48%, Spikes = 0.0384\n",
            "Epoch 7, Batch 230: Loss = 1.1730, Acc = 70.56%, Spikes = 0.0382\n",
            "Epoch 7, Batch 240: Loss = 1.4183, Acc = 70.49%, Spikes = 0.0420\n",
            "Epoch 7, Batch 250: Loss = 0.8510, Acc = 70.39%, Spikes = 0.0436\n",
            "Epoch 7, Batch 260: Loss = 1.0309, Acc = 70.35%, Spikes = 0.0390\n",
            "Epoch 7, Batch 270: Loss = 1.0918, Acc = 70.19%, Spikes = 0.0432\n",
            "Epoch 7, Batch 280: Loss = 1.2181, Acc = 70.21%, Spikes = 0.0383\n",
            "Epoch 7, Batch 290: Loss = 1.0044, Acc = 70.27%, Spikes = 0.0407\n",
            "Epoch 7, Batch 300: Loss = 0.8546, Acc = 70.33%, Spikes = 0.0436\n",
            "Epoch 7, Batch 310: Loss = 1.2936, Acc = 70.10%, Spikes = 0.0418\n",
            "Epoch 7, Batch 320: Loss = 1.1110, Acc = 70.05%, Spikes = 0.0412\n",
            "Epoch 7, Batch 330: Loss = 1.0863, Acc = 70.02%, Spikes = 0.0415\n",
            "Epoch 7, Batch 340: Loss = 0.9701, Acc = 69.76%, Spikes = 0.0417\n",
            "Epoch 7, Batch 350: Loss = 0.9144, Acc = 69.71%, Spikes = 0.0415\n",
            "Epoch 7, Batch 360: Loss = 1.1476, Acc = 69.74%, Spikes = 0.0399\n",
            "Epoch 7, Batch 370: Loss = 1.0559, Acc = 69.80%, Spikes = 0.0404\n",
            "Epoch 7, Batch 380: Loss = 0.8794, Acc = 69.82%, Spikes = 0.0411\n",
            "Epoch 7, Batch 390: Loss = 0.9336, Acc = 69.87%, Spikes = 0.0436\n",
            "Epoch 7, Batch 400: Loss = 0.8970, Acc = 69.92%, Spikes = 0.0446\n",
            "Epoch 7, Batch 410: Loss = 0.9992, Acc = 69.75%, Spikes = 0.0403\n",
            "Epoch 7, Batch 420: Loss = 1.0779, Acc = 69.80%, Spikes = 0.0358\n",
            "Epoch 7, Batch 430: Loss = 0.9099, Acc = 69.92%, Spikes = 0.0410\n",
            "Epoch 7, Batch 440: Loss = 0.9013, Acc = 69.88%, Spikes = 0.0455\n",
            "Epoch 7, Batch 450: Loss = 1.0768, Acc = 69.87%, Spikes = 0.0386\n",
            "Epoch 7, Batch 460: Loss = 1.0239, Acc = 69.96%, Spikes = 0.0454\n",
            "Epoch 7, Batch 470: Loss = 0.7785, Acc = 70.02%, Spikes = 0.0406\n",
            "Epoch 7, Batch 480: Loss = 0.8781, Acc = 70.06%, Spikes = 0.0429\n",
            "Epoch 7, Batch 490: Loss = 0.9020, Acc = 70.05%, Spikes = 0.0418\n",
            "Epoch 7, Batch 500: Loss = 1.0434, Acc = 70.05%, Spikes = 0.0409\n",
            "Epoch 7, Batch 510: Loss = 0.8444, Acc = 70.10%, Spikes = 0.0418\n",
            "Epoch 7, Batch 520: Loss = 0.8089, Acc = 70.19%, Spikes = 0.0434\n",
            "Epoch 7, Batch 530: Loss = 1.2702, Acc = 70.18%, Spikes = 0.0367\n",
            "Epoch 7, Batch 540: Loss = 0.8815, Acc = 70.14%, Spikes = 0.0408\n",
            "Epoch 7, Batch 550: Loss = 1.0112, Acc = 70.15%, Spikes = 0.0462\n",
            "Epoch 7, Batch 560: Loss = 1.1140, Acc = 70.14%, Spikes = 0.0387\n",
            "Epoch 7, Batch 570: Loss = 1.0241, Acc = 70.24%, Spikes = 0.0396\n",
            "Epoch 7, Batch 580: Loss = 1.2127, Acc = 70.29%, Spikes = 0.0377\n",
            "Epoch 7, Batch 590: Loss = 1.0156, Acc = 70.35%, Spikes = 0.0403\n",
            "Epoch 7, Batch 600: Loss = 1.1248, Acc = 70.29%, Spikes = 0.0433\n",
            "Epoch 7, Batch 610: Loss = 1.1828, Acc = 70.27%, Spikes = 0.0362\n",
            "Epoch 7, Batch 620: Loss = 1.0325, Acc = 70.30%, Spikes = 0.0385\n",
            "Epoch 7, Batch 630: Loss = 1.0171, Acc = 70.33%, Spikes = 0.0447\n",
            "Epoch 7, Batch 640: Loss = 1.1051, Acc = 70.33%, Spikes = 0.0413\n",
            "Epoch 7, Batch 650: Loss = 1.2318, Acc = 70.32%, Spikes = 0.0376\n",
            "Epoch 7, Batch 660: Loss = 1.0703, Acc = 70.24%, Spikes = 0.0421\n",
            "Epoch 7, Batch 670: Loss = 1.1197, Acc = 70.24%, Spikes = 0.0367\n",
            "Epoch 7, Batch 680: Loss = 1.1060, Acc = 70.22%, Spikes = 0.0438\n",
            "Epoch 7, Batch 690: Loss = 1.0681, Acc = 70.17%, Spikes = 0.0417\n",
            "Epoch 7, Batch 700: Loss = 0.9080, Acc = 70.22%, Spikes = 0.0409\n",
            "Epoch 7, Batch 710: Loss = 1.0648, Acc = 70.20%, Spikes = 0.0406\n",
            "Epoch 7, Batch 720: Loss = 0.9281, Acc = 70.24%, Spikes = 0.0449\n",
            "Epoch 7, Batch 730: Loss = 0.9828, Acc = 70.28%, Spikes = 0.0398\n",
            "Epoch 7, Batch 740: Loss = 1.2372, Acc = 70.29%, Spikes = 0.0401\n",
            "Epoch 7, Batch 750: Loss = 0.8658, Acc = 70.31%, Spikes = 0.0450\n",
            "Epoch 7, Batch 760: Loss = 0.7580, Acc = 70.36%, Spikes = 0.0449\n",
            "Epoch 7, Batch 770: Loss = 1.1508, Acc = 70.33%, Spikes = 0.0454\n",
            "Epoch 7, Batch 780: Loss = 0.9316, Acc = 70.29%, Spikes = 0.0461\n",
            "Epoch 7, Batch 790: Loss = 1.0241, Acc = 70.29%, Spikes = 0.0416\n",
            "Epoch 7, Batch 800: Loss = 1.0527, Acc = 70.27%, Spikes = 0.0382\n",
            "Epoch 7, Batch 810: Loss = 1.1714, Acc = 70.27%, Spikes = 0.0429\n",
            "Epoch 7, Batch 820: Loss = 1.1418, Acc = 70.26%, Spikes = 0.0399\n",
            "Epoch 7, Batch 830: Loss = 1.0410, Acc = 70.25%, Spikes = 0.0409\n",
            "Epoch 7, Batch 840: Loss = 1.0707, Acc = 70.20%, Spikes = 0.0391\n",
            "Epoch 7, Batch 850: Loss = 0.8689, Acc = 70.19%, Spikes = 0.0437\n",
            "Epoch 7, Batch 860: Loss = 0.8632, Acc = 70.19%, Spikes = 0.0424\n",
            "Epoch 7, Batch 870: Loss = 0.9702, Acc = 70.21%, Spikes = 0.0406\n",
            "Epoch 7, Batch 880: Loss = 1.0380, Acc = 70.21%, Spikes = 0.0426\n",
            "Epoch 7, Batch 890: Loss = 0.8450, Acc = 70.26%, Spikes = 0.0404\n",
            "Epoch 7, Batch 900: Loss = 0.8779, Acc = 70.27%, Spikes = 0.0418\n",
            "Epoch 7, Batch 910: Loss = 0.7400, Acc = 70.27%, Spikes = 0.0468\n",
            "Epoch 7, Batch 920: Loss = 0.9322, Acc = 70.25%, Spikes = 0.0386\n",
            "Epoch 7, Batch 930: Loss = 1.2744, Acc = 70.24%, Spikes = 0.0382\n",
            "Epoch 7, Batch 940: Loss = 1.0448, Acc = 70.20%, Spikes = 0.0397\n",
            "Epoch 7, Batch 950: Loss = 0.6539, Acc = 70.19%, Spikes = 0.0447\n",
            "Epoch 7, Batch 960: Loss = 0.7903, Acc = 70.19%, Spikes = 0.0445\n",
            "Epoch 7, Batch 970: Loss = 0.9020, Acc = 70.19%, Spikes = 0.0459\n",
            "Epoch 7, Batch 980: Loss = 0.8332, Acc = 70.21%, Spikes = 0.0444\n",
            "Epoch 7, Batch 990: Loss = 1.3249, Acc = 70.18%, Spikes = 0.0384\n",
            "Epoch 7, Batch 1000: Loss = 1.0624, Acc = 70.19%, Spikes = 0.0430\n",
            "Epoch 7, Batch 1010: Loss = 0.8482, Acc = 70.20%, Spikes = 0.0430\n",
            "Epoch 7, Batch 1020: Loss = 1.0585, Acc = 70.18%, Spikes = 0.0389\n",
            "Epoch 7, Batch 1030: Loss = 0.8996, Acc = 70.20%, Spikes = 0.0434\n",
            "Epoch 7, Batch 1040: Loss = 1.1590, Acc = 70.19%, Spikes = 0.0371\n",
            "Epoch 7, Batch 1050: Loss = 0.9089, Acc = 70.20%, Spikes = 0.0428\n",
            "Epoch 7, Batch 1060: Loss = 0.9809, Acc = 70.23%, Spikes = 0.0385\n",
            "Epoch 7, Batch 1070: Loss = 0.9458, Acc = 70.27%, Spikes = 0.0430\n",
            "Epoch 7, Batch 1080: Loss = 1.0986, Acc = 70.27%, Spikes = 0.0394\n",
            "Epoch 7, Batch 1090: Loss = 0.7560, Acc = 70.29%, Spikes = 0.0446\n",
            "Epoch 7, Batch 1100: Loss = 0.9154, Acc = 70.33%, Spikes = 0.0389\n",
            "Epoch 7, Batch 1110: Loss = 1.0743, Acc = 70.38%, Spikes = 0.0387\n",
            "Epoch 7, Batch 1120: Loss = 1.0750, Acc = 70.37%, Spikes = 0.0404\n",
            "Epoch 7, Batch 1130: Loss = 0.9177, Acc = 70.38%, Spikes = 0.0397\n",
            "Epoch 7, Batch 1140: Loss = 0.8138, Acc = 70.41%, Spikes = 0.0433\n",
            "Epoch 7, Batch 1150: Loss = 0.8934, Acc = 70.39%, Spikes = 0.0445\n",
            "Epoch 7, Batch 1160: Loss = 1.0161, Acc = 70.37%, Spikes = 0.0358\n",
            "Epoch 7, Batch 1170: Loss = 1.0784, Acc = 70.38%, Spikes = 0.0384\n",
            "Epoch 7, Batch 1180: Loss = 1.0287, Acc = 70.35%, Spikes = 0.0430\n",
            "Epoch 7, Batch 1190: Loss = 0.9362, Acc = 70.30%, Spikes = 0.0424\n",
            "Epoch 7, Batch 1200: Loss = 1.0026, Acc = 70.29%, Spikes = 0.0385\n",
            "Epoch 7, Batch 1210: Loss = 1.1554, Acc = 70.29%, Spikes = 0.0449\n",
            "Epoch 7, Batch 1220: Loss = 0.9466, Acc = 70.28%, Spikes = 0.0414\n",
            "Epoch 7, Batch 1230: Loss = 1.3522, Acc = 70.27%, Spikes = 0.0402\n",
            "Epoch 7, Batch 1240: Loss = 0.7896, Acc = 70.31%, Spikes = 0.0461\n",
            "Epoch 7, Batch 1250: Loss = 0.8058, Acc = 70.34%, Spikes = 0.0416\n",
            "Epoch 7, Batch 1260: Loss = 0.7384, Acc = 70.37%, Spikes = 0.0470\n",
            "Epoch 7, Batch 1270: Loss = 0.9230, Acc = 70.36%, Spikes = 0.0435\n",
            "Epoch 7, Batch 1280: Loss = 1.1336, Acc = 70.38%, Spikes = 0.0445\n",
            "Epoch 7, Batch 1290: Loss = 1.0125, Acc = 70.37%, Spikes = 0.0407\n",
            "Epoch 7, Batch 1300: Loss = 0.9619, Acc = 70.35%, Spikes = 0.0433\n",
            "Epoch 7, Batch 1310: Loss = 1.1282, Acc = 70.34%, Spikes = 0.0416\n",
            "Epoch 7, Batch 1320: Loss = 0.8620, Acc = 70.35%, Spikes = 0.0421\n",
            "Epoch 7, Batch 1330: Loss = 1.2439, Acc = 70.36%, Spikes = 0.0443\n",
            "Epoch 7, Batch 1340: Loss = 1.0631, Acc = 70.38%, Spikes = 0.0443\n",
            "Epoch 7, Batch 1350: Loss = 1.0611, Acc = 70.39%, Spikes = 0.0418\n",
            "Epoch 7, Batch 1360: Loss = 0.7270, Acc = 70.38%, Spikes = 0.0444\n",
            "Epoch 7, Batch 1370: Loss = 1.1954, Acc = 70.36%, Spikes = 0.0419\n",
            "Epoch 7, Batch 1380: Loss = 1.1238, Acc = 70.35%, Spikes = 0.0422\n",
            "Epoch 7, Batch 1390: Loss = 1.0781, Acc = 70.35%, Spikes = 0.0439\n",
            "Epoch 7, Batch 1400: Loss = 0.6652, Acc = 70.35%, Spikes = 0.0409\n",
            "Epoch 7, Batch 1410: Loss = 0.7515, Acc = 70.35%, Spikes = 0.0431\n",
            "Epoch 7, Batch 1420: Loss = 1.0318, Acc = 70.37%, Spikes = 0.0422\n",
            "Epoch 7, Batch 1430: Loss = 0.6959, Acc = 70.40%, Spikes = 0.0436\n",
            "Epoch 7, Batch 1440: Loss = 0.9740, Acc = 70.42%, Spikes = 0.0404\n",
            "Epoch 7, Batch 1450: Loss = 1.2557, Acc = 70.41%, Spikes = 0.0390\n",
            "Epoch 7, Batch 1460: Loss = 0.6992, Acc = 70.42%, Spikes = 0.0445\n",
            "Epoch 7, Batch 1470: Loss = 0.7671, Acc = 70.45%, Spikes = 0.0422\n",
            "Epoch 7, Batch 1480: Loss = 0.8188, Acc = 70.50%, Spikes = 0.0449\n",
            "Epoch 7, Batch 1490: Loss = 0.9881, Acc = 70.51%, Spikes = 0.0406\n",
            "Epoch 7, Batch 1500: Loss = 0.8827, Acc = 70.52%, Spikes = 0.0375\n",
            "Epoch 7, Batch 1510: Loss = 0.9856, Acc = 70.50%, Spikes = 0.0415\n",
            "Epoch 7, Batch 1520: Loss = 0.6478, Acc = 70.49%, Spikes = 0.0466\n",
            "Epoch 7, Batch 1530: Loss = 0.9830, Acc = 70.50%, Spikes = 0.0438\n",
            "Epoch 7, Batch 1540: Loss = 1.0279, Acc = 70.52%, Spikes = 0.0459\n",
            "Epoch 7, Batch 1550: Loss = 0.8059, Acc = 70.55%, Spikes = 0.0424\n",
            "Epoch 7, Batch 1560: Loss = 1.1118, Acc = 70.54%, Spikes = 0.0415\n",
            "Epoch 7, Batch 1570: Loss = 0.9661, Acc = 70.54%, Spikes = 0.0399\n",
            "Epoch 7, Batch 1580: Loss = 0.9885, Acc = 70.55%, Spikes = 0.0443\n",
            "Epoch 7, Batch 1590: Loss = 0.9984, Acc = 70.56%, Spikes = 0.0421\n",
            "Epoch 7, Batch 1600: Loss = 0.9008, Acc = 70.56%, Spikes = 0.0405\n",
            "Epoch 7, Batch 1610: Loss = 1.0751, Acc = 70.58%, Spikes = 0.0407\n",
            "Epoch 7, Batch 1620: Loss = 0.8507, Acc = 70.62%, Spikes = 0.0434\n",
            "Epoch 7, Batch 1630: Loss = 1.0541, Acc = 70.63%, Spikes = 0.0423\n",
            "Epoch 7, Batch 1640: Loss = 1.0055, Acc = 70.64%, Spikes = 0.0456\n",
            "Epoch 7, Batch 1650: Loss = 1.1156, Acc = 70.63%, Spikes = 0.0431\n",
            "Epoch 7, Batch 1660: Loss = 0.8686, Acc = 70.63%, Spikes = 0.0431\n",
            "Epoch 7, Batch 1670: Loss = 1.0259, Acc = 70.62%, Spikes = 0.0386\n",
            "Epoch 7, Batch 1680: Loss = 0.9379, Acc = 70.61%, Spikes = 0.0408\n",
            "Epoch 7, Batch 1690: Loss = 0.8581, Acc = 70.60%, Spikes = 0.0414\n",
            "Epoch 7, Batch 1700: Loss = 1.0157, Acc = 70.60%, Spikes = 0.0415\n",
            "Epoch 7, Batch 1710: Loss = 0.8935, Acc = 70.62%, Spikes = 0.0420\n",
            "Epoch 7, Batch 1720: Loss = 0.9811, Acc = 70.61%, Spikes = 0.0401\n",
            "Epoch 7, Batch 1730: Loss = 0.9340, Acc = 70.61%, Spikes = 0.0439\n",
            "Epoch 7, Batch 1740: Loss = 0.9453, Acc = 70.63%, Spikes = 0.0420\n",
            "Epoch 7, Batch 1750: Loss = 0.9446, Acc = 70.63%, Spikes = 0.0403\n",
            "Epoch 7, Batch 1760: Loss = 0.9337, Acc = 70.62%, Spikes = 0.0422\n",
            "Epoch 7, Batch 1770: Loss = 0.8985, Acc = 70.63%, Spikes = 0.0388\n",
            "Epoch 7, Batch 1780: Loss = 0.8796, Acc = 70.65%, Spikes = 0.0380\n",
            "Epoch 7, Batch 1790: Loss = 0.9559, Acc = 70.64%, Spikes = 0.0459\n",
            "Epoch 7, Batch 1800: Loss = 0.8283, Acc = 70.65%, Spikes = 0.0426\n",
            "Epoch 7, Batch 1810: Loss = 0.8514, Acc = 70.66%, Spikes = 0.0412\n",
            "Epoch 7, Batch 1820: Loss = 0.8675, Acc = 70.69%, Spikes = 0.0465\n",
            "Epoch 7, Batch 1830: Loss = 1.0566, Acc = 70.68%, Spikes = 0.0424\n",
            "Epoch 7, Batch 1840: Loss = 0.9338, Acc = 70.70%, Spikes = 0.0424\n",
            "Epoch 7, Batch 1850: Loss = 1.1681, Acc = 70.72%, Spikes = 0.0409\n",
            "Epoch 7, Batch 1860: Loss = 0.8370, Acc = 70.71%, Spikes = 0.0393\n",
            "Epoch 7, Batch 1870: Loss = 1.0634, Acc = 70.72%, Spikes = 0.0424\n",
            "Epoch 7/15:\n",
            "Train Loss: 0.9881 | Train Acc: 70.72% | Train Spikes: 0.0416\n",
            "Test Acc: 71.97% | Test Spikes: 0.0427\n",
            "------------------------------------------------------------\n",
            "Epoch 8, Batch 0: Loss = 1.2694, Acc = 50.00%, Spikes = 0.0410\n",
            "Epoch 8, Batch 10: Loss = 0.9793, Acc = 70.45%, Spikes = 0.0413\n",
            "Epoch 8, Batch 20: Loss = 0.8487, Acc = 71.73%, Spikes = 0.0433\n",
            "Epoch 8, Batch 30: Loss = 0.7947, Acc = 72.98%, Spikes = 0.0461\n",
            "Epoch 8, Batch 40: Loss = 1.1098, Acc = 72.18%, Spikes = 0.0411\n",
            "Epoch 8, Batch 50: Loss = 0.9887, Acc = 72.49%, Spikes = 0.0417\n",
            "Epoch 8, Batch 60: Loss = 0.8729, Acc = 71.93%, Spikes = 0.0425\n",
            "Epoch 8, Batch 70: Loss = 0.8798, Acc = 72.36%, Spikes = 0.0429\n",
            "Epoch 8, Batch 80: Loss = 0.7761, Acc = 72.38%, Spikes = 0.0431\n",
            "Epoch 8, Batch 90: Loss = 0.9592, Acc = 72.39%, Spikes = 0.0410\n",
            "Epoch 8, Batch 100: Loss = 0.8940, Acc = 72.22%, Spikes = 0.0390\n",
            "Epoch 8, Batch 110: Loss = 0.7166, Acc = 72.04%, Spikes = 0.0459\n",
            "Epoch 8, Batch 120: Loss = 1.0148, Acc = 72.03%, Spikes = 0.0441\n",
            "Epoch 8, Batch 130: Loss = 1.0522, Acc = 71.78%, Spikes = 0.0427\n",
            "Epoch 8, Batch 140: Loss = 0.9709, Acc = 71.63%, Spikes = 0.0432\n",
            "Epoch 8, Batch 150: Loss = 1.0850, Acc = 71.79%, Spikes = 0.0385\n",
            "Epoch 8, Batch 160: Loss = 0.9422, Acc = 71.35%, Spikes = 0.0385\n",
            "Epoch 8, Batch 170: Loss = 0.8348, Acc = 71.36%, Spikes = 0.0448\n",
            "Epoch 8, Batch 180: Loss = 1.0293, Acc = 71.25%, Spikes = 0.0425\n",
            "Epoch 8, Batch 190: Loss = 1.0890, Acc = 71.40%, Spikes = 0.0422\n",
            "Epoch 8, Batch 200: Loss = 0.8993, Acc = 71.49%, Spikes = 0.0425\n",
            "Epoch 8, Batch 210: Loss = 0.7371, Acc = 71.45%, Spikes = 0.0455\n",
            "Epoch 8, Batch 220: Loss = 0.9005, Acc = 71.32%, Spikes = 0.0441\n",
            "Epoch 8, Batch 230: Loss = 0.9868, Acc = 71.24%, Spikes = 0.0416\n",
            "Epoch 8, Batch 240: Loss = 1.0873, Acc = 71.23%, Spikes = 0.0399\n",
            "Epoch 8, Batch 250: Loss = 0.8038, Acc = 71.38%, Spikes = 0.0431\n",
            "Epoch 8, Batch 260: Loss = 1.1739, Acc = 71.42%, Spikes = 0.0419\n",
            "Epoch 8, Batch 270: Loss = 0.7540, Acc = 71.43%, Spikes = 0.0440\n",
            "Epoch 8, Batch 280: Loss = 1.3322, Acc = 71.13%, Spikes = 0.0422\n",
            "Epoch 8, Batch 290: Loss = 1.0459, Acc = 71.07%, Spikes = 0.0447\n",
            "Epoch 8, Batch 300: Loss = 0.9645, Acc = 71.03%, Spikes = 0.0426\n",
            "Epoch 8, Batch 310: Loss = 1.2307, Acc = 71.10%, Spikes = 0.0425\n",
            "Epoch 8, Batch 320: Loss = 0.9839, Acc = 71.16%, Spikes = 0.0436\n",
            "Epoch 8, Batch 330: Loss = 1.0963, Acc = 71.11%, Spikes = 0.0393\n",
            "Epoch 8, Batch 340: Loss = 0.9579, Acc = 71.05%, Spikes = 0.0447\n",
            "Epoch 8, Batch 350: Loss = 0.7565, Acc = 71.12%, Spikes = 0.0450\n",
            "Epoch 8, Batch 360: Loss = 0.8902, Acc = 71.13%, Spikes = 0.0406\n",
            "Epoch 8, Batch 370: Loss = 1.0692, Acc = 71.19%, Spikes = 0.0432\n",
            "Epoch 8, Batch 380: Loss = 0.7356, Acc = 71.04%, Spikes = 0.0457\n",
            "Epoch 8, Batch 390: Loss = 0.9758, Acc = 71.16%, Spikes = 0.0451\n",
            "Epoch 8, Batch 400: Loss = 0.7702, Acc = 71.24%, Spikes = 0.0464\n",
            "Epoch 8, Batch 410: Loss = 0.8941, Acc = 71.33%, Spikes = 0.0447\n",
            "Epoch 8, Batch 420: Loss = 1.0346, Acc = 71.34%, Spikes = 0.0451\n",
            "Epoch 8, Batch 430: Loss = 0.8649, Acc = 71.33%, Spikes = 0.0455\n",
            "Epoch 8, Batch 440: Loss = 0.9227, Acc = 71.29%, Spikes = 0.0436\n",
            "Epoch 8, Batch 450: Loss = 0.9455, Acc = 71.17%, Spikes = 0.0390\n",
            "Epoch 8, Batch 460: Loss = 1.0392, Acc = 71.19%, Spikes = 0.0434\n",
            "Epoch 8, Batch 470: Loss = 0.8365, Acc = 71.26%, Spikes = 0.0450\n",
            "Epoch 8, Batch 480: Loss = 0.9481, Acc = 71.28%, Spikes = 0.0429\n",
            "Epoch 8, Batch 490: Loss = 0.9368, Acc = 71.40%, Spikes = 0.0437\n",
            "Epoch 8, Batch 500: Loss = 0.7961, Acc = 71.44%, Spikes = 0.0474\n",
            "Epoch 8, Batch 510: Loss = 1.0889, Acc = 71.41%, Spikes = 0.0409\n",
            "Epoch 8, Batch 520: Loss = 1.0131, Acc = 71.41%, Spikes = 0.0450\n",
            "Epoch 8, Batch 530: Loss = 0.8593, Acc = 71.36%, Spikes = 0.0464\n",
            "Epoch 8, Batch 540: Loss = 0.9249, Acc = 71.34%, Spikes = 0.0441\n",
            "Epoch 8, Batch 550: Loss = 1.0321, Acc = 71.35%, Spikes = 0.0421\n",
            "Epoch 8, Batch 560: Loss = 1.0374, Acc = 71.33%, Spikes = 0.0443\n",
            "Epoch 8, Batch 570: Loss = 0.8359, Acc = 71.42%, Spikes = 0.0458\n",
            "Epoch 8, Batch 580: Loss = 0.9838, Acc = 71.40%, Spikes = 0.0411\n",
            "Epoch 8, Batch 590: Loss = 0.8073, Acc = 71.46%, Spikes = 0.0431\n",
            "Epoch 8, Batch 600: Loss = 0.8531, Acc = 71.40%, Spikes = 0.0467\n",
            "Epoch 8, Batch 610: Loss = 0.9447, Acc = 71.38%, Spikes = 0.0422\n",
            "Epoch 8, Batch 620: Loss = 1.1000, Acc = 71.37%, Spikes = 0.0439\n",
            "Epoch 8, Batch 630: Loss = 0.8890, Acc = 71.46%, Spikes = 0.0425\n",
            "Epoch 8, Batch 640: Loss = 0.8876, Acc = 71.48%, Spikes = 0.0417\n",
            "Epoch 8, Batch 650: Loss = 0.9456, Acc = 71.53%, Spikes = 0.0490\n",
            "Epoch 8, Batch 660: Loss = 1.0854, Acc = 71.57%, Spikes = 0.0414\n",
            "Epoch 8, Batch 670: Loss = 0.9932, Acc = 71.60%, Spikes = 0.0422\n",
            "Epoch 8, Batch 680: Loss = 0.8750, Acc = 71.59%, Spikes = 0.0440\n",
            "Epoch 8, Batch 690: Loss = 0.9999, Acc = 71.62%, Spikes = 0.0424\n",
            "Epoch 8, Batch 700: Loss = 1.1202, Acc = 71.59%, Spikes = 0.0430\n",
            "Epoch 8, Batch 710: Loss = 0.7176, Acc = 71.61%, Spikes = 0.0453\n",
            "Epoch 8, Batch 720: Loss = 0.8203, Acc = 71.60%, Spikes = 0.0447\n",
            "Epoch 8, Batch 730: Loss = 0.7388, Acc = 71.66%, Spikes = 0.0454\n",
            "Epoch 8, Batch 740: Loss = 0.6962, Acc = 71.70%, Spikes = 0.0479\n",
            "Epoch 8, Batch 750: Loss = 0.7945, Acc = 71.74%, Spikes = 0.0417\n",
            "Epoch 8, Batch 760: Loss = 0.8424, Acc = 71.74%, Spikes = 0.0432\n",
            "Epoch 8, Batch 770: Loss = 0.9172, Acc = 71.77%, Spikes = 0.0459\n",
            "Epoch 8, Batch 780: Loss = 1.0930, Acc = 71.77%, Spikes = 0.0437\n",
            "Epoch 8, Batch 790: Loss = 0.9827, Acc = 71.73%, Spikes = 0.0418\n",
            "Epoch 8, Batch 800: Loss = 0.9258, Acc = 71.75%, Spikes = 0.0413\n",
            "Epoch 8, Batch 810: Loss = 1.2604, Acc = 71.71%, Spikes = 0.0426\n",
            "Epoch 8, Batch 820: Loss = 0.9730, Acc = 71.67%, Spikes = 0.0449\n",
            "Epoch 8, Batch 830: Loss = 0.6757, Acc = 71.74%, Spikes = 0.0503\n",
            "Epoch 8, Batch 840: Loss = 0.9081, Acc = 71.73%, Spikes = 0.0462\n",
            "Epoch 8, Batch 850: Loss = 1.0062, Acc = 71.76%, Spikes = 0.0432\n",
            "Epoch 8, Batch 860: Loss = 0.9755, Acc = 71.79%, Spikes = 0.0386\n",
            "Epoch 8, Batch 870: Loss = 1.1777, Acc = 71.74%, Spikes = 0.0404\n",
            "Epoch 8, Batch 880: Loss = 0.8903, Acc = 71.74%, Spikes = 0.0447\n",
            "Epoch 8, Batch 890: Loss = 0.8672, Acc = 71.76%, Spikes = 0.0467\n",
            "Epoch 8, Batch 900: Loss = 0.8798, Acc = 71.76%, Spikes = 0.0438\n",
            "Epoch 8, Batch 910: Loss = 0.8667, Acc = 71.75%, Spikes = 0.0446\n",
            "Epoch 8, Batch 920: Loss = 0.7598, Acc = 71.72%, Spikes = 0.0456\n",
            "Epoch 8, Batch 930: Loss = 1.5461, Acc = 71.65%, Spikes = 0.0410\n",
            "Epoch 8, Batch 940: Loss = 0.8697, Acc = 71.68%, Spikes = 0.0420\n",
            "Epoch 8, Batch 950: Loss = 1.0350, Acc = 71.72%, Spikes = 0.0412\n",
            "Epoch 8, Batch 960: Loss = 1.1431, Acc = 71.71%, Spikes = 0.0466\n",
            "Epoch 8, Batch 970: Loss = 0.8666, Acc = 71.72%, Spikes = 0.0425\n",
            "Epoch 8, Batch 980: Loss = 0.8223, Acc = 71.71%, Spikes = 0.0481\n",
            "Epoch 8, Batch 990: Loss = 0.8558, Acc = 71.74%, Spikes = 0.0433\n",
            "Epoch 8, Batch 1000: Loss = 1.1023, Acc = 71.73%, Spikes = 0.0449\n",
            "Epoch 8, Batch 1010: Loss = 0.9340, Acc = 71.74%, Spikes = 0.0441\n",
            "Epoch 8, Batch 1020: Loss = 0.8806, Acc = 71.74%, Spikes = 0.0432\n",
            "Epoch 8, Batch 1030: Loss = 0.9872, Acc = 71.73%, Spikes = 0.0435\n",
            "Epoch 8, Batch 1040: Loss = 0.7078, Acc = 71.74%, Spikes = 0.0458\n",
            "Epoch 8, Batch 1050: Loss = 1.0035, Acc = 71.75%, Spikes = 0.0435\n",
            "Epoch 8, Batch 1060: Loss = 1.1196, Acc = 71.69%, Spikes = 0.0434\n",
            "Epoch 8, Batch 1070: Loss = 0.7379, Acc = 71.73%, Spikes = 0.0468\n",
            "Epoch 8, Batch 1080: Loss = 0.7928, Acc = 71.74%, Spikes = 0.0479\n",
            "Epoch 8, Batch 1090: Loss = 1.0932, Acc = 71.69%, Spikes = 0.0421\n",
            "Epoch 8, Batch 1100: Loss = 0.8522, Acc = 71.72%, Spikes = 0.0414\n",
            "Epoch 8, Batch 1110: Loss = 0.7015, Acc = 71.73%, Spikes = 0.0471\n",
            "Epoch 8, Batch 1120: Loss = 0.8795, Acc = 71.72%, Spikes = 0.0409\n",
            "Epoch 8, Batch 1130: Loss = 0.8019, Acc = 71.75%, Spikes = 0.0458\n",
            "Epoch 8, Batch 1140: Loss = 0.9008, Acc = 71.73%, Spikes = 0.0485\n",
            "Epoch 8, Batch 1150: Loss = 0.9799, Acc = 71.72%, Spikes = 0.0420\n",
            "Epoch 8, Batch 1160: Loss = 0.6963, Acc = 71.70%, Spikes = 0.0449\n",
            "Epoch 8, Batch 1170: Loss = 0.8741, Acc = 71.72%, Spikes = 0.0451\n",
            "Epoch 8, Batch 1180: Loss = 1.2072, Acc = 71.68%, Spikes = 0.0464\n",
            "Epoch 8, Batch 1190: Loss = 1.2097, Acc = 71.73%, Spikes = 0.0417\n",
            "Epoch 8, Batch 1200: Loss = 1.1500, Acc = 71.74%, Spikes = 0.0403\n",
            "Epoch 8, Batch 1210: Loss = 0.8654, Acc = 71.74%, Spikes = 0.0458\n",
            "Epoch 8, Batch 1220: Loss = 0.8248, Acc = 71.72%, Spikes = 0.0443\n",
            "Epoch 8, Batch 1230: Loss = 0.8419, Acc = 71.71%, Spikes = 0.0457\n",
            "Epoch 8, Batch 1240: Loss = 0.7960, Acc = 71.71%, Spikes = 0.0447\n",
            "Epoch 8, Batch 1250: Loss = 0.8837, Acc = 71.74%, Spikes = 0.0436\n",
            "Epoch 8, Batch 1260: Loss = 0.8778, Acc = 71.74%, Spikes = 0.0473\n",
            "Epoch 8, Batch 1270: Loss = 1.0680, Acc = 71.78%, Spikes = 0.0427\n",
            "Epoch 8, Batch 1280: Loss = 0.9610, Acc = 71.78%, Spikes = 0.0417\n",
            "Epoch 8, Batch 1290: Loss = 1.0921, Acc = 71.78%, Spikes = 0.0460\n",
            "Epoch 8, Batch 1300: Loss = 0.9683, Acc = 71.75%, Spikes = 0.0436\n",
            "Epoch 8, Batch 1310: Loss = 0.9455, Acc = 71.79%, Spikes = 0.0462\n",
            "Epoch 8, Batch 1320: Loss = 0.7608, Acc = 71.76%, Spikes = 0.0478\n",
            "Epoch 8, Batch 1330: Loss = 0.9455, Acc = 71.74%, Spikes = 0.0442\n",
            "Epoch 8, Batch 1340: Loss = 0.8548, Acc = 71.75%, Spikes = 0.0451\n",
            "Epoch 8, Batch 1350: Loss = 1.1062, Acc = 71.75%, Spikes = 0.0414\n",
            "Epoch 8, Batch 1360: Loss = 0.8526, Acc = 71.76%, Spikes = 0.0451\n",
            "Epoch 8, Batch 1370: Loss = 1.1825, Acc = 71.75%, Spikes = 0.0416\n",
            "Epoch 8, Batch 1380: Loss = 0.7955, Acc = 71.75%, Spikes = 0.0448\n",
            "Epoch 8, Batch 1390: Loss = 0.8170, Acc = 71.76%, Spikes = 0.0458\n",
            "Epoch 8, Batch 1400: Loss = 0.8930, Acc = 71.81%, Spikes = 0.0454\n",
            "Epoch 8, Batch 1410: Loss = 0.9136, Acc = 71.83%, Spikes = 0.0405\n",
            "Epoch 8, Batch 1420: Loss = 0.7552, Acc = 71.84%, Spikes = 0.0485\n",
            "Epoch 8, Batch 1430: Loss = 0.9046, Acc = 71.83%, Spikes = 0.0477\n",
            "Epoch 8, Batch 1440: Loss = 0.9065, Acc = 71.83%, Spikes = 0.0487\n",
            "Epoch 8, Batch 1450: Loss = 1.0185, Acc = 71.84%, Spikes = 0.0376\n",
            "Epoch 8, Batch 1460: Loss = 1.0321, Acc = 71.87%, Spikes = 0.0416\n",
            "Epoch 8, Batch 1470: Loss = 0.9978, Acc = 71.84%, Spikes = 0.0421\n",
            "Epoch 8, Batch 1480: Loss = 0.9675, Acc = 71.84%, Spikes = 0.0429\n",
            "Epoch 8, Batch 1490: Loss = 0.8597, Acc = 71.85%, Spikes = 0.0435\n",
            "Epoch 8, Batch 1500: Loss = 1.0673, Acc = 71.86%, Spikes = 0.0399\n",
            "Epoch 8, Batch 1510: Loss = 1.0241, Acc = 71.87%, Spikes = 0.0448\n",
            "Epoch 8, Batch 1520: Loss = 1.0366, Acc = 71.85%, Spikes = 0.0484\n",
            "Epoch 8, Batch 1530: Loss = 1.1751, Acc = 71.85%, Spikes = 0.0425\n",
            "Epoch 8, Batch 1540: Loss = 0.8835, Acc = 71.84%, Spikes = 0.0450\n",
            "Epoch 8, Batch 1550: Loss = 0.7717, Acc = 71.86%, Spikes = 0.0429\n",
            "Epoch 8, Batch 1560: Loss = 0.9209, Acc = 71.86%, Spikes = 0.0435\n",
            "Epoch 8, Batch 1570: Loss = 0.8599, Acc = 71.86%, Spikes = 0.0447\n",
            "Epoch 8, Batch 1580: Loss = 0.9135, Acc = 71.85%, Spikes = 0.0448\n",
            "Epoch 8, Batch 1590: Loss = 0.9801, Acc = 71.88%, Spikes = 0.0436\n",
            "Epoch 8, Batch 1600: Loss = 0.9573, Acc = 71.90%, Spikes = 0.0470\n",
            "Epoch 8, Batch 1610: Loss = 0.7499, Acc = 71.91%, Spikes = 0.0442\n",
            "Epoch 8, Batch 1620: Loss = 0.8887, Acc = 71.88%, Spikes = 0.0439\n",
            "Epoch 8, Batch 1630: Loss = 0.9398, Acc = 71.87%, Spikes = 0.0458\n",
            "Epoch 8, Batch 1640: Loss = 0.7626, Acc = 71.88%, Spikes = 0.0485\n",
            "Epoch 8, Batch 1650: Loss = 0.9198, Acc = 71.87%, Spikes = 0.0434\n",
            "Epoch 8, Batch 1660: Loss = 0.7333, Acc = 71.87%, Spikes = 0.0461\n",
            "Epoch 8, Batch 1670: Loss = 0.8011, Acc = 71.88%, Spikes = 0.0437\n",
            "Epoch 8, Batch 1680: Loss = 0.9769, Acc = 71.87%, Spikes = 0.0431\n",
            "Epoch 8, Batch 1690: Loss = 1.2072, Acc = 71.89%, Spikes = 0.0424\n",
            "Epoch 8, Batch 1700: Loss = 0.8984, Acc = 71.90%, Spikes = 0.0460\n",
            "Epoch 8, Batch 1710: Loss = 0.7967, Acc = 71.88%, Spikes = 0.0457\n",
            "Epoch 8, Batch 1720: Loss = 0.7407, Acc = 71.88%, Spikes = 0.0448\n",
            "Epoch 8, Batch 1730: Loss = 0.7814, Acc = 71.88%, Spikes = 0.0449\n",
            "Epoch 8, Batch 1740: Loss = 0.7374, Acc = 71.89%, Spikes = 0.0479\n",
            "Epoch 8, Batch 1750: Loss = 0.8561, Acc = 71.90%, Spikes = 0.0462\n",
            "Epoch 8, Batch 1760: Loss = 0.8773, Acc = 71.90%, Spikes = 0.0435\n",
            "Epoch 8, Batch 1770: Loss = 1.0861, Acc = 71.90%, Spikes = 0.0464\n",
            "Epoch 8, Batch 1780: Loss = 0.8713, Acc = 71.91%, Spikes = 0.0449\n",
            "Epoch 8, Batch 1790: Loss = 0.9433, Acc = 71.90%, Spikes = 0.0466\n",
            "Epoch 8, Batch 1800: Loss = 0.7588, Acc = 71.91%, Spikes = 0.0488\n",
            "Epoch 8, Batch 1810: Loss = 0.7219, Acc = 71.94%, Spikes = 0.0446\n",
            "Epoch 8, Batch 1820: Loss = 0.9613, Acc = 71.92%, Spikes = 0.0440\n",
            "Epoch 8, Batch 1830: Loss = 0.8007, Acc = 71.95%, Spikes = 0.0441\n",
            "Epoch 8, Batch 1840: Loss = 0.8917, Acc = 71.96%, Spikes = 0.0446\n",
            "Epoch 8, Batch 1850: Loss = 0.7826, Acc = 71.97%, Spikes = 0.0470\n",
            "Epoch 8, Batch 1860: Loss = 0.9016, Acc = 71.96%, Spikes = 0.0470\n",
            "Epoch 8, Batch 1870: Loss = 0.7190, Acc = 71.97%, Spikes = 0.0445\n",
            "Epoch 8/15:\n",
            "Train Loss: 0.9288 | Train Acc: 71.95% | Train Spikes: 0.0439\n",
            "Test Acc: 73.16% | Test Spikes: 0.0452\n",
            "------------------------------------------------------------\n",
            "Epoch 9, Batch 0: Loss = 0.8366, Acc = 78.12%, Spikes = 0.0451\n",
            "Epoch 9, Batch 10: Loss = 1.0896, Acc = 73.01%, Spikes = 0.0443\n",
            "Epoch 9, Batch 20: Loss = 0.8980, Acc = 73.36%, Spikes = 0.0450\n",
            "Epoch 9, Batch 30: Loss = 0.7828, Acc = 73.59%, Spikes = 0.0450\n",
            "Epoch 9, Batch 40: Loss = 0.8608, Acc = 73.93%, Spikes = 0.0425\n",
            "Epoch 9, Batch 50: Loss = 0.9374, Acc = 73.65%, Spikes = 0.0427\n",
            "Epoch 9, Batch 60: Loss = 0.9252, Acc = 73.98%, Spikes = 0.0416\n",
            "Epoch 9, Batch 70: Loss = 0.9448, Acc = 73.59%, Spikes = 0.0418\n",
            "Epoch 9, Batch 80: Loss = 1.2131, Acc = 72.99%, Spikes = 0.0397\n",
            "Epoch 9, Batch 90: Loss = 0.8699, Acc = 73.08%, Spikes = 0.0432\n",
            "Epoch 9, Batch 100: Loss = 1.0371, Acc = 72.93%, Spikes = 0.0407\n",
            "Epoch 9, Batch 110: Loss = 0.8734, Acc = 72.78%, Spikes = 0.0425\n",
            "Epoch 9, Batch 120: Loss = 0.7805, Acc = 72.88%, Spikes = 0.0470\n",
            "Epoch 9, Batch 130: Loss = 1.1688, Acc = 73.00%, Spikes = 0.0421\n",
            "Epoch 9, Batch 140: Loss = 0.8437, Acc = 72.81%, Spikes = 0.0460\n",
            "Epoch 9, Batch 150: Loss = 1.1850, Acc = 72.74%, Spikes = 0.0413\n",
            "Epoch 9, Batch 160: Loss = 0.8898, Acc = 72.59%, Spikes = 0.0439\n",
            "Epoch 9, Batch 170: Loss = 0.8752, Acc = 72.79%, Spikes = 0.0470\n",
            "Epoch 9, Batch 180: Loss = 0.9044, Acc = 72.72%, Spikes = 0.0420\n",
            "Epoch 9, Batch 190: Loss = 0.8419, Acc = 72.59%, Spikes = 0.0466\n",
            "Epoch 9, Batch 200: Loss = 0.6114, Acc = 72.70%, Spikes = 0.0507\n",
            "Epoch 9, Batch 210: Loss = 0.7818, Acc = 72.70%, Spikes = 0.0461\n",
            "Epoch 9, Batch 220: Loss = 0.7378, Acc = 72.62%, Spikes = 0.0443\n",
            "Epoch 9, Batch 230: Loss = 0.7425, Acc = 72.70%, Spikes = 0.0451\n",
            "Epoch 9, Batch 240: Loss = 1.0869, Acc = 72.73%, Spikes = 0.0446\n",
            "Epoch 9, Batch 250: Loss = 0.6476, Acc = 72.75%, Spikes = 0.0508\n",
            "Epoch 9, Batch 260: Loss = 0.6344, Acc = 72.67%, Spikes = 0.0483\n",
            "Epoch 9, Batch 270: Loss = 1.2104, Acc = 72.72%, Spikes = 0.0437\n",
            "Epoch 9, Batch 280: Loss = 0.7215, Acc = 72.85%, Spikes = 0.0486\n",
            "Epoch 9, Batch 290: Loss = 0.7432, Acc = 72.82%, Spikes = 0.0493\n",
            "Epoch 9, Batch 300: Loss = 0.6566, Acc = 73.04%, Spikes = 0.0478\n",
            "Epoch 9, Batch 310: Loss = 1.1834, Acc = 73.12%, Spikes = 0.0447\n",
            "Epoch 9, Batch 320: Loss = 0.8274, Acc = 73.09%, Spikes = 0.0413\n",
            "Epoch 9, Batch 330: Loss = 0.9357, Acc = 73.05%, Spikes = 0.0452\n",
            "Epoch 9, Batch 340: Loss = 1.0383, Acc = 73.06%, Spikes = 0.0445\n",
            "Epoch 9, Batch 350: Loss = 0.8509, Acc = 73.05%, Spikes = 0.0479\n",
            "Epoch 9, Batch 360: Loss = 0.9231, Acc = 73.03%, Spikes = 0.0472\n",
            "Epoch 9, Batch 370: Loss = 1.2063, Acc = 73.14%, Spikes = 0.0445\n",
            "Epoch 9, Batch 380: Loss = 0.8444, Acc = 73.01%, Spikes = 0.0428\n",
            "Epoch 9, Batch 390: Loss = 1.0158, Acc = 73.05%, Spikes = 0.0441\n",
            "Epoch 9, Batch 400: Loss = 1.0712, Acc = 73.00%, Spikes = 0.0391\n",
            "Epoch 9, Batch 410: Loss = 0.8985, Acc = 72.97%, Spikes = 0.0455\n",
            "Epoch 9, Batch 420: Loss = 0.9058, Acc = 73.00%, Spikes = 0.0436\n",
            "Epoch 9, Batch 430: Loss = 0.6783, Acc = 73.07%, Spikes = 0.0479\n",
            "Epoch 9, Batch 440: Loss = 1.1362, Acc = 73.01%, Spikes = 0.0470\n",
            "Epoch 9, Batch 450: Loss = 0.9888, Acc = 73.00%, Spikes = 0.0443\n",
            "Epoch 9, Batch 460: Loss = 0.9345, Acc = 73.02%, Spikes = 0.0445\n",
            "Epoch 9, Batch 470: Loss = 0.7779, Acc = 72.98%, Spikes = 0.0467\n",
            "Epoch 9, Batch 480: Loss = 0.6995, Acc = 73.04%, Spikes = 0.0479\n",
            "Epoch 9, Batch 490: Loss = 0.9703, Acc = 73.11%, Spikes = 0.0433\n",
            "Epoch 9, Batch 500: Loss = 0.7820, Acc = 73.15%, Spikes = 0.0476\n",
            "Epoch 9, Batch 510: Loss = 0.9185, Acc = 73.10%, Spikes = 0.0405\n",
            "Epoch 9, Batch 520: Loss = 0.6326, Acc = 73.04%, Spikes = 0.0466\n",
            "Epoch 9, Batch 530: Loss = 0.9374, Acc = 73.07%, Spikes = 0.0449\n",
            "Epoch 9, Batch 540: Loss = 1.0230, Acc = 72.97%, Spikes = 0.0426\n",
            "Epoch 9, Batch 550: Loss = 0.8694, Acc = 72.99%, Spikes = 0.0437\n",
            "Epoch 9, Batch 560: Loss = 0.8465, Acc = 73.02%, Spikes = 0.0435\n",
            "Epoch 9, Batch 570: Loss = 1.0655, Acc = 73.01%, Spikes = 0.0420\n",
            "Epoch 9, Batch 580: Loss = 1.1608, Acc = 72.95%, Spikes = 0.0416\n",
            "Epoch 9, Batch 590: Loss = 1.1378, Acc = 72.96%, Spikes = 0.0419\n",
            "Epoch 9, Batch 600: Loss = 1.0085, Acc = 72.90%, Spikes = 0.0448\n",
            "Epoch 9, Batch 610: Loss = 1.0650, Acc = 72.96%, Spikes = 0.0455\n",
            "Epoch 9, Batch 620: Loss = 1.1402, Acc = 72.95%, Spikes = 0.0432\n",
            "Epoch 9, Batch 630: Loss = 0.8872, Acc = 72.84%, Spikes = 0.0449\n",
            "Epoch 9, Batch 640: Loss = 1.1974, Acc = 72.79%, Spikes = 0.0466\n",
            "Epoch 9, Batch 650: Loss = 1.0283, Acc = 72.82%, Spikes = 0.0436\n",
            "Epoch 9, Batch 660: Loss = 0.7533, Acc = 72.83%, Spikes = 0.0477\n",
            "Epoch 9, Batch 670: Loss = 0.7946, Acc = 72.79%, Spikes = 0.0433\n",
            "Epoch 9, Batch 680: Loss = 0.8422, Acc = 72.79%, Spikes = 0.0429\n",
            "Epoch 9, Batch 690: Loss = 0.7199, Acc = 72.81%, Spikes = 0.0497\n",
            "Epoch 9, Batch 700: Loss = 0.8993, Acc = 72.78%, Spikes = 0.0489\n",
            "Epoch 9, Batch 710: Loss = 0.9408, Acc = 72.75%, Spikes = 0.0488\n",
            "Epoch 9, Batch 720: Loss = 0.7805, Acc = 72.76%, Spikes = 0.0467\n",
            "Epoch 9, Batch 730: Loss = 0.9630, Acc = 72.77%, Spikes = 0.0447\n",
            "Epoch 9, Batch 740: Loss = 0.7746, Acc = 72.78%, Spikes = 0.0456\n",
            "Epoch 9, Batch 750: Loss = 0.7507, Acc = 72.83%, Spikes = 0.0432\n",
            "Epoch 9, Batch 760: Loss = 0.9376, Acc = 72.81%, Spikes = 0.0465\n",
            "Epoch 9, Batch 770: Loss = 0.8734, Acc = 72.74%, Spikes = 0.0456\n",
            "Epoch 9, Batch 780: Loss = 1.0461, Acc = 72.73%, Spikes = 0.0493\n",
            "Epoch 9, Batch 790: Loss = 0.7003, Acc = 72.71%, Spikes = 0.0460\n",
            "Epoch 9, Batch 800: Loss = 0.9061, Acc = 72.71%, Spikes = 0.0451\n",
            "Epoch 9, Batch 810: Loss = 1.0123, Acc = 72.76%, Spikes = 0.0442\n",
            "Epoch 9, Batch 820: Loss = 0.8294, Acc = 72.75%, Spikes = 0.0460\n",
            "Epoch 9, Batch 830: Loss = 0.9671, Acc = 72.72%, Spikes = 0.0494\n",
            "Epoch 9, Batch 840: Loss = 1.1998, Acc = 72.73%, Spikes = 0.0480\n",
            "Epoch 9, Batch 850: Loss = 0.8432, Acc = 72.73%, Spikes = 0.0487\n",
            "Epoch 9, Batch 860: Loss = 1.1929, Acc = 72.74%, Spikes = 0.0440\n",
            "Epoch 9, Batch 870: Loss = 0.8717, Acc = 72.78%, Spikes = 0.0466\n",
            "Epoch 9, Batch 880: Loss = 1.0293, Acc = 72.77%, Spikes = 0.0412\n",
            "Epoch 9, Batch 890: Loss = 0.6055, Acc = 72.80%, Spikes = 0.0470\n",
            "Epoch 9, Batch 900: Loss = 0.7927, Acc = 72.79%, Spikes = 0.0504\n",
            "Epoch 9, Batch 910: Loss = 0.9297, Acc = 72.86%, Spikes = 0.0430\n",
            "Epoch 9, Batch 920: Loss = 0.8607, Acc = 72.81%, Spikes = 0.0447\n",
            "Epoch 9, Batch 930: Loss = 0.8464, Acc = 72.82%, Spikes = 0.0413\n",
            "Epoch 9, Batch 940: Loss = 0.8373, Acc = 72.79%, Spikes = 0.0457\n",
            "Epoch 9, Batch 950: Loss = 0.9196, Acc = 72.81%, Spikes = 0.0422\n",
            "Epoch 9, Batch 960: Loss = 0.6982, Acc = 72.79%, Spikes = 0.0451\n",
            "Epoch 9, Batch 970: Loss = 0.9385, Acc = 72.74%, Spikes = 0.0428\n",
            "Epoch 9, Batch 980: Loss = 1.1395, Acc = 72.73%, Spikes = 0.0421\n",
            "Epoch 9, Batch 990: Loss = 0.7635, Acc = 72.77%, Spikes = 0.0467\n",
            "Epoch 9, Batch 1000: Loss = 1.2879, Acc = 72.74%, Spikes = 0.0463\n",
            "Epoch 9, Batch 1010: Loss = 0.9000, Acc = 72.75%, Spikes = 0.0414\n",
            "Epoch 9, Batch 1020: Loss = 1.0304, Acc = 72.77%, Spikes = 0.0414\n",
            "Epoch 9, Batch 1030: Loss = 0.9196, Acc = 72.77%, Spikes = 0.0436\n",
            "Epoch 9, Batch 1040: Loss = 1.0561, Acc = 72.72%, Spikes = 0.0406\n",
            "Epoch 9, Batch 1050: Loss = 1.0954, Acc = 72.71%, Spikes = 0.0427\n",
            "Epoch 9, Batch 1060: Loss = 0.8782, Acc = 72.73%, Spikes = 0.0487\n",
            "Epoch 9, Batch 1070: Loss = 0.9536, Acc = 72.72%, Spikes = 0.0431\n",
            "Epoch 9, Batch 1080: Loss = 0.7821, Acc = 72.72%, Spikes = 0.0468\n",
            "Epoch 9, Batch 1090: Loss = 1.0801, Acc = 72.72%, Spikes = 0.0442\n",
            "Epoch 9, Batch 1100: Loss = 1.1267, Acc = 72.68%, Spikes = 0.0451\n",
            "Epoch 9, Batch 1110: Loss = 0.7428, Acc = 72.71%, Spikes = 0.0436\n",
            "Epoch 9, Batch 1120: Loss = 0.8639, Acc = 72.68%, Spikes = 0.0482\n",
            "Epoch 9, Batch 1130: Loss = 0.9471, Acc = 72.66%, Spikes = 0.0490\n",
            "Epoch 9, Batch 1140: Loss = 1.0904, Acc = 72.64%, Spikes = 0.0443\n",
            "Epoch 9, Batch 1150: Loss = 0.9055, Acc = 72.64%, Spikes = 0.0452\n",
            "Epoch 9, Batch 1160: Loss = 0.8985, Acc = 72.66%, Spikes = 0.0423\n",
            "Epoch 9, Batch 1170: Loss = 0.6330, Acc = 72.69%, Spikes = 0.0508\n",
            "Epoch 9, Batch 1180: Loss = 0.6707, Acc = 72.68%, Spikes = 0.0461\n",
            "Epoch 9, Batch 1190: Loss = 1.0129, Acc = 72.67%, Spikes = 0.0482\n",
            "Epoch 9, Batch 1200: Loss = 0.9723, Acc = 72.68%, Spikes = 0.0438\n",
            "Epoch 9, Batch 1210: Loss = 0.7414, Acc = 72.66%, Spikes = 0.0471\n",
            "Epoch 9, Batch 1220: Loss = 0.7079, Acc = 72.64%, Spikes = 0.0455\n",
            "Epoch 9, Batch 1230: Loss = 0.8411, Acc = 72.63%, Spikes = 0.0524\n",
            "Epoch 9, Batch 1240: Loss = 0.9996, Acc = 72.61%, Spikes = 0.0451\n",
            "Epoch 9, Batch 1250: Loss = 0.8905, Acc = 72.60%, Spikes = 0.0478\n",
            "Epoch 9, Batch 1260: Loss = 0.6011, Acc = 72.64%, Spikes = 0.0460\n",
            "Epoch 9, Batch 1270: Loss = 0.6595, Acc = 72.63%, Spikes = 0.0487\n",
            "Epoch 9, Batch 1280: Loss = 1.0460, Acc = 72.66%, Spikes = 0.0445\n",
            "Epoch 9, Batch 1290: Loss = 0.8251, Acc = 72.69%, Spikes = 0.0500\n",
            "Epoch 9, Batch 1300: Loss = 0.8684, Acc = 72.69%, Spikes = 0.0462\n",
            "Epoch 9, Batch 1310: Loss = 0.8845, Acc = 72.68%, Spikes = 0.0421\n",
            "Epoch 9, Batch 1320: Loss = 1.0012, Acc = 72.65%, Spikes = 0.0415\n",
            "Epoch 9, Batch 1330: Loss = 0.9420, Acc = 72.67%, Spikes = 0.0485\n",
            "Epoch 9, Batch 1340: Loss = 0.9317, Acc = 72.68%, Spikes = 0.0461\n",
            "Epoch 9, Batch 1350: Loss = 0.7474, Acc = 72.71%, Spikes = 0.0464\n",
            "Epoch 9, Batch 1360: Loss = 0.7158, Acc = 72.75%, Spikes = 0.0474\n",
            "Epoch 9, Batch 1370: Loss = 0.9142, Acc = 72.73%, Spikes = 0.0437\n",
            "Epoch 9, Batch 1380: Loss = 0.6520, Acc = 72.73%, Spikes = 0.0495\n",
            "Epoch 9, Batch 1390: Loss = 0.9438, Acc = 72.72%, Spikes = 0.0481\n",
            "Epoch 9, Batch 1400: Loss = 0.8053, Acc = 72.73%, Spikes = 0.0486\n",
            "Epoch 9, Batch 1410: Loss = 0.6981, Acc = 72.74%, Spikes = 0.0499\n",
            "Epoch 9, Batch 1420: Loss = 0.6782, Acc = 72.73%, Spikes = 0.0493\n",
            "Epoch 9, Batch 1430: Loss = 0.6786, Acc = 72.75%, Spikes = 0.0454\n",
            "Epoch 9, Batch 1440: Loss = 0.8060, Acc = 72.73%, Spikes = 0.0450\n",
            "Epoch 9, Batch 1450: Loss = 1.0671, Acc = 72.76%, Spikes = 0.0455\n",
            "Epoch 9, Batch 1460: Loss = 1.0465, Acc = 72.78%, Spikes = 0.0459\n",
            "Epoch 9, Batch 1470: Loss = 0.9822, Acc = 72.76%, Spikes = 0.0454\n",
            "Epoch 9, Batch 1480: Loss = 0.8173, Acc = 72.75%, Spikes = 0.0472\n",
            "Epoch 9, Batch 1490: Loss = 0.7224, Acc = 72.76%, Spikes = 0.0490\n",
            "Epoch 9, Batch 1500: Loss = 1.0163, Acc = 72.76%, Spikes = 0.0465\n",
            "Epoch 9, Batch 1510: Loss = 0.8202, Acc = 72.77%, Spikes = 0.0511\n",
            "Epoch 9, Batch 1520: Loss = 0.7006, Acc = 72.76%, Spikes = 0.0525\n",
            "Epoch 9, Batch 1530: Loss = 0.5866, Acc = 72.78%, Spikes = 0.0496\n",
            "Epoch 9, Batch 1540: Loss = 0.9271, Acc = 72.80%, Spikes = 0.0469\n",
            "Epoch 9, Batch 1550: Loss = 0.7717, Acc = 72.80%, Spikes = 0.0446\n",
            "Epoch 9, Batch 1560: Loss = 1.0392, Acc = 72.78%, Spikes = 0.0476\n",
            "Epoch 9, Batch 1570: Loss = 0.9030, Acc = 72.76%, Spikes = 0.0454\n",
            "Epoch 9, Batch 1580: Loss = 0.7295, Acc = 72.76%, Spikes = 0.0465\n",
            "Epoch 9, Batch 1590: Loss = 1.0647, Acc = 72.77%, Spikes = 0.0447\n",
            "Epoch 9, Batch 1600: Loss = 0.6982, Acc = 72.78%, Spikes = 0.0505\n",
            "Epoch 9, Batch 1610: Loss = 0.6390, Acc = 72.77%, Spikes = 0.0478\n",
            "Epoch 9, Batch 1620: Loss = 0.5624, Acc = 72.78%, Spikes = 0.0473\n",
            "Epoch 9, Batch 1630: Loss = 0.6301, Acc = 72.80%, Spikes = 0.0490\n",
            "Epoch 9, Batch 1640: Loss = 0.8287, Acc = 72.83%, Spikes = 0.0461\n",
            "Epoch 9, Batch 1650: Loss = 0.7658, Acc = 72.81%, Spikes = 0.0496\n",
            "Epoch 9, Batch 1660: Loss = 0.8323, Acc = 72.84%, Spikes = 0.0480\n",
            "Epoch 9, Batch 1670: Loss = 0.6043, Acc = 72.85%, Spikes = 0.0491\n",
            "Epoch 9, Batch 1680: Loss = 0.9633, Acc = 72.89%, Spikes = 0.0465\n",
            "Epoch 9, Batch 1690: Loss = 0.7775, Acc = 72.90%, Spikes = 0.0502\n",
            "Epoch 9, Batch 1700: Loss = 0.8880, Acc = 72.89%, Spikes = 0.0440\n",
            "Epoch 9, Batch 1710: Loss = 0.8762, Acc = 72.88%, Spikes = 0.0459\n",
            "Epoch 9, Batch 1720: Loss = 0.8868, Acc = 72.87%, Spikes = 0.0447\n",
            "Epoch 9, Batch 1730: Loss = 1.0955, Acc = 72.89%, Spikes = 0.0437\n",
            "Epoch 9, Batch 1740: Loss = 0.8054, Acc = 72.91%, Spikes = 0.0454\n",
            "Epoch 9, Batch 1750: Loss = 0.9649, Acc = 72.92%, Spikes = 0.0428\n",
            "Epoch 9, Batch 1760: Loss = 0.8010, Acc = 72.95%, Spikes = 0.0456\n",
            "Epoch 9, Batch 1770: Loss = 0.8719, Acc = 72.93%, Spikes = 0.0461\n",
            "Epoch 9, Batch 1780: Loss = 0.5973, Acc = 72.94%, Spikes = 0.0500\n",
            "Epoch 9, Batch 1790: Loss = 0.8221, Acc = 72.93%, Spikes = 0.0466\n",
            "Epoch 9, Batch 1800: Loss = 0.6803, Acc = 72.93%, Spikes = 0.0480\n",
            "Epoch 9, Batch 1810: Loss = 1.0536, Acc = 72.93%, Spikes = 0.0445\n",
            "Epoch 9, Batch 1820: Loss = 0.8731, Acc = 72.94%, Spikes = 0.0445\n",
            "Epoch 9, Batch 1830: Loss = 0.4820, Acc = 72.95%, Spikes = 0.0503\n",
            "Epoch 9, Batch 1840: Loss = 0.9182, Acc = 72.96%, Spikes = 0.0503\n",
            "Epoch 9, Batch 1850: Loss = 0.8623, Acc = 72.98%, Spikes = 0.0464\n",
            "Epoch 9, Batch 1860: Loss = 0.8424, Acc = 73.00%, Spikes = 0.0488\n",
            "Epoch 9, Batch 1870: Loss = 0.7845, Acc = 72.99%, Spikes = 0.0499\n",
            "Epoch 9/15:\n",
            "Train Loss: 0.8828 | Train Acc: 73.00% | Train Spikes: 0.0458\n",
            "Test Acc: 73.84% | Test Spikes: 0.0470\n",
            "------------------------------------------------------------\n",
            "Epoch 10, Batch 0: Loss = 1.0659, Acc = 56.25%, Spikes = 0.0415\n",
            "Epoch 10, Batch 10: Loss = 0.7744, Acc = 73.30%, Spikes = 0.0470\n",
            "Epoch 10, Batch 20: Loss = 0.6294, Acc = 71.58%, Spikes = 0.0478\n",
            "Epoch 10, Batch 30: Loss = 0.6178, Acc = 71.67%, Spikes = 0.0516\n",
            "Epoch 10, Batch 40: Loss = 0.9716, Acc = 72.03%, Spikes = 0.0421\n",
            "Epoch 10, Batch 50: Loss = 1.2569, Acc = 72.86%, Spikes = 0.0431\n",
            "Epoch 10, Batch 60: Loss = 1.0543, Acc = 72.49%, Spikes = 0.0443\n",
            "Epoch 10, Batch 70: Loss = 0.7366, Acc = 72.89%, Spikes = 0.0451\n",
            "Epoch 10, Batch 80: Loss = 0.9340, Acc = 72.99%, Spikes = 0.0450\n",
            "Epoch 10, Batch 90: Loss = 1.0006, Acc = 72.73%, Spikes = 0.0448\n",
            "Epoch 10, Batch 100: Loss = 0.6634, Acc = 72.90%, Spikes = 0.0457\n",
            "Epoch 10, Batch 110: Loss = 1.1371, Acc = 72.97%, Spikes = 0.0458\n",
            "Epoch 10, Batch 120: Loss = 0.9028, Acc = 73.22%, Spikes = 0.0495\n",
            "Epoch 10, Batch 130: Loss = 0.8340, Acc = 73.43%, Spikes = 0.0444\n",
            "Epoch 10, Batch 140: Loss = 0.7713, Acc = 73.58%, Spikes = 0.0485\n",
            "Epoch 10, Batch 150: Loss = 0.4388, Acc = 73.86%, Spikes = 0.0483\n",
            "Epoch 10, Batch 160: Loss = 0.8969, Acc = 73.80%, Spikes = 0.0461\n",
            "Epoch 10, Batch 170: Loss = 0.9765, Acc = 73.81%, Spikes = 0.0456\n",
            "Epoch 10, Batch 180: Loss = 0.7552, Acc = 73.81%, Spikes = 0.0476\n",
            "Epoch 10, Batch 190: Loss = 0.6518, Acc = 73.87%, Spikes = 0.0518\n",
            "Epoch 10, Batch 200: Loss = 0.7566, Acc = 74.14%, Spikes = 0.0463\n",
            "Epoch 10, Batch 210: Loss = 0.8613, Acc = 74.20%, Spikes = 0.0456\n",
            "Epoch 10, Batch 220: Loss = 0.9524, Acc = 74.12%, Spikes = 0.0454\n",
            "Epoch 10, Batch 230: Loss = 1.0455, Acc = 74.09%, Spikes = 0.0470\n",
            "Epoch 10, Batch 240: Loss = 0.8558, Acc = 74.14%, Spikes = 0.0505\n",
            "Epoch 10, Batch 250: Loss = 0.7482, Acc = 74.18%, Spikes = 0.0433\n",
            "Epoch 10, Batch 260: Loss = 0.9367, Acc = 74.13%, Spikes = 0.0434\n",
            "Epoch 10, Batch 270: Loss = 0.8433, Acc = 74.22%, Spikes = 0.0473\n",
            "Epoch 10, Batch 280: Loss = 0.6220, Acc = 74.20%, Spikes = 0.0470\n",
            "Epoch 10, Batch 290: Loss = 0.5860, Acc = 74.23%, Spikes = 0.0484\n",
            "Epoch 10, Batch 300: Loss = 1.0418, Acc = 74.20%, Spikes = 0.0443\n",
            "Epoch 10, Batch 310: Loss = 1.1366, Acc = 74.22%, Spikes = 0.0465\n",
            "Epoch 10, Batch 320: Loss = 0.8401, Acc = 74.33%, Spikes = 0.0486\n",
            "Epoch 10, Batch 330: Loss = 0.8420, Acc = 74.19%, Spikes = 0.0504\n",
            "Epoch 10, Batch 340: Loss = 0.9314, Acc = 74.23%, Spikes = 0.0482\n",
            "Epoch 10, Batch 350: Loss = 0.8837, Acc = 74.18%, Spikes = 0.0474\n",
            "Epoch 10, Batch 360: Loss = 1.1720, Acc = 74.11%, Spikes = 0.0443\n",
            "Epoch 10, Batch 370: Loss = 1.0331, Acc = 74.01%, Spikes = 0.0465\n",
            "Epoch 10, Batch 380: Loss = 0.9670, Acc = 73.88%, Spikes = 0.0486\n",
            "Epoch 10, Batch 390: Loss = 0.9308, Acc = 73.82%, Spikes = 0.0460\n",
            "Epoch 10, Batch 400: Loss = 0.9217, Acc = 73.77%, Spikes = 0.0451\n",
            "Epoch 10, Batch 410: Loss = 1.0423, Acc = 73.85%, Spikes = 0.0432\n",
            "Epoch 10, Batch 420: Loss = 0.6918, Acc = 73.87%, Spikes = 0.0475\n",
            "Epoch 10, Batch 430: Loss = 1.0599, Acc = 73.77%, Spikes = 0.0442\n",
            "Epoch 10, Batch 440: Loss = 0.8994, Acc = 73.75%, Spikes = 0.0444\n",
            "Epoch 10, Batch 450: Loss = 0.8444, Acc = 73.69%, Spikes = 0.0483\n",
            "Epoch 10, Batch 460: Loss = 0.6672, Acc = 73.79%, Spikes = 0.0441\n",
            "Epoch 10, Batch 470: Loss = 0.7194, Acc = 73.87%, Spikes = 0.0513\n",
            "Epoch 10, Batch 480: Loss = 0.9728, Acc = 73.91%, Spikes = 0.0439\n",
            "Epoch 10, Batch 490: Loss = 0.6825, Acc = 73.91%, Spikes = 0.0495\n",
            "Epoch 10, Batch 500: Loss = 0.6822, Acc = 73.92%, Spikes = 0.0503\n",
            "Epoch 10, Batch 510: Loss = 0.8611, Acc = 73.82%, Spikes = 0.0479\n",
            "Epoch 10, Batch 520: Loss = 1.2113, Acc = 73.67%, Spikes = 0.0444\n",
            "Epoch 10, Batch 530: Loss = 0.7592, Acc = 73.69%, Spikes = 0.0486\n",
            "Epoch 10, Batch 540: Loss = 0.6156, Acc = 73.65%, Spikes = 0.0489\n",
            "Epoch 10, Batch 550: Loss = 0.8346, Acc = 73.70%, Spikes = 0.0497\n",
            "Epoch 10, Batch 560: Loss = 0.8516, Acc = 73.72%, Spikes = 0.0456\n",
            "Epoch 10, Batch 570: Loss = 1.0104, Acc = 73.68%, Spikes = 0.0469\n",
            "Epoch 10, Batch 580: Loss = 0.7709, Acc = 73.63%, Spikes = 0.0486\n",
            "Epoch 10, Batch 590: Loss = 1.1629, Acc = 73.55%, Spikes = 0.0492\n",
            "Epoch 10, Batch 600: Loss = 0.8943, Acc = 73.58%, Spikes = 0.0480\n",
            "Epoch 10, Batch 610: Loss = 0.8608, Acc = 73.55%, Spikes = 0.0491\n",
            "Epoch 10, Batch 620: Loss = 0.8118, Acc = 73.51%, Spikes = 0.0474\n",
            "Epoch 10, Batch 630: Loss = 0.7087, Acc = 73.51%, Spikes = 0.0480\n",
            "Epoch 10, Batch 640: Loss = 0.6190, Acc = 73.56%, Spikes = 0.0541\n",
            "Epoch 10, Batch 650: Loss = 0.8974, Acc = 73.52%, Spikes = 0.0477\n",
            "Epoch 10, Batch 660: Loss = 1.3564, Acc = 73.47%, Spikes = 0.0422\n",
            "Epoch 10, Batch 670: Loss = 0.9950, Acc = 73.51%, Spikes = 0.0451\n",
            "Epoch 10, Batch 680: Loss = 0.9389, Acc = 73.48%, Spikes = 0.0524\n",
            "Epoch 10, Batch 690: Loss = 0.7222, Acc = 73.49%, Spikes = 0.0483\n",
            "Epoch 10, Batch 700: Loss = 0.9012, Acc = 73.51%, Spikes = 0.0493\n",
            "Epoch 10, Batch 710: Loss = 1.1282, Acc = 73.51%, Spikes = 0.0484\n",
            "Epoch 10, Batch 720: Loss = 0.9075, Acc = 73.57%, Spikes = 0.0460\n",
            "Epoch 10, Batch 730: Loss = 0.9369, Acc = 73.56%, Spikes = 0.0504\n",
            "Epoch 10, Batch 740: Loss = 0.9465, Acc = 73.49%, Spikes = 0.0465\n",
            "Epoch 10, Batch 750: Loss = 0.8232, Acc = 73.52%, Spikes = 0.0485\n",
            "Epoch 10, Batch 760: Loss = 0.9058, Acc = 73.52%, Spikes = 0.0472\n",
            "Epoch 10, Batch 770: Loss = 0.5869, Acc = 73.55%, Spikes = 0.0513\n",
            "Epoch 10, Batch 780: Loss = 1.2833, Acc = 73.57%, Spikes = 0.0474\n",
            "Epoch 10, Batch 790: Loss = 0.8975, Acc = 73.55%, Spikes = 0.0497\n",
            "Epoch 10, Batch 800: Loss = 0.8361, Acc = 73.52%, Spikes = 0.0476\n",
            "Epoch 10, Batch 810: Loss = 0.7088, Acc = 73.51%, Spikes = 0.0549\n",
            "Epoch 10, Batch 820: Loss = 0.8902, Acc = 73.51%, Spikes = 0.0492\n",
            "Epoch 10, Batch 830: Loss = 0.8693, Acc = 73.49%, Spikes = 0.0469\n",
            "Epoch 10, Batch 840: Loss = 1.0149, Acc = 73.52%, Spikes = 0.0490\n",
            "Epoch 10, Batch 850: Loss = 1.0365, Acc = 73.52%, Spikes = 0.0455\n",
            "Epoch 10, Batch 860: Loss = 1.1240, Acc = 73.52%, Spikes = 0.0469\n",
            "Epoch 10, Batch 870: Loss = 0.8136, Acc = 73.51%, Spikes = 0.0491\n",
            "Epoch 10, Batch 880: Loss = 0.7981, Acc = 73.54%, Spikes = 0.0526\n",
            "Epoch 10, Batch 890: Loss = 0.8815, Acc = 73.53%, Spikes = 0.0466\n",
            "Epoch 10, Batch 900: Loss = 0.6709, Acc = 73.57%, Spikes = 0.0510\n",
            "Epoch 10, Batch 910: Loss = 0.8514, Acc = 73.50%, Spikes = 0.0442\n",
            "Epoch 10, Batch 920: Loss = 0.8597, Acc = 73.53%, Spikes = 0.0424\n",
            "Epoch 10, Batch 930: Loss = 0.6996, Acc = 73.55%, Spikes = 0.0477\n",
            "Epoch 10, Batch 940: Loss = 0.8265, Acc = 73.55%, Spikes = 0.0482\n",
            "Epoch 10, Batch 950: Loss = 0.8105, Acc = 73.52%, Spikes = 0.0460\n",
            "Epoch 10, Batch 960: Loss = 0.8145, Acc = 73.55%, Spikes = 0.0472\n",
            "Epoch 10, Batch 970: Loss = 1.0881, Acc = 73.54%, Spikes = 0.0459\n",
            "Epoch 10, Batch 980: Loss = 0.7566, Acc = 73.57%, Spikes = 0.0485\n",
            "Epoch 10, Batch 990: Loss = 0.7286, Acc = 73.57%, Spikes = 0.0532\n",
            "Epoch 10, Batch 1000: Loss = 0.6953, Acc = 73.55%, Spikes = 0.0462\n",
            "Epoch 10, Batch 1010: Loss = 1.0050, Acc = 73.54%, Spikes = 0.0443\n",
            "Epoch 10, Batch 1020: Loss = 0.9193, Acc = 73.55%, Spikes = 0.0481\n",
            "Epoch 10, Batch 1030: Loss = 1.0471, Acc = 73.54%, Spikes = 0.0464\n",
            "Epoch 10, Batch 1040: Loss = 0.7619, Acc = 73.54%, Spikes = 0.0479\n",
            "Epoch 10, Batch 1050: Loss = 0.8863, Acc = 73.53%, Spikes = 0.0454\n",
            "Epoch 10, Batch 1060: Loss = 1.1533, Acc = 73.51%, Spikes = 0.0495\n",
            "Epoch 10, Batch 1070: Loss = 0.8093, Acc = 73.52%, Spikes = 0.0504\n",
            "Epoch 10, Batch 1080: Loss = 0.8436, Acc = 73.49%, Spikes = 0.0509\n",
            "Epoch 10, Batch 1090: Loss = 1.0760, Acc = 73.53%, Spikes = 0.0503\n",
            "Epoch 10, Batch 1100: Loss = 0.9584, Acc = 73.52%, Spikes = 0.0462\n",
            "Epoch 10, Batch 1110: Loss = 0.7397, Acc = 73.50%, Spikes = 0.0523\n",
            "Epoch 10, Batch 1120: Loss = 0.5328, Acc = 73.53%, Spikes = 0.0517\n",
            "Epoch 10, Batch 1130: Loss = 0.7231, Acc = 73.50%, Spikes = 0.0480\n",
            "Epoch 10, Batch 1140: Loss = 0.8700, Acc = 73.52%, Spikes = 0.0512\n",
            "Epoch 10, Batch 1150: Loss = 0.7839, Acc = 73.55%, Spikes = 0.0452\n",
            "Epoch 10, Batch 1160: Loss = 0.8210, Acc = 73.55%, Spikes = 0.0489\n",
            "Epoch 10, Batch 1170: Loss = 0.8943, Acc = 73.59%, Spikes = 0.0498\n",
            "Epoch 10, Batch 1180: Loss = 0.9256, Acc = 73.59%, Spikes = 0.0462\n",
            "Epoch 10, Batch 1190: Loss = 1.0868, Acc = 73.60%, Spikes = 0.0478\n",
            "Epoch 10, Batch 1200: Loss = 0.5469, Acc = 73.60%, Spikes = 0.0538\n",
            "Epoch 10, Batch 1210: Loss = 0.8693, Acc = 73.56%, Spikes = 0.0475\n",
            "Epoch 10, Batch 1220: Loss = 0.8459, Acc = 73.56%, Spikes = 0.0454\n",
            "Epoch 10, Batch 1230: Loss = 0.9104, Acc = 73.57%, Spikes = 0.0495\n",
            "Epoch 10, Batch 1240: Loss = 1.2492, Acc = 73.55%, Spikes = 0.0410\n",
            "Epoch 10, Batch 1250: Loss = 0.7873, Acc = 73.55%, Spikes = 0.0469\n",
            "Epoch 10, Batch 1260: Loss = 0.9839, Acc = 73.58%, Spikes = 0.0475\n",
            "Epoch 10, Batch 1270: Loss = 1.2070, Acc = 73.59%, Spikes = 0.0464\n",
            "Epoch 10, Batch 1280: Loss = 1.0061, Acc = 73.59%, Spikes = 0.0436\n",
            "Epoch 10, Batch 1290: Loss = 0.4819, Acc = 73.59%, Spikes = 0.0512\n",
            "Epoch 10, Batch 1300: Loss = 1.0834, Acc = 73.59%, Spikes = 0.0470\n",
            "Epoch 10, Batch 1310: Loss = 1.0812, Acc = 73.59%, Spikes = 0.0494\n",
            "Epoch 10, Batch 1320: Loss = 0.8528, Acc = 73.60%, Spikes = 0.0461\n",
            "Epoch 10, Batch 1330: Loss = 0.7833, Acc = 73.57%, Spikes = 0.0488\n",
            "Epoch 10, Batch 1340: Loss = 0.7443, Acc = 73.57%, Spikes = 0.0523\n",
            "Epoch 10, Batch 1350: Loss = 1.0542, Acc = 73.56%, Spikes = 0.0502\n",
            "Epoch 10, Batch 1360: Loss = 1.0652, Acc = 73.52%, Spikes = 0.0457\n",
            "Epoch 10, Batch 1370: Loss = 0.7154, Acc = 73.51%, Spikes = 0.0447\n",
            "Epoch 10, Batch 1380: Loss = 0.7824, Acc = 73.49%, Spikes = 0.0483\n",
            "Epoch 10, Batch 1390: Loss = 1.0601, Acc = 73.50%, Spikes = 0.0469\n",
            "Epoch 10, Batch 1400: Loss = 1.0087, Acc = 73.49%, Spikes = 0.0483\n",
            "Epoch 10, Batch 1410: Loss = 0.9218, Acc = 73.50%, Spikes = 0.0461\n",
            "Epoch 10, Batch 1420: Loss = 0.7728, Acc = 73.51%, Spikes = 0.0518\n",
            "Epoch 10, Batch 1430: Loss = 0.7440, Acc = 73.50%, Spikes = 0.0508\n",
            "Epoch 10, Batch 1440: Loss = 0.6988, Acc = 73.49%, Spikes = 0.0481\n",
            "Epoch 10, Batch 1450: Loss = 0.6054, Acc = 73.51%, Spikes = 0.0487\n",
            "Epoch 10, Batch 1460: Loss = 0.8786, Acc = 73.51%, Spikes = 0.0483\n",
            "Epoch 10, Batch 1470: Loss = 0.7045, Acc = 73.54%, Spikes = 0.0524\n",
            "Epoch 10, Batch 1480: Loss = 0.5239, Acc = 73.56%, Spikes = 0.0528\n",
            "Epoch 10, Batch 1490: Loss = 0.8973, Acc = 73.57%, Spikes = 0.0503\n",
            "Epoch 10, Batch 1500: Loss = 0.7892, Acc = 73.57%, Spikes = 0.0493\n",
            "Epoch 10, Batch 1510: Loss = 1.2580, Acc = 73.55%, Spikes = 0.0458\n",
            "Epoch 10, Batch 1520: Loss = 0.8795, Acc = 73.55%, Spikes = 0.0476\n",
            "Epoch 10, Batch 1530: Loss = 0.7296, Acc = 73.56%, Spikes = 0.0508\n",
            "Epoch 10, Batch 1540: Loss = 0.9718, Acc = 73.54%, Spikes = 0.0518\n",
            "Epoch 10, Batch 1550: Loss = 0.8113, Acc = 73.56%, Spikes = 0.0499\n",
            "Epoch 10, Batch 1560: Loss = 0.9255, Acc = 73.57%, Spikes = 0.0474\n",
            "Epoch 10, Batch 1570: Loss = 0.5886, Acc = 73.59%, Spikes = 0.0472\n",
            "Epoch 10, Batch 1580: Loss = 1.0819, Acc = 73.57%, Spikes = 0.0448\n",
            "Epoch 10, Batch 1590: Loss = 0.8063, Acc = 73.53%, Spikes = 0.0471\n",
            "Epoch 10, Batch 1600: Loss = 0.7660, Acc = 73.54%, Spikes = 0.0494\n",
            "Epoch 10, Batch 1610: Loss = 0.6899, Acc = 73.51%, Spikes = 0.0529\n",
            "Epoch 10, Batch 1620: Loss = 0.6046, Acc = 73.51%, Spikes = 0.0518\n",
            "Epoch 10, Batch 1630: Loss = 1.1546, Acc = 73.50%, Spikes = 0.0449\n",
            "Epoch 10, Batch 1640: Loss = 0.8656, Acc = 73.48%, Spikes = 0.0495\n",
            "Epoch 10, Batch 1650: Loss = 0.6910, Acc = 73.49%, Spikes = 0.0497\n",
            "Epoch 10, Batch 1660: Loss = 0.8303, Acc = 73.47%, Spikes = 0.0481\n",
            "Epoch 10, Batch 1670: Loss = 0.7167, Acc = 73.45%, Spikes = 0.0491\n",
            "Epoch 10, Batch 1680: Loss = 0.7078, Acc = 73.46%, Spikes = 0.0472\n",
            "Epoch 10, Batch 1690: Loss = 0.9579, Acc = 73.43%, Spikes = 0.0486\n",
            "Epoch 10, Batch 1700: Loss = 0.8046, Acc = 73.46%, Spikes = 0.0469\n",
            "Epoch 10, Batch 1710: Loss = 0.6715, Acc = 73.48%, Spikes = 0.0517\n",
            "Epoch 10, Batch 1720: Loss = 0.9192, Acc = 73.47%, Spikes = 0.0525\n",
            "Epoch 10, Batch 1730: Loss = 0.7994, Acc = 73.47%, Spikes = 0.0481\n",
            "Epoch 10, Batch 1740: Loss = 0.6450, Acc = 73.47%, Spikes = 0.0493\n",
            "Epoch 10, Batch 1750: Loss = 0.7309, Acc = 73.48%, Spikes = 0.0526\n",
            "Epoch 10, Batch 1760: Loss = 0.8009, Acc = 73.46%, Spikes = 0.0531\n",
            "Epoch 10, Batch 1770: Loss = 1.1491, Acc = 73.46%, Spikes = 0.0452\n",
            "Epoch 10, Batch 1780: Loss = 0.6667, Acc = 73.45%, Spikes = 0.0481\n",
            "Epoch 10, Batch 1790: Loss = 0.8335, Acc = 73.45%, Spikes = 0.0502\n",
            "Epoch 10, Batch 1800: Loss = 0.7637, Acc = 73.47%, Spikes = 0.0492\n",
            "Epoch 10, Batch 1810: Loss = 0.8375, Acc = 73.48%, Spikes = 0.0458\n",
            "Epoch 10, Batch 1820: Loss = 0.7094, Acc = 73.47%, Spikes = 0.0468\n",
            "Epoch 10, Batch 1830: Loss = 0.7054, Acc = 73.48%, Spikes = 0.0499\n",
            "Epoch 10, Batch 1840: Loss = 0.4323, Acc = 73.49%, Spikes = 0.0525\n",
            "Epoch 10, Batch 1850: Loss = 0.7954, Acc = 73.51%, Spikes = 0.0486\n",
            "Epoch 10, Batch 1860: Loss = 1.1637, Acc = 73.53%, Spikes = 0.0480\n",
            "Epoch 10, Batch 1870: Loss = 0.5258, Acc = 73.55%, Spikes = 0.0531\n",
            "Epoch 10/15:\n",
            "Train Loss: 0.8496 | Train Acc: 73.55% | Train Spikes: 0.0478\n",
            "Test Acc: 75.05% | Test Spikes: 0.0490\n",
            "------------------------------------------------------------\n",
            "Epoch 11, Batch 0: Loss = 0.5471, Acc = 84.38%, Spikes = 0.0499\n",
            "Epoch 11, Batch 10: Loss = 0.6758, Acc = 79.26%, Spikes = 0.0499\n",
            "Epoch 11, Batch 20: Loss = 0.6300, Acc = 79.17%, Spikes = 0.0476\n",
            "Epoch 11, Batch 30: Loss = 0.9981, Acc = 77.82%, Spikes = 0.0477\n",
            "Epoch 11, Batch 40: Loss = 0.5975, Acc = 76.91%, Spikes = 0.0487\n",
            "Epoch 11, Batch 50: Loss = 0.9864, Acc = 76.35%, Spikes = 0.0432\n",
            "Epoch 11, Batch 60: Loss = 0.7112, Acc = 76.18%, Spikes = 0.0483\n",
            "Epoch 11, Batch 70: Loss = 0.7657, Acc = 75.97%, Spikes = 0.0464\n",
            "Epoch 11, Batch 80: Loss = 0.8194, Acc = 75.93%, Spikes = 0.0480\n",
            "Epoch 11, Batch 90: Loss = 0.7673, Acc = 75.76%, Spikes = 0.0467\n",
            "Epoch 11, Batch 100: Loss = 0.7388, Acc = 75.59%, Spikes = 0.0500\n",
            "Epoch 11, Batch 110: Loss = 0.9573, Acc = 75.25%, Spikes = 0.0459\n",
            "Epoch 11, Batch 120: Loss = 1.0033, Acc = 74.97%, Spikes = 0.0486\n",
            "Epoch 11, Batch 130: Loss = 0.7681, Acc = 75.41%, Spikes = 0.0503\n",
            "Epoch 11, Batch 140: Loss = 0.5606, Acc = 75.49%, Spikes = 0.0475\n",
            "Epoch 11, Batch 150: Loss = 0.7220, Acc = 75.33%, Spikes = 0.0446\n",
            "Epoch 11, Batch 160: Loss = 0.8870, Acc = 74.86%, Spikes = 0.0481\n",
            "Epoch 11, Batch 170: Loss = 0.6639, Acc = 75.02%, Spikes = 0.0498\n",
            "Epoch 11, Batch 180: Loss = 0.9255, Acc = 74.97%, Spikes = 0.0477\n",
            "Epoch 11, Batch 190: Loss = 0.6321, Acc = 74.93%, Spikes = 0.0517\n",
            "Epoch 11, Batch 200: Loss = 0.6903, Acc = 75.02%, Spikes = 0.0498\n",
            "Epoch 11, Batch 210: Loss = 0.7405, Acc = 74.81%, Spikes = 0.0454\n",
            "Epoch 11, Batch 220: Loss = 0.5503, Acc = 74.73%, Spikes = 0.0487\n",
            "Epoch 11, Batch 230: Loss = 0.7419, Acc = 74.74%, Spikes = 0.0428\n",
            "Epoch 11, Batch 240: Loss = 0.9357, Acc = 74.62%, Spikes = 0.0482\n",
            "Epoch 11, Batch 250: Loss = 1.0335, Acc = 74.59%, Spikes = 0.0488\n",
            "Epoch 11, Batch 260: Loss = 0.8027, Acc = 74.59%, Spikes = 0.0486\n",
            "Epoch 11, Batch 270: Loss = 0.9620, Acc = 74.48%, Spikes = 0.0494\n",
            "Epoch 11, Batch 280: Loss = 1.0062, Acc = 74.30%, Spikes = 0.0531\n",
            "Epoch 11, Batch 290: Loss = 1.0088, Acc = 74.22%, Spikes = 0.0489\n",
            "Epoch 11, Batch 300: Loss = 0.8407, Acc = 74.19%, Spikes = 0.0504\n",
            "Epoch 11, Batch 310: Loss = 1.2458, Acc = 74.14%, Spikes = 0.0479\n",
            "Epoch 11, Batch 320: Loss = 0.8194, Acc = 74.22%, Spikes = 0.0499\n",
            "Epoch 11, Batch 330: Loss = 0.9402, Acc = 74.31%, Spikes = 0.0486\n",
            "Epoch 11, Batch 340: Loss = 0.8470, Acc = 74.29%, Spikes = 0.0555\n",
            "Epoch 11, Batch 350: Loss = 0.6994, Acc = 74.38%, Spikes = 0.0494\n",
            "Epoch 11, Batch 360: Loss = 0.6823, Acc = 74.45%, Spikes = 0.0534\n",
            "Epoch 11, Batch 370: Loss = 1.0959, Acc = 74.44%, Spikes = 0.0507\n",
            "Epoch 11, Batch 380: Loss = 0.7721, Acc = 74.45%, Spikes = 0.0452\n",
            "Epoch 11, Batch 390: Loss = 0.8549, Acc = 74.40%, Spikes = 0.0493\n",
            "Epoch 11, Batch 400: Loss = 0.9277, Acc = 74.37%, Spikes = 0.0494\n",
            "Epoch 11, Batch 410: Loss = 0.6958, Acc = 74.41%, Spikes = 0.0511\n",
            "Epoch 11, Batch 420: Loss = 1.0302, Acc = 74.50%, Spikes = 0.0464\n",
            "Epoch 11, Batch 430: Loss = 0.7486, Acc = 74.43%, Spikes = 0.0456\n",
            "Epoch 11, Batch 440: Loss = 0.8692, Acc = 74.37%, Spikes = 0.0474\n",
            "Epoch 11, Batch 450: Loss = 0.9961, Acc = 74.34%, Spikes = 0.0481\n",
            "Epoch 11, Batch 460: Loss = 0.6981, Acc = 74.40%, Spikes = 0.0523\n",
            "Epoch 11, Batch 470: Loss = 0.6308, Acc = 74.42%, Spikes = 0.0468\n",
            "Epoch 11, Batch 480: Loss = 0.7282, Acc = 74.43%, Spikes = 0.0518\n",
            "Epoch 11, Batch 490: Loss = 0.9974, Acc = 74.31%, Spikes = 0.0443\n",
            "Epoch 11, Batch 500: Loss = 0.7880, Acc = 74.27%, Spikes = 0.0494\n",
            "Epoch 11, Batch 510: Loss = 1.0887, Acc = 74.25%, Spikes = 0.0412\n",
            "Epoch 11, Batch 520: Loss = 0.7058, Acc = 74.32%, Spikes = 0.0509\n",
            "Epoch 11, Batch 530: Loss = 1.1723, Acc = 74.33%, Spikes = 0.0478\n",
            "Epoch 11, Batch 540: Loss = 0.7176, Acc = 74.27%, Spikes = 0.0502\n",
            "Epoch 11, Batch 550: Loss = 0.8721, Acc = 74.27%, Spikes = 0.0491\n",
            "Epoch 11, Batch 560: Loss = 0.6256, Acc = 74.24%, Spikes = 0.0506\n",
            "Epoch 11, Batch 570: Loss = 0.8987, Acc = 74.24%, Spikes = 0.0489\n",
            "Epoch 11, Batch 580: Loss = 1.0923, Acc = 74.27%, Spikes = 0.0488\n",
            "Epoch 11, Batch 590: Loss = 0.6309, Acc = 74.25%, Spikes = 0.0499\n",
            "Epoch 11, Batch 600: Loss = 0.8627, Acc = 74.32%, Spikes = 0.0495\n",
            "Epoch 11, Batch 610: Loss = 0.7660, Acc = 74.35%, Spikes = 0.0482\n",
            "Epoch 11, Batch 620: Loss = 0.5713, Acc = 74.37%, Spikes = 0.0506\n",
            "Epoch 11, Batch 630: Loss = 0.7398, Acc = 74.31%, Spikes = 0.0500\n",
            "Epoch 11, Batch 640: Loss = 0.8632, Acc = 74.30%, Spikes = 0.0459\n",
            "Epoch 11, Batch 650: Loss = 0.9000, Acc = 74.26%, Spikes = 0.0525\n",
            "Epoch 11, Batch 660: Loss = 0.6782, Acc = 74.30%, Spikes = 0.0479\n",
            "Epoch 11, Batch 670: Loss = 1.2062, Acc = 74.36%, Spikes = 0.0497\n",
            "Epoch 11, Batch 680: Loss = 0.7304, Acc = 74.32%, Spikes = 0.0507\n",
            "Epoch 11, Batch 690: Loss = 0.6943, Acc = 74.32%, Spikes = 0.0536\n",
            "Epoch 11, Batch 700: Loss = 0.7158, Acc = 74.29%, Spikes = 0.0558\n",
            "Epoch 11, Batch 710: Loss = 0.6600, Acc = 74.34%, Spikes = 0.0527\n",
            "Epoch 11, Batch 720: Loss = 0.6382, Acc = 74.35%, Spikes = 0.0508\n",
            "Epoch 11, Batch 730: Loss = 1.0820, Acc = 74.30%, Spikes = 0.0476\n",
            "Epoch 11, Batch 740: Loss = 0.8817, Acc = 74.29%, Spikes = 0.0498\n",
            "Epoch 11, Batch 750: Loss = 0.8471, Acc = 74.26%, Spikes = 0.0502\n",
            "Epoch 11, Batch 760: Loss = 0.9388, Acc = 74.28%, Spikes = 0.0510\n",
            "Epoch 11, Batch 770: Loss = 0.6004, Acc = 74.33%, Spikes = 0.0489\n",
            "Epoch 11, Batch 780: Loss = 0.9193, Acc = 74.34%, Spikes = 0.0478\n",
            "Epoch 11, Batch 790: Loss = 0.8818, Acc = 74.34%, Spikes = 0.0484\n",
            "Epoch 11, Batch 800: Loss = 0.6572, Acc = 74.38%, Spikes = 0.0466\n",
            "Epoch 11, Batch 810: Loss = 1.0219, Acc = 74.40%, Spikes = 0.0523\n",
            "Epoch 11, Batch 820: Loss = 1.0534, Acc = 74.43%, Spikes = 0.0509\n",
            "Epoch 11, Batch 830: Loss = 0.8513, Acc = 74.44%, Spikes = 0.0519\n",
            "Epoch 11, Batch 840: Loss = 1.1067, Acc = 74.41%, Spikes = 0.0499\n",
            "Epoch 11, Batch 850: Loss = 0.8865, Acc = 74.42%, Spikes = 0.0472\n",
            "Epoch 11, Batch 860: Loss = 0.8629, Acc = 74.40%, Spikes = 0.0467\n",
            "Epoch 11, Batch 870: Loss = 0.6625, Acc = 74.44%, Spikes = 0.0512\n",
            "Epoch 11, Batch 880: Loss = 1.0331, Acc = 74.43%, Spikes = 0.0457\n",
            "Epoch 11, Batch 890: Loss = 0.7863, Acc = 74.44%, Spikes = 0.0529\n",
            "Epoch 11, Batch 900: Loss = 0.8188, Acc = 74.40%, Spikes = 0.0490\n",
            "Epoch 11, Batch 910: Loss = 0.9816, Acc = 74.37%, Spikes = 0.0494\n",
            "Epoch 11, Batch 920: Loss = 0.6352, Acc = 74.34%, Spikes = 0.0491\n",
            "Epoch 11, Batch 930: Loss = 0.6979, Acc = 74.36%, Spikes = 0.0517\n",
            "Epoch 11, Batch 940: Loss = 1.0381, Acc = 74.32%, Spikes = 0.0483\n",
            "Epoch 11, Batch 950: Loss = 0.7019, Acc = 74.33%, Spikes = 0.0488\n",
            "Epoch 11, Batch 960: Loss = 0.8538, Acc = 74.27%, Spikes = 0.0487\n",
            "Epoch 11, Batch 970: Loss = 0.7633, Acc = 74.29%, Spikes = 0.0472\n",
            "Epoch 11, Batch 980: Loss = 1.0335, Acc = 74.34%, Spikes = 0.0512\n",
            "Epoch 11, Batch 990: Loss = 1.0981, Acc = 74.34%, Spikes = 0.0541\n",
            "Epoch 11, Batch 1000: Loss = 0.7866, Acc = 74.35%, Spikes = 0.0498\n",
            "Epoch 11, Batch 1010: Loss = 0.6736, Acc = 74.38%, Spikes = 0.0519\n",
            "Epoch 11, Batch 1020: Loss = 0.6476, Acc = 74.42%, Spikes = 0.0529\n",
            "Epoch 11, Batch 1030: Loss = 1.0400, Acc = 74.45%, Spikes = 0.0516\n",
            "Epoch 11, Batch 1040: Loss = 0.9683, Acc = 74.41%, Spikes = 0.0482\n",
            "Epoch 11, Batch 1050: Loss = 0.6676, Acc = 74.42%, Spikes = 0.0482\n",
            "Epoch 11, Batch 1060: Loss = 0.8468, Acc = 74.44%, Spikes = 0.0503\n",
            "Epoch 11, Batch 1070: Loss = 0.7540, Acc = 74.42%, Spikes = 0.0459\n",
            "Epoch 11, Batch 1080: Loss = 0.8331, Acc = 74.41%, Spikes = 0.0484\n",
            "Epoch 11, Batch 1090: Loss = 0.6480, Acc = 74.44%, Spikes = 0.0532\n",
            "Epoch 11, Batch 1100: Loss = 0.8608, Acc = 74.43%, Spikes = 0.0451\n",
            "Epoch 11, Batch 1110: Loss = 1.1760, Acc = 74.43%, Spikes = 0.0514\n",
            "Epoch 11, Batch 1120: Loss = 0.7574, Acc = 74.41%, Spikes = 0.0461\n",
            "Epoch 11, Batch 1130: Loss = 0.5833, Acc = 74.44%, Spikes = 0.0511\n",
            "Epoch 11, Batch 1140: Loss = 0.5837, Acc = 74.43%, Spikes = 0.0512\n",
            "Epoch 11, Batch 1150: Loss = 0.8870, Acc = 74.41%, Spikes = 0.0517\n",
            "Epoch 11, Batch 1160: Loss = 0.8249, Acc = 74.40%, Spikes = 0.0498\n",
            "Epoch 11, Batch 1170: Loss = 0.9648, Acc = 74.41%, Spikes = 0.0545\n",
            "Epoch 11, Batch 1180: Loss = 0.8387, Acc = 74.39%, Spikes = 0.0494\n",
            "Epoch 11, Batch 1190: Loss = 0.7450, Acc = 74.37%, Spikes = 0.0500\n",
            "Epoch 11, Batch 1200: Loss = 1.0118, Acc = 74.36%, Spikes = 0.0527\n",
            "Epoch 11, Batch 1210: Loss = 0.7495, Acc = 74.37%, Spikes = 0.0514\n",
            "Epoch 11, Batch 1220: Loss = 0.7802, Acc = 74.34%, Spikes = 0.0470\n",
            "Epoch 11, Batch 1230: Loss = 0.7622, Acc = 74.34%, Spikes = 0.0527\n",
            "Epoch 11, Batch 1240: Loss = 0.7914, Acc = 74.33%, Spikes = 0.0558\n",
            "Epoch 11, Batch 1250: Loss = 1.0990, Acc = 74.32%, Spikes = 0.0455\n",
            "Epoch 11, Batch 1260: Loss = 1.1486, Acc = 74.33%, Spikes = 0.0472\n",
            "Epoch 11, Batch 1270: Loss = 0.6776, Acc = 74.33%, Spikes = 0.0505\n",
            "Epoch 11, Batch 1280: Loss = 0.8112, Acc = 74.33%, Spikes = 0.0501\n",
            "Epoch 11, Batch 1290: Loss = 0.9141, Acc = 74.34%, Spikes = 0.0476\n",
            "Epoch 11, Batch 1300: Loss = 0.8802, Acc = 74.33%, Spikes = 0.0514\n",
            "Epoch 11, Batch 1310: Loss = 0.8171, Acc = 74.33%, Spikes = 0.0523\n",
            "Epoch 11, Batch 1320: Loss = 0.7418, Acc = 74.34%, Spikes = 0.0519\n",
            "Epoch 11, Batch 1330: Loss = 0.8619, Acc = 74.35%, Spikes = 0.0482\n",
            "Epoch 11, Batch 1340: Loss = 0.6817, Acc = 74.38%, Spikes = 0.0525\n",
            "Epoch 11, Batch 1350: Loss = 0.5832, Acc = 74.37%, Spikes = 0.0474\n",
            "Epoch 11, Batch 1360: Loss = 0.7268, Acc = 74.38%, Spikes = 0.0515\n",
            "Epoch 11, Batch 1370: Loss = 0.9478, Acc = 74.38%, Spikes = 0.0495\n",
            "Epoch 11, Batch 1380: Loss = 0.7858, Acc = 74.37%, Spikes = 0.0466\n",
            "Epoch 11, Batch 1390: Loss = 0.7897, Acc = 74.38%, Spikes = 0.0509\n",
            "Epoch 11, Batch 1400: Loss = 0.6531, Acc = 74.41%, Spikes = 0.0482\n",
            "Epoch 11, Batch 1410: Loss = 0.9985, Acc = 74.43%, Spikes = 0.0490\n",
            "Epoch 11, Batch 1420: Loss = 0.7778, Acc = 74.43%, Spikes = 0.0516\n",
            "Epoch 11, Batch 1430: Loss = 1.0624, Acc = 74.41%, Spikes = 0.0457\n",
            "Epoch 11, Batch 1440: Loss = 0.9529, Acc = 74.42%, Spikes = 0.0497\n",
            "Epoch 11, Batch 1450: Loss = 0.7032, Acc = 74.43%, Spikes = 0.0497\n",
            "Epoch 11, Batch 1460: Loss = 0.9790, Acc = 74.40%, Spikes = 0.0534\n",
            "Epoch 11, Batch 1470: Loss = 0.9906, Acc = 74.38%, Spikes = 0.0499\n",
            "Epoch 11, Batch 1480: Loss = 0.5968, Acc = 74.38%, Spikes = 0.0486\n",
            "Epoch 11, Batch 1490: Loss = 0.7421, Acc = 74.38%, Spikes = 0.0512\n",
            "Epoch 11, Batch 1500: Loss = 0.7720, Acc = 74.37%, Spikes = 0.0547\n",
            "Epoch 11, Batch 1510: Loss = 0.7318, Acc = 74.38%, Spikes = 0.0521\n",
            "Epoch 11, Batch 1520: Loss = 0.7756, Acc = 74.39%, Spikes = 0.0522\n",
            "Epoch 11, Batch 1530: Loss = 1.1150, Acc = 74.40%, Spikes = 0.0512\n",
            "Epoch 11, Batch 1540: Loss = 0.7700, Acc = 74.40%, Spikes = 0.0507\n",
            "Epoch 11, Batch 1550: Loss = 0.8232, Acc = 74.41%, Spikes = 0.0514\n",
            "Epoch 11, Batch 1560: Loss = 0.8116, Acc = 74.40%, Spikes = 0.0510\n",
            "Epoch 11, Batch 1570: Loss = 0.7030, Acc = 74.41%, Spikes = 0.0508\n",
            "Epoch 11, Batch 1580: Loss = 0.9219, Acc = 74.40%, Spikes = 0.0506\n",
            "Epoch 11, Batch 1590: Loss = 0.6383, Acc = 74.43%, Spikes = 0.0531\n",
            "Epoch 11, Batch 1600: Loss = 0.8645, Acc = 74.44%, Spikes = 0.0512\n",
            "Epoch 11, Batch 1610: Loss = 1.2136, Acc = 74.45%, Spikes = 0.0520\n",
            "Epoch 11, Batch 1620: Loss = 1.0360, Acc = 74.46%, Spikes = 0.0484\n",
            "Epoch 11, Batch 1630: Loss = 0.8090, Acc = 74.46%, Spikes = 0.0554\n",
            "Epoch 11, Batch 1640: Loss = 1.0497, Acc = 74.47%, Spikes = 0.0495\n",
            "Epoch 11, Batch 1650: Loss = 0.8931, Acc = 74.46%, Spikes = 0.0520\n",
            "Epoch 11, Batch 1660: Loss = 0.8782, Acc = 74.48%, Spikes = 0.0497\n",
            "Epoch 11, Batch 1670: Loss = 0.6646, Acc = 74.48%, Spikes = 0.0486\n",
            "Epoch 11, Batch 1680: Loss = 0.7303, Acc = 74.48%, Spikes = 0.0517\n",
            "Epoch 11, Batch 1690: Loss = 0.9267, Acc = 74.48%, Spikes = 0.0480\n",
            "Epoch 11, Batch 1700: Loss = 0.5564, Acc = 74.48%, Spikes = 0.0519\n",
            "Epoch 11, Batch 1710: Loss = 0.7173, Acc = 74.49%, Spikes = 0.0519\n",
            "Epoch 11, Batch 1720: Loss = 1.0747, Acc = 74.51%, Spikes = 0.0471\n",
            "Epoch 11, Batch 1730: Loss = 1.0651, Acc = 74.50%, Spikes = 0.0489\n",
            "Epoch 11, Batch 1740: Loss = 0.8096, Acc = 74.51%, Spikes = 0.0478\n",
            "Epoch 11, Batch 1750: Loss = 1.1011, Acc = 74.52%, Spikes = 0.0508\n",
            "Epoch 11, Batch 1760: Loss = 1.0153, Acc = 74.51%, Spikes = 0.0497\n",
            "Epoch 11, Batch 1770: Loss = 0.9572, Acc = 74.50%, Spikes = 0.0497\n",
            "Epoch 11, Batch 1780: Loss = 0.8515, Acc = 74.49%, Spikes = 0.0511\n",
            "Epoch 11, Batch 1790: Loss = 0.9012, Acc = 74.51%, Spikes = 0.0498\n",
            "Epoch 11, Batch 1800: Loss = 0.9572, Acc = 74.50%, Spikes = 0.0520\n",
            "Epoch 11, Batch 1810: Loss = 0.6847, Acc = 74.51%, Spikes = 0.0513\n",
            "Epoch 11, Batch 1820: Loss = 0.7690, Acc = 74.50%, Spikes = 0.0474\n",
            "Epoch 11, Batch 1830: Loss = 0.7283, Acc = 74.49%, Spikes = 0.0519\n",
            "Epoch 11, Batch 1840: Loss = 1.0040, Acc = 74.47%, Spikes = 0.0505\n",
            "Epoch 11, Batch 1850: Loss = 0.7781, Acc = 74.47%, Spikes = 0.0460\n",
            "Epoch 11, Batch 1860: Loss = 0.9364, Acc = 74.48%, Spikes = 0.0481\n",
            "Epoch 11, Batch 1870: Loss = 0.8030, Acc = 74.45%, Spikes = 0.0514\n",
            "Epoch 11/15:\n",
            "Train Loss: 0.8235 | Train Acc: 74.44% | Train Spikes: 0.0497\n",
            "Test Acc: 75.08% | Test Spikes: 0.0512\n",
            "------------------------------------------------------------\n",
            "Epoch 12, Batch 0: Loss = 1.1447, Acc = 65.62%, Spikes = 0.0496\n",
            "Epoch 12, Batch 10: Loss = 0.8157, Acc = 76.70%, Spikes = 0.0467\n",
            "Epoch 12, Batch 20: Loss = 0.8172, Acc = 75.30%, Spikes = 0.0475\n",
            "Epoch 12, Batch 30: Loss = 1.0797, Acc = 73.39%, Spikes = 0.0466\n",
            "Epoch 12, Batch 40: Loss = 1.0551, Acc = 73.02%, Spikes = 0.0531\n",
            "Epoch 12, Batch 50: Loss = 0.5310, Acc = 72.37%, Spikes = 0.0505\n",
            "Epoch 12, Batch 60: Loss = 0.8727, Acc = 73.00%, Spikes = 0.0506\n",
            "Epoch 12, Batch 70: Loss = 0.8973, Acc = 72.93%, Spikes = 0.0512\n",
            "Epoch 12, Batch 80: Loss = 0.5650, Acc = 73.19%, Spikes = 0.0545\n",
            "Epoch 12, Batch 90: Loss = 0.6422, Acc = 73.32%, Spikes = 0.0520\n",
            "Epoch 12, Batch 100: Loss = 0.7692, Acc = 73.27%, Spikes = 0.0511\n",
            "Epoch 12, Batch 110: Loss = 0.7390, Acc = 73.25%, Spikes = 0.0519\n",
            "Epoch 12, Batch 120: Loss = 0.8303, Acc = 73.58%, Spikes = 0.0510\n",
            "Epoch 12, Batch 130: Loss = 0.8447, Acc = 73.90%, Spikes = 0.0528\n",
            "Epoch 12, Batch 140: Loss = 1.2672, Acc = 73.65%, Spikes = 0.0515\n",
            "Epoch 12, Batch 150: Loss = 0.9070, Acc = 73.76%, Spikes = 0.0503\n",
            "Epoch 12, Batch 160: Loss = 1.0065, Acc = 73.76%, Spikes = 0.0474\n",
            "Epoch 12, Batch 170: Loss = 1.1463, Acc = 73.70%, Spikes = 0.0530\n",
            "Epoch 12, Batch 180: Loss = 1.0118, Acc = 73.64%, Spikes = 0.0524\n",
            "Epoch 12, Batch 190: Loss = 1.2026, Acc = 73.67%, Spikes = 0.0464\n",
            "Epoch 12, Batch 200: Loss = 0.4450, Acc = 73.74%, Spikes = 0.0540\n",
            "Epoch 12, Batch 210: Loss = 0.6293, Acc = 73.96%, Spikes = 0.0517\n",
            "Epoch 12, Batch 220: Loss = 0.7315, Acc = 74.00%, Spikes = 0.0542\n",
            "Epoch 12, Batch 230: Loss = 0.9042, Acc = 74.12%, Spikes = 0.0521\n",
            "Epoch 12, Batch 240: Loss = 0.7625, Acc = 74.14%, Spikes = 0.0498\n",
            "Epoch 12, Batch 250: Loss = 0.7820, Acc = 74.13%, Spikes = 0.0517\n",
            "Epoch 12, Batch 260: Loss = 0.9325, Acc = 74.19%, Spikes = 0.0474\n",
            "Epoch 12, Batch 270: Loss = 0.6697, Acc = 74.22%, Spikes = 0.0490\n",
            "Epoch 12, Batch 280: Loss = 0.8493, Acc = 74.32%, Spikes = 0.0522\n",
            "Epoch 12, Batch 290: Loss = 1.1167, Acc = 74.33%, Spikes = 0.0487\n",
            "Epoch 12, Batch 300: Loss = 0.5639, Acc = 74.41%, Spikes = 0.0481\n",
            "Epoch 12, Batch 310: Loss = 0.7312, Acc = 74.36%, Spikes = 0.0561\n",
            "Epoch 12, Batch 320: Loss = 0.8859, Acc = 74.38%, Spikes = 0.0496\n",
            "Epoch 12, Batch 330: Loss = 0.8445, Acc = 74.45%, Spikes = 0.0511\n",
            "Epoch 12, Batch 340: Loss = 0.8637, Acc = 74.53%, Spikes = 0.0511\n",
            "Epoch 12, Batch 350: Loss = 0.6476, Acc = 74.58%, Spikes = 0.0534\n",
            "Epoch 12, Batch 360: Loss = 0.6601, Acc = 74.61%, Spikes = 0.0512\n",
            "Epoch 12, Batch 370: Loss = 1.1517, Acc = 74.59%, Spikes = 0.0453\n",
            "Epoch 12, Batch 380: Loss = 0.9652, Acc = 74.59%, Spikes = 0.0499\n",
            "Epoch 12, Batch 390: Loss = 0.6719, Acc = 74.62%, Spikes = 0.0505\n",
            "Epoch 12, Batch 400: Loss = 0.9292, Acc = 74.59%, Spikes = 0.0509\n",
            "Epoch 12, Batch 410: Loss = 0.6047, Acc = 74.65%, Spikes = 0.0517\n",
            "Epoch 12, Batch 420: Loss = 0.7978, Acc = 74.76%, Spikes = 0.0518\n",
            "Epoch 12, Batch 430: Loss = 0.8238, Acc = 74.73%, Spikes = 0.0514\n",
            "Epoch 12, Batch 440: Loss = 0.5044, Acc = 74.71%, Spikes = 0.0535\n",
            "Epoch 12, Batch 450: Loss = 0.9510, Acc = 74.67%, Spikes = 0.0507\n",
            "Epoch 12, Batch 460: Loss = 0.8200, Acc = 74.60%, Spikes = 0.0506\n",
            "Epoch 12, Batch 470: Loss = 0.9280, Acc = 74.58%, Spikes = 0.0487\n",
            "Epoch 12, Batch 480: Loss = 1.0690, Acc = 74.49%, Spikes = 0.0520\n",
            "Epoch 12, Batch 490: Loss = 0.7608, Acc = 74.54%, Spikes = 0.0508\n",
            "Epoch 12, Batch 500: Loss = 0.8690, Acc = 74.44%, Spikes = 0.0511\n",
            "Epoch 12, Batch 510: Loss = 1.0039, Acc = 74.43%, Spikes = 0.0539\n",
            "Epoch 12, Batch 520: Loss = 0.8563, Acc = 74.37%, Spikes = 0.0523\n",
            "Epoch 12, Batch 530: Loss = 0.9459, Acc = 74.35%, Spikes = 0.0503\n",
            "Epoch 12, Batch 540: Loss = 0.8474, Acc = 74.37%, Spikes = 0.0491\n",
            "Epoch 12, Batch 550: Loss = 0.8745, Acc = 74.35%, Spikes = 0.0504\n",
            "Epoch 12, Batch 560: Loss = 0.7574, Acc = 74.42%, Spikes = 0.0511\n",
            "Epoch 12, Batch 570: Loss = 0.9828, Acc = 74.50%, Spikes = 0.0568\n",
            "Epoch 12, Batch 580: Loss = 0.7634, Acc = 74.57%, Spikes = 0.0517\n",
            "Epoch 12, Batch 590: Loss = 0.6891, Acc = 74.67%, Spikes = 0.0536\n",
            "Epoch 12, Batch 600: Loss = 0.9348, Acc = 74.64%, Spikes = 0.0483\n",
            "Epoch 12, Batch 610: Loss = 0.8143, Acc = 74.64%, Spikes = 0.0520\n",
            "Epoch 12, Batch 620: Loss = 0.6974, Acc = 74.73%, Spikes = 0.0511\n",
            "Epoch 12, Batch 630: Loss = 0.7109, Acc = 74.72%, Spikes = 0.0510\n",
            "Epoch 12, Batch 640: Loss = 1.0080, Acc = 74.82%, Spikes = 0.0497\n",
            "Epoch 12, Batch 650: Loss = 0.7001, Acc = 74.85%, Spikes = 0.0512\n",
            "Epoch 12, Batch 660: Loss = 0.8274, Acc = 74.84%, Spikes = 0.0547\n",
            "Epoch 12, Batch 670: Loss = 0.8185, Acc = 74.90%, Spikes = 0.0522\n",
            "Epoch 12, Batch 680: Loss = 0.7460, Acc = 74.89%, Spikes = 0.0484\n",
            "Epoch 12, Batch 690: Loss = 0.6887, Acc = 74.93%, Spikes = 0.0483\n",
            "Epoch 12, Batch 700: Loss = 0.7339, Acc = 74.94%, Spikes = 0.0530\n",
            "Epoch 12, Batch 710: Loss = 0.6802, Acc = 74.96%, Spikes = 0.0498\n",
            "Epoch 12, Batch 720: Loss = 0.8105, Acc = 74.95%, Spikes = 0.0493\n",
            "Epoch 12, Batch 730: Loss = 0.4686, Acc = 75.00%, Spikes = 0.0539\n",
            "Epoch 12, Batch 740: Loss = 0.7591, Acc = 75.02%, Spikes = 0.0494\n",
            "Epoch 12, Batch 750: Loss = 0.6649, Acc = 75.05%, Spikes = 0.0525\n",
            "Epoch 12, Batch 760: Loss = 1.0106, Acc = 75.00%, Spikes = 0.0514\n",
            "Epoch 12, Batch 770: Loss = 1.2394, Acc = 74.96%, Spikes = 0.0483\n",
            "Epoch 12, Batch 780: Loss = 0.8530, Acc = 75.00%, Spikes = 0.0493\n",
            "Epoch 12, Batch 790: Loss = 0.8897, Acc = 75.00%, Spikes = 0.0498\n",
            "Epoch 12, Batch 800: Loss = 0.6298, Acc = 75.06%, Spikes = 0.0500\n",
            "Epoch 12, Batch 810: Loss = 1.4402, Acc = 75.04%, Spikes = 0.0501\n",
            "Epoch 12, Batch 820: Loss = 0.8306, Acc = 75.05%, Spikes = 0.0542\n",
            "Epoch 12, Batch 830: Loss = 0.8906, Acc = 75.02%, Spikes = 0.0531\n",
            "Epoch 12, Batch 840: Loss = 1.1444, Acc = 75.01%, Spikes = 0.0482\n",
            "Epoch 12, Batch 850: Loss = 0.8383, Acc = 74.98%, Spikes = 0.0528\n",
            "Epoch 12, Batch 860: Loss = 0.6642, Acc = 74.95%, Spikes = 0.0553\n",
            "Epoch 12, Batch 870: Loss = 0.8129, Acc = 74.94%, Spikes = 0.0521\n",
            "Epoch 12, Batch 880: Loss = 0.9073, Acc = 74.96%, Spikes = 0.0516\n",
            "Epoch 12, Batch 890: Loss = 0.6701, Acc = 74.95%, Spikes = 0.0497\n",
            "Epoch 12, Batch 900: Loss = 0.9233, Acc = 74.96%, Spikes = 0.0556\n",
            "Epoch 12, Batch 910: Loss = 0.8057, Acc = 74.90%, Spikes = 0.0574\n",
            "Epoch 12, Batch 920: Loss = 0.5033, Acc = 74.90%, Spikes = 0.0500\n",
            "Epoch 12, Batch 930: Loss = 0.6366, Acc = 74.89%, Spikes = 0.0514\n",
            "Epoch 12, Batch 940: Loss = 0.9330, Acc = 74.88%, Spikes = 0.0480\n",
            "Epoch 12, Batch 950: Loss = 0.6079, Acc = 74.90%, Spikes = 0.0504\n",
            "Epoch 12, Batch 960: Loss = 0.7348, Acc = 74.91%, Spikes = 0.0537\n",
            "Epoch 12, Batch 970: Loss = 0.6423, Acc = 74.90%, Spikes = 0.0577\n",
            "Epoch 12, Batch 980: Loss = 1.0584, Acc = 74.95%, Spikes = 0.0517\n",
            "Epoch 12, Batch 990: Loss = 0.6684, Acc = 74.96%, Spikes = 0.0545\n",
            "Epoch 12, Batch 1000: Loss = 0.8103, Acc = 74.97%, Spikes = 0.0544\n",
            "Epoch 12, Batch 1010: Loss = 0.9453, Acc = 75.00%, Spikes = 0.0500\n",
            "Epoch 12, Batch 1020: Loss = 0.6734, Acc = 75.01%, Spikes = 0.0533\n",
            "Epoch 12, Batch 1030: Loss = 0.9746, Acc = 75.01%, Spikes = 0.0524\n",
            "Epoch 12, Batch 1040: Loss = 0.7536, Acc = 75.04%, Spikes = 0.0516\n",
            "Epoch 12, Batch 1050: Loss = 1.0256, Acc = 75.06%, Spikes = 0.0481\n",
            "Epoch 12, Batch 1060: Loss = 0.8100, Acc = 75.06%, Spikes = 0.0520\n",
            "Epoch 12, Batch 1070: Loss = 0.8382, Acc = 75.05%, Spikes = 0.0506\n",
            "Epoch 12, Batch 1080: Loss = 0.7847, Acc = 75.03%, Spikes = 0.0519\n",
            "Epoch 12, Batch 1090: Loss = 0.8550, Acc = 75.02%, Spikes = 0.0491\n",
            "Epoch 12, Batch 1100: Loss = 0.6642, Acc = 75.03%, Spikes = 0.0504\n",
            "Epoch 12, Batch 1110: Loss = 0.9533, Acc = 75.02%, Spikes = 0.0545\n",
            "Epoch 12, Batch 1120: Loss = 1.2799, Acc = 75.02%, Spikes = 0.0473\n",
            "Epoch 12, Batch 1130: Loss = 0.5896, Acc = 75.06%, Spikes = 0.0512\n",
            "Epoch 12, Batch 1140: Loss = 0.7170, Acc = 75.06%, Spikes = 0.0556\n",
            "Epoch 12, Batch 1150: Loss = 0.8790, Acc = 75.06%, Spikes = 0.0532\n",
            "Epoch 12, Batch 1160: Loss = 0.9044, Acc = 75.05%, Spikes = 0.0529\n",
            "Epoch 12, Batch 1170: Loss = 0.7888, Acc = 75.08%, Spikes = 0.0470\n",
            "Epoch 12, Batch 1180: Loss = 0.9878, Acc = 75.07%, Spikes = 0.0476\n",
            "Epoch 12, Batch 1190: Loss = 0.7340, Acc = 75.10%, Spikes = 0.0559\n",
            "Epoch 12, Batch 1200: Loss = 0.7724, Acc = 75.06%, Spikes = 0.0513\n",
            "Epoch 12, Batch 1210: Loss = 0.8392, Acc = 75.10%, Spikes = 0.0552\n",
            "Epoch 12, Batch 1220: Loss = 0.9453, Acc = 75.12%, Spikes = 0.0509\n",
            "Epoch 12, Batch 1230: Loss = 0.7860, Acc = 75.11%, Spikes = 0.0550\n",
            "Epoch 12, Batch 1240: Loss = 0.5640, Acc = 75.13%, Spikes = 0.0550\n",
            "Epoch 12, Batch 1250: Loss = 0.8213, Acc = 75.13%, Spikes = 0.0497\n",
            "Epoch 12, Batch 1260: Loss = 0.9285, Acc = 75.10%, Spikes = 0.0470\n",
            "Epoch 12, Batch 1270: Loss = 0.7242, Acc = 75.11%, Spikes = 0.0486\n",
            "Epoch 12, Batch 1280: Loss = 0.8804, Acc = 75.09%, Spikes = 0.0483\n",
            "Epoch 12, Batch 1290: Loss = 0.9346, Acc = 75.05%, Spikes = 0.0494\n",
            "Epoch 12, Batch 1300: Loss = 0.7102, Acc = 75.04%, Spikes = 0.0502\n",
            "Epoch 12, Batch 1310: Loss = 0.9164, Acc = 75.06%, Spikes = 0.0515\n",
            "Epoch 12, Batch 1320: Loss = 0.5483, Acc = 75.08%, Spikes = 0.0518\n",
            "Epoch 12, Batch 1330: Loss = 0.5395, Acc = 75.08%, Spikes = 0.0509\n",
            "Epoch 12, Batch 1340: Loss = 0.6680, Acc = 75.08%, Spikes = 0.0537\n",
            "Epoch 12, Batch 1350: Loss = 0.7637, Acc = 75.08%, Spikes = 0.0564\n",
            "Epoch 12, Batch 1360: Loss = 0.7562, Acc = 75.11%, Spikes = 0.0503\n",
            "Epoch 12, Batch 1370: Loss = 0.9073, Acc = 75.12%, Spikes = 0.0541\n",
            "Epoch 12, Batch 1380: Loss = 0.7120, Acc = 75.12%, Spikes = 0.0486\n",
            "Epoch 12, Batch 1390: Loss = 0.5724, Acc = 75.13%, Spikes = 0.0576\n",
            "Epoch 12, Batch 1400: Loss = 0.6290, Acc = 75.14%, Spikes = 0.0516\n",
            "Epoch 12, Batch 1410: Loss = 0.8296, Acc = 75.15%, Spikes = 0.0459\n",
            "Epoch 12, Batch 1420: Loss = 0.7562, Acc = 75.13%, Spikes = 0.0492\n",
            "Epoch 12, Batch 1430: Loss = 0.9512, Acc = 75.13%, Spikes = 0.0511\n",
            "Epoch 12, Batch 1440: Loss = 0.7133, Acc = 75.13%, Spikes = 0.0559\n",
            "Epoch 12, Batch 1450: Loss = 0.6113, Acc = 75.16%, Spikes = 0.0501\n",
            "Epoch 12, Batch 1460: Loss = 0.5654, Acc = 75.17%, Spikes = 0.0512\n",
            "Epoch 12, Batch 1470: Loss = 0.5013, Acc = 75.15%, Spikes = 0.0618\n",
            "Epoch 12, Batch 1480: Loss = 0.7627, Acc = 75.15%, Spikes = 0.0507\n",
            "Epoch 12, Batch 1490: Loss = 0.7713, Acc = 75.15%, Spikes = 0.0539\n",
            "Epoch 12, Batch 1500: Loss = 0.8174, Acc = 75.16%, Spikes = 0.0518\n",
            "Epoch 12, Batch 1510: Loss = 0.7745, Acc = 75.18%, Spikes = 0.0586\n",
            "Epoch 12, Batch 1520: Loss = 0.6662, Acc = 75.16%, Spikes = 0.0506\n",
            "Epoch 12, Batch 1530: Loss = 0.9523, Acc = 75.15%, Spikes = 0.0508\n",
            "Epoch 12, Batch 1540: Loss = 0.8689, Acc = 75.16%, Spikes = 0.0490\n",
            "Epoch 12, Batch 1550: Loss = 0.5840, Acc = 75.18%, Spikes = 0.0512\n",
            "Epoch 12, Batch 1560: Loss = 0.7406, Acc = 75.17%, Spikes = 0.0558\n",
            "Epoch 12, Batch 1570: Loss = 0.7702, Acc = 75.16%, Spikes = 0.0558\n",
            "Epoch 12, Batch 1580: Loss = 0.7013, Acc = 75.16%, Spikes = 0.0545\n",
            "Epoch 12, Batch 1590: Loss = 0.6179, Acc = 75.15%, Spikes = 0.0525\n",
            "Epoch 12, Batch 1600: Loss = 0.5359, Acc = 75.15%, Spikes = 0.0560\n",
            "Epoch 12, Batch 1610: Loss = 0.8060, Acc = 75.19%, Spikes = 0.0525\n",
            "Epoch 12, Batch 1620: Loss = 0.6462, Acc = 75.17%, Spikes = 0.0485\n",
            "Epoch 12, Batch 1630: Loss = 0.9625, Acc = 75.15%, Spikes = 0.0537\n",
            "Epoch 12, Batch 1640: Loss = 0.7556, Acc = 75.14%, Spikes = 0.0551\n",
            "Epoch 12, Batch 1650: Loss = 0.6891, Acc = 75.13%, Spikes = 0.0537\n",
            "Epoch 12, Batch 1660: Loss = 0.9442, Acc = 75.12%, Spikes = 0.0523\n",
            "Epoch 12, Batch 1670: Loss = 0.7167, Acc = 75.13%, Spikes = 0.0533\n",
            "Epoch 12, Batch 1680: Loss = 0.7541, Acc = 75.13%, Spikes = 0.0546\n",
            "Epoch 12, Batch 1690: Loss = 0.7513, Acc = 75.15%, Spikes = 0.0562\n",
            "Epoch 12, Batch 1700: Loss = 0.9924, Acc = 75.15%, Spikes = 0.0500\n",
            "Epoch 12, Batch 1710: Loss = 0.9967, Acc = 75.15%, Spikes = 0.0491\n",
            "Epoch 12, Batch 1720: Loss = 0.7948, Acc = 75.16%, Spikes = 0.0553\n",
            "Epoch 12, Batch 1730: Loss = 0.9042, Acc = 75.15%, Spikes = 0.0547\n",
            "Epoch 12, Batch 1740: Loss = 0.7380, Acc = 75.14%, Spikes = 0.0515\n",
            "Epoch 12, Batch 1750: Loss = 0.7017, Acc = 75.15%, Spikes = 0.0526\n",
            "Epoch 12, Batch 1760: Loss = 1.0635, Acc = 75.16%, Spikes = 0.0479\n",
            "Epoch 12, Batch 1770: Loss = 0.8989, Acc = 75.18%, Spikes = 0.0518\n",
            "Epoch 12, Batch 1780: Loss = 0.4826, Acc = 75.18%, Spikes = 0.0550\n",
            "Epoch 12, Batch 1790: Loss = 0.4525, Acc = 75.17%, Spikes = 0.0546\n",
            "Epoch 12, Batch 1800: Loss = 0.7909, Acc = 75.19%, Spikes = 0.0535\n",
            "Epoch 12, Batch 1810: Loss = 0.5266, Acc = 75.20%, Spikes = 0.0573\n",
            "Epoch 12, Batch 1820: Loss = 0.6081, Acc = 75.21%, Spikes = 0.0526\n",
            "Epoch 12, Batch 1830: Loss = 0.7488, Acc = 75.20%, Spikes = 0.0516\n",
            "Epoch 12, Batch 1840: Loss = 0.5279, Acc = 75.20%, Spikes = 0.0545\n",
            "Epoch 12, Batch 1850: Loss = 0.7983, Acc = 75.20%, Spikes = 0.0521\n",
            "Epoch 12, Batch 1860: Loss = 0.7464, Acc = 75.18%, Spikes = 0.0567\n",
            "Epoch 12, Batch 1870: Loss = 0.5819, Acc = 75.19%, Spikes = 0.0548\n",
            "Epoch 12/15:\n",
            "Train Loss: 0.7998 | Train Acc: 75.18% | Train Spikes: 0.0517\n",
            "Test Acc: 75.78% | Test Spikes: 0.0529\n",
            "------------------------------------------------------------\n",
            "Epoch 13, Batch 0: Loss = 0.8493, Acc = 75.00%, Spikes = 0.0487\n",
            "Epoch 13, Batch 10: Loss = 0.7912, Acc = 71.31%, Spikes = 0.0521\n",
            "Epoch 13, Batch 20: Loss = 0.6519, Acc = 73.07%, Spikes = 0.0500\n",
            "Epoch 13, Batch 30: Loss = 0.7983, Acc = 73.08%, Spikes = 0.0538\n",
            "Epoch 13, Batch 40: Loss = 0.8833, Acc = 74.16%, Spikes = 0.0574\n",
            "Epoch 13, Batch 50: Loss = 0.8406, Acc = 74.02%, Spikes = 0.0495\n",
            "Epoch 13, Batch 60: Loss = 0.6889, Acc = 74.39%, Spikes = 0.0528\n",
            "Epoch 13, Batch 70: Loss = 0.6079, Acc = 74.34%, Spikes = 0.0556\n",
            "Epoch 13, Batch 80: Loss = 0.8489, Acc = 74.19%, Spikes = 0.0523\n",
            "Epoch 13, Batch 90: Loss = 0.8583, Acc = 74.14%, Spikes = 0.0506\n",
            "Epoch 13, Batch 100: Loss = 0.6161, Acc = 74.23%, Spikes = 0.0532\n",
            "Epoch 13, Batch 110: Loss = 0.5497, Acc = 74.55%, Spikes = 0.0541\n",
            "Epoch 13, Batch 120: Loss = 0.4999, Acc = 74.95%, Spikes = 0.0575\n",
            "Epoch 13, Batch 130: Loss = 0.8203, Acc = 74.69%, Spikes = 0.0522\n",
            "Epoch 13, Batch 140: Loss = 1.0793, Acc = 74.78%, Spikes = 0.0484\n",
            "Epoch 13, Batch 150: Loss = 0.7218, Acc = 74.69%, Spikes = 0.0521\n",
            "Epoch 13, Batch 160: Loss = 0.9291, Acc = 74.77%, Spikes = 0.0577\n",
            "Epoch 13, Batch 170: Loss = 0.8104, Acc = 74.69%, Spikes = 0.0501\n",
            "Epoch 13, Batch 180: Loss = 0.9399, Acc = 74.53%, Spikes = 0.0539\n",
            "Epoch 13, Batch 190: Loss = 0.9095, Acc = 74.57%, Spikes = 0.0564\n",
            "Epoch 13, Batch 200: Loss = 0.8118, Acc = 74.66%, Spikes = 0.0544\n",
            "Epoch 13, Batch 210: Loss = 0.6456, Acc = 74.70%, Spikes = 0.0514\n",
            "Epoch 13, Batch 220: Loss = 0.8328, Acc = 74.75%, Spikes = 0.0556\n",
            "Epoch 13, Batch 230: Loss = 0.7630, Acc = 74.68%, Spikes = 0.0530\n",
            "Epoch 13, Batch 240: Loss = 0.5179, Acc = 74.91%, Spikes = 0.0530\n",
            "Epoch 13, Batch 250: Loss = 0.6279, Acc = 74.86%, Spikes = 0.0483\n",
            "Epoch 13, Batch 260: Loss = 1.2182, Acc = 74.82%, Spikes = 0.0519\n",
            "Epoch 13, Batch 270: Loss = 0.6488, Acc = 74.85%, Spikes = 0.0517\n",
            "Epoch 13, Batch 280: Loss = 0.6821, Acc = 74.98%, Spikes = 0.0531\n",
            "Epoch 13, Batch 290: Loss = 0.6592, Acc = 74.82%, Spikes = 0.0498\n",
            "Epoch 13, Batch 300: Loss = 0.9497, Acc = 74.80%, Spikes = 0.0497\n",
            "Epoch 13, Batch 310: Loss = 0.6625, Acc = 74.70%, Spikes = 0.0519\n",
            "Epoch 13, Batch 320: Loss = 0.9796, Acc = 74.66%, Spikes = 0.0544\n",
            "Epoch 13, Batch 330: Loss = 1.3486, Acc = 74.58%, Spikes = 0.0479\n",
            "Epoch 13, Batch 340: Loss = 1.1714, Acc = 74.57%, Spikes = 0.0505\n",
            "Epoch 13, Batch 350: Loss = 1.0512, Acc = 74.71%, Spikes = 0.0545\n",
            "Epoch 13, Batch 360: Loss = 0.8015, Acc = 74.68%, Spikes = 0.0544\n",
            "Epoch 13, Batch 370: Loss = 1.0334, Acc = 74.71%, Spikes = 0.0530\n",
            "Epoch 13, Batch 380: Loss = 0.8718, Acc = 74.71%, Spikes = 0.0499\n",
            "Epoch 13, Batch 390: Loss = 0.6158, Acc = 74.68%, Spikes = 0.0520\n",
            "Epoch 13, Batch 400: Loss = 0.7781, Acc = 74.68%, Spikes = 0.0523\n",
            "Epoch 13, Batch 410: Loss = 0.7957, Acc = 74.70%, Spikes = 0.0521\n",
            "Epoch 13, Batch 420: Loss = 0.8252, Acc = 74.67%, Spikes = 0.0521\n",
            "Epoch 13, Batch 430: Loss = 0.8474, Acc = 74.60%, Spikes = 0.0537\n",
            "Epoch 13, Batch 440: Loss = 0.7156, Acc = 74.69%, Spikes = 0.0541\n",
            "Epoch 13, Batch 450: Loss = 0.8406, Acc = 74.61%, Spikes = 0.0502\n",
            "Epoch 13, Batch 460: Loss = 0.8117, Acc = 74.60%, Spikes = 0.0496\n",
            "Epoch 13, Batch 470: Loss = 1.2205, Acc = 74.58%, Spikes = 0.0542\n",
            "Epoch 13, Batch 480: Loss = 0.7751, Acc = 74.60%, Spikes = 0.0511\n",
            "Epoch 13, Batch 490: Loss = 0.6315, Acc = 74.71%, Spikes = 0.0545\n",
            "Epoch 13, Batch 500: Loss = 0.6256, Acc = 74.66%, Spikes = 0.0500\n",
            "Epoch 13, Batch 510: Loss = 1.1083, Acc = 74.62%, Spikes = 0.0505\n",
            "Epoch 13, Batch 520: Loss = 0.7557, Acc = 74.66%, Spikes = 0.0553\n",
            "Epoch 13, Batch 530: Loss = 0.6518, Acc = 74.65%, Spikes = 0.0558\n",
            "Epoch 13, Batch 540: Loss = 0.6411, Acc = 74.68%, Spikes = 0.0525\n",
            "Epoch 13, Batch 550: Loss = 0.6217, Acc = 74.68%, Spikes = 0.0528\n",
            "Epoch 13, Batch 560: Loss = 0.6336, Acc = 74.72%, Spikes = 0.0538\n",
            "Epoch 13, Batch 570: Loss = 0.8113, Acc = 74.75%, Spikes = 0.0518\n",
            "Epoch 13, Batch 580: Loss = 1.1562, Acc = 74.76%, Spikes = 0.0524\n",
            "Epoch 13, Batch 590: Loss = 0.7537, Acc = 74.76%, Spikes = 0.0523\n",
            "Epoch 13, Batch 600: Loss = 0.6083, Acc = 74.82%, Spikes = 0.0552\n",
            "Epoch 13, Batch 610: Loss = 0.8648, Acc = 74.85%, Spikes = 0.0536\n",
            "Epoch 13, Batch 620: Loss = 1.1665, Acc = 74.84%, Spikes = 0.0507\n",
            "Epoch 13, Batch 630: Loss = 0.5623, Acc = 74.84%, Spikes = 0.0552\n",
            "Epoch 13, Batch 640: Loss = 0.8282, Acc = 74.88%, Spikes = 0.0510\n",
            "Epoch 13, Batch 650: Loss = 0.7192, Acc = 74.85%, Spikes = 0.0536\n",
            "Epoch 13, Batch 660: Loss = 0.8203, Acc = 74.82%, Spikes = 0.0509\n",
            "Epoch 13, Batch 670: Loss = 0.7441, Acc = 74.87%, Spikes = 0.0471\n",
            "Epoch 13, Batch 680: Loss = 0.8406, Acc = 74.91%, Spikes = 0.0503\n",
            "Epoch 13, Batch 690: Loss = 0.7018, Acc = 74.93%, Spikes = 0.0514\n",
            "Epoch 13, Batch 700: Loss = 0.5466, Acc = 75.02%, Spikes = 0.0565\n",
            "Epoch 13, Batch 710: Loss = 0.6213, Acc = 74.97%, Spikes = 0.0546\n",
            "Epoch 13, Batch 720: Loss = 0.9326, Acc = 75.04%, Spikes = 0.0502\n",
            "Epoch 13, Batch 730: Loss = 0.6510, Acc = 75.07%, Spikes = 0.0533\n",
            "Epoch 13, Batch 740: Loss = 0.6565, Acc = 75.08%, Spikes = 0.0514\n",
            "Epoch 13, Batch 750: Loss = 0.7860, Acc = 75.09%, Spikes = 0.0516\n",
            "Epoch 13, Batch 760: Loss = 0.9162, Acc = 75.12%, Spikes = 0.0534\n",
            "Epoch 13, Batch 770: Loss = 0.6268, Acc = 75.10%, Spikes = 0.0539\n",
            "Epoch 13, Batch 780: Loss = 0.7867, Acc = 75.11%, Spikes = 0.0546\n",
            "Epoch 13, Batch 790: Loss = 0.8332, Acc = 75.13%, Spikes = 0.0531\n",
            "Epoch 13, Batch 800: Loss = 0.8584, Acc = 75.15%, Spikes = 0.0512\n",
            "Epoch 13, Batch 810: Loss = 0.7813, Acc = 75.16%, Spikes = 0.0517\n",
            "Epoch 13, Batch 820: Loss = 1.0248, Acc = 75.16%, Spikes = 0.0485\n",
            "Epoch 13, Batch 830: Loss = 0.8547, Acc = 75.15%, Spikes = 0.0541\n",
            "Epoch 13, Batch 840: Loss = 0.9215, Acc = 75.14%, Spikes = 0.0518\n",
            "Epoch 13, Batch 850: Loss = 0.6488, Acc = 75.15%, Spikes = 0.0520\n",
            "Epoch 13, Batch 860: Loss = 1.1087, Acc = 75.16%, Spikes = 0.0518\n",
            "Epoch 13, Batch 870: Loss = 0.8251, Acc = 75.11%, Spikes = 0.0526\n",
            "Epoch 13, Batch 880: Loss = 0.6626, Acc = 75.11%, Spikes = 0.0543\n",
            "Epoch 13, Batch 890: Loss = 0.8520, Acc = 75.13%, Spikes = 0.0489\n",
            "Epoch 13, Batch 900: Loss = 0.7621, Acc = 75.15%, Spikes = 0.0553\n",
            "Epoch 13, Batch 910: Loss = 0.6149, Acc = 75.14%, Spikes = 0.0536\n",
            "Epoch 13, Batch 920: Loss = 0.8102, Acc = 75.09%, Spikes = 0.0559\n",
            "Epoch 13, Batch 930: Loss = 0.7553, Acc = 75.11%, Spikes = 0.0500\n",
            "Epoch 13, Batch 940: Loss = 0.8224, Acc = 75.13%, Spikes = 0.0514\n",
            "Epoch 13, Batch 950: Loss = 0.7176, Acc = 75.10%, Spikes = 0.0536\n",
            "Epoch 13, Batch 960: Loss = 0.6994, Acc = 75.07%, Spikes = 0.0575\n",
            "Epoch 13, Batch 970: Loss = 0.7033, Acc = 75.08%, Spikes = 0.0525\n",
            "Epoch 13, Batch 980: Loss = 0.5539, Acc = 75.10%, Spikes = 0.0526\n",
            "Epoch 13, Batch 990: Loss = 0.6408, Acc = 75.08%, Spikes = 0.0558\n",
            "Epoch 13, Batch 1000: Loss = 0.6419, Acc = 75.10%, Spikes = 0.0527\n",
            "Epoch 13, Batch 1010: Loss = 0.8601, Acc = 75.10%, Spikes = 0.0536\n",
            "Epoch 13, Batch 1020: Loss = 0.6572, Acc = 75.12%, Spikes = 0.0520\n",
            "Epoch 13, Batch 1030: Loss = 1.0758, Acc = 75.14%, Spikes = 0.0534\n",
            "Epoch 13, Batch 1040: Loss = 0.6780, Acc = 75.11%, Spikes = 0.0511\n",
            "Epoch 13, Batch 1050: Loss = 0.7999, Acc = 75.09%, Spikes = 0.0545\n",
            "Epoch 13, Batch 1060: Loss = 0.6060, Acc = 75.09%, Spikes = 0.0539\n",
            "Epoch 13, Batch 1070: Loss = 0.8941, Acc = 75.06%, Spikes = 0.0576\n",
            "Epoch 13, Batch 1080: Loss = 0.9501, Acc = 75.05%, Spikes = 0.0560\n",
            "Epoch 13, Batch 1090: Loss = 0.8939, Acc = 75.05%, Spikes = 0.0505\n",
            "Epoch 13, Batch 1100: Loss = 0.7741, Acc = 75.01%, Spikes = 0.0557\n",
            "Epoch 13, Batch 1110: Loss = 0.9925, Acc = 74.99%, Spikes = 0.0518\n",
            "Epoch 13, Batch 1120: Loss = 0.7102, Acc = 75.00%, Spikes = 0.0529\n",
            "Epoch 13, Batch 1130: Loss = 0.5929, Acc = 75.01%, Spikes = 0.0582\n",
            "Epoch 13, Batch 1140: Loss = 0.9886, Acc = 75.01%, Spikes = 0.0548\n",
            "Epoch 13, Batch 1150: Loss = 0.7241, Acc = 75.04%, Spikes = 0.0552\n",
            "Epoch 13, Batch 1160: Loss = 0.8062, Acc = 75.01%, Spikes = 0.0492\n",
            "Epoch 13, Batch 1170: Loss = 0.7923, Acc = 75.03%, Spikes = 0.0588\n",
            "Epoch 13, Batch 1180: Loss = 0.7600, Acc = 75.02%, Spikes = 0.0576\n",
            "Epoch 13, Batch 1190: Loss = 1.2438, Acc = 75.03%, Spikes = 0.0544\n",
            "Epoch 13, Batch 1200: Loss = 0.8839, Acc = 75.02%, Spikes = 0.0521\n",
            "Epoch 13, Batch 1210: Loss = 0.6885, Acc = 75.04%, Spikes = 0.0569\n",
            "Epoch 13, Batch 1220: Loss = 0.6596, Acc = 75.07%, Spikes = 0.0579\n",
            "Epoch 13, Batch 1230: Loss = 0.5815, Acc = 75.08%, Spikes = 0.0531\n",
            "Epoch 13, Batch 1240: Loss = 1.0735, Acc = 75.05%, Spikes = 0.0523\n",
            "Epoch 13, Batch 1250: Loss = 0.5494, Acc = 75.04%, Spikes = 0.0574\n",
            "Epoch 13, Batch 1260: Loss = 0.7263, Acc = 75.04%, Spikes = 0.0551\n",
            "Epoch 13, Batch 1270: Loss = 0.4752, Acc = 75.08%, Spikes = 0.0590\n",
            "Epoch 13, Batch 1280: Loss = 1.0268, Acc = 75.07%, Spikes = 0.0542\n",
            "Epoch 13, Batch 1290: Loss = 0.8775, Acc = 75.09%, Spikes = 0.0527\n",
            "Epoch 13, Batch 1300: Loss = 0.6247, Acc = 75.07%, Spikes = 0.0556\n",
            "Epoch 13, Batch 1310: Loss = 0.5870, Acc = 75.08%, Spikes = 0.0549\n",
            "Epoch 13, Batch 1320: Loss = 0.9610, Acc = 75.06%, Spikes = 0.0533\n",
            "Epoch 13, Batch 1330: Loss = 0.7840, Acc = 75.08%, Spikes = 0.0501\n",
            "Epoch 13, Batch 1340: Loss = 0.8119, Acc = 75.10%, Spikes = 0.0512\n",
            "Epoch 13, Batch 1350: Loss = 1.2318, Acc = 75.08%, Spikes = 0.0513\n",
            "Epoch 13, Batch 1360: Loss = 0.7280, Acc = 75.11%, Spikes = 0.0516\n",
            "Epoch 13, Batch 1370: Loss = 0.6394, Acc = 75.10%, Spikes = 0.0542\n",
            "Epoch 13, Batch 1380: Loss = 0.6035, Acc = 75.08%, Spikes = 0.0499\n",
            "Epoch 13, Batch 1390: Loss = 0.7425, Acc = 75.09%, Spikes = 0.0530\n",
            "Epoch 13, Batch 1400: Loss = 0.5725, Acc = 75.09%, Spikes = 0.0562\n",
            "Epoch 13, Batch 1410: Loss = 0.6291, Acc = 75.05%, Spikes = 0.0586\n",
            "Epoch 13, Batch 1420: Loss = 0.8435, Acc = 75.05%, Spikes = 0.0521\n",
            "Epoch 13, Batch 1430: Loss = 0.9514, Acc = 75.07%, Spikes = 0.0551\n",
            "Epoch 13, Batch 1440: Loss = 0.6125, Acc = 75.07%, Spikes = 0.0552\n",
            "Epoch 13, Batch 1450: Loss = 0.9373, Acc = 75.09%, Spikes = 0.0545\n",
            "Epoch 13, Batch 1460: Loss = 0.7623, Acc = 75.05%, Spikes = 0.0567\n",
            "Epoch 13, Batch 1470: Loss = 0.6721, Acc = 75.06%, Spikes = 0.0533\n",
            "Epoch 13, Batch 1480: Loss = 0.8198, Acc = 75.05%, Spikes = 0.0522\n",
            "Epoch 13, Batch 1490: Loss = 0.5418, Acc = 75.08%, Spikes = 0.0505\n",
            "Epoch 13, Batch 1500: Loss = 0.7688, Acc = 75.08%, Spikes = 0.0539\n",
            "Epoch 13, Batch 1510: Loss = 0.7215, Acc = 75.10%, Spikes = 0.0563\n",
            "Epoch 13, Batch 1520: Loss = 0.5808, Acc = 75.13%, Spikes = 0.0591\n",
            "Epoch 13, Batch 1530: Loss = 0.5991, Acc = 75.14%, Spikes = 0.0549\n",
            "Epoch 13, Batch 1540: Loss = 0.6807, Acc = 75.15%, Spikes = 0.0600\n",
            "Epoch 13, Batch 1550: Loss = 1.0063, Acc = 75.15%, Spikes = 0.0549\n",
            "Epoch 13, Batch 1560: Loss = 0.9237, Acc = 75.14%, Spikes = 0.0517\n",
            "Epoch 13, Batch 1570: Loss = 0.5115, Acc = 75.15%, Spikes = 0.0567\n",
            "Epoch 13, Batch 1580: Loss = 0.7057, Acc = 75.16%, Spikes = 0.0546\n",
            "Epoch 13, Batch 1590: Loss = 0.9083, Acc = 75.19%, Spikes = 0.0526\n",
            "Epoch 13, Batch 1600: Loss = 0.7590, Acc = 75.19%, Spikes = 0.0564\n",
            "Epoch 13, Batch 1610: Loss = 0.6027, Acc = 75.17%, Spikes = 0.0570\n",
            "Epoch 13, Batch 1620: Loss = 0.7096, Acc = 75.19%, Spikes = 0.0582\n",
            "Epoch 13, Batch 1630: Loss = 0.8827, Acc = 75.17%, Spikes = 0.0545\n",
            "Epoch 13, Batch 1640: Loss = 0.5994, Acc = 75.19%, Spikes = 0.0531\n",
            "Epoch 13, Batch 1650: Loss = 0.9362, Acc = 75.18%, Spikes = 0.0607\n",
            "Epoch 13, Batch 1660: Loss = 0.5637, Acc = 75.18%, Spikes = 0.0540\n",
            "Epoch 13, Batch 1670: Loss = 0.8535, Acc = 75.21%, Spikes = 0.0557\n",
            "Epoch 13, Batch 1680: Loss = 0.9728, Acc = 75.21%, Spikes = 0.0533\n",
            "Epoch 13, Batch 1690: Loss = 1.1998, Acc = 75.18%, Spikes = 0.0522\n",
            "Epoch 13, Batch 1700: Loss = 1.1987, Acc = 75.14%, Spikes = 0.0520\n",
            "Epoch 13, Batch 1710: Loss = 1.1839, Acc = 75.13%, Spikes = 0.0513\n",
            "Epoch 13, Batch 1720: Loss = 0.6706, Acc = 75.12%, Spikes = 0.0512\n",
            "Epoch 13, Batch 1730: Loss = 0.7971, Acc = 75.13%, Spikes = 0.0550\n",
            "Epoch 13, Batch 1740: Loss = 1.1000, Acc = 75.13%, Spikes = 0.0531\n",
            "Epoch 13, Batch 1750: Loss = 1.2357, Acc = 75.13%, Spikes = 0.0561\n",
            "Epoch 13, Batch 1760: Loss = 0.6777, Acc = 75.13%, Spikes = 0.0581\n",
            "Epoch 13, Batch 1770: Loss = 0.8238, Acc = 75.15%, Spikes = 0.0567\n",
            "Epoch 13, Batch 1780: Loss = 0.9859, Acc = 75.14%, Spikes = 0.0500\n",
            "Epoch 13, Batch 1790: Loss = 0.8193, Acc = 75.15%, Spikes = 0.0536\n",
            "Epoch 13, Batch 1800: Loss = 0.8699, Acc = 75.15%, Spikes = 0.0544\n",
            "Epoch 13, Batch 1810: Loss = 1.0075, Acc = 75.15%, Spikes = 0.0533\n",
            "Epoch 13, Batch 1820: Loss = 0.6039, Acc = 75.16%, Spikes = 0.0526\n",
            "Epoch 13, Batch 1830: Loss = 0.7720, Acc = 75.16%, Spikes = 0.0560\n",
            "Epoch 13, Batch 1840: Loss = 0.8575, Acc = 75.17%, Spikes = 0.0542\n",
            "Epoch 13, Batch 1850: Loss = 0.8219, Acc = 75.16%, Spikes = 0.0493\n",
            "Epoch 13, Batch 1860: Loss = 0.8091, Acc = 75.14%, Spikes = 0.0567\n",
            "Epoch 13, Batch 1870: Loss = 0.6017, Acc = 75.16%, Spikes = 0.0549\n",
            "Epoch 13/15:\n",
            "Train Loss: 0.7848 | Train Acc: 75.16% | Train Spikes: 0.0536\n",
            "Test Acc: 76.28% | Test Spikes: 0.0555\n",
            "------------------------------------------------------------\n",
            "Epoch 14, Batch 0: Loss = 0.8562, Acc = 75.00%, Spikes = 0.0544\n",
            "Epoch 14, Batch 10: Loss = 0.8550, Acc = 73.86%, Spikes = 0.0547\n",
            "Epoch 14, Batch 20: Loss = 0.6499, Acc = 75.74%, Spikes = 0.0547\n",
            "Epoch 14, Batch 30: Loss = 0.6601, Acc = 74.90%, Spikes = 0.0558\n",
            "Epoch 14, Batch 40: Loss = 0.6448, Acc = 75.76%, Spikes = 0.0558\n",
            "Epoch 14, Batch 50: Loss = 0.8156, Acc = 76.16%, Spikes = 0.0567\n",
            "Epoch 14, Batch 60: Loss = 1.0408, Acc = 75.87%, Spikes = 0.0526\n",
            "Epoch 14, Batch 70: Loss = 1.0630, Acc = 76.10%, Spikes = 0.0490\n",
            "Epoch 14, Batch 80: Loss = 0.7387, Acc = 76.16%, Spikes = 0.0544\n",
            "Epoch 14, Batch 90: Loss = 0.5699, Acc = 76.79%, Spikes = 0.0515\n",
            "Epoch 14, Batch 100: Loss = 0.6678, Acc = 76.45%, Spikes = 0.0552\n",
            "Epoch 14, Batch 110: Loss = 0.9637, Acc = 76.55%, Spikes = 0.0503\n",
            "Epoch 14, Batch 120: Loss = 0.7259, Acc = 76.39%, Spikes = 0.0546\n",
            "Epoch 14, Batch 130: Loss = 0.6900, Acc = 76.48%, Spikes = 0.0607\n",
            "Epoch 14, Batch 140: Loss = 0.9040, Acc = 76.40%, Spikes = 0.0523\n",
            "Epoch 14, Batch 150: Loss = 1.0273, Acc = 76.59%, Spikes = 0.0501\n",
            "Epoch 14, Batch 160: Loss = 0.7556, Acc = 76.65%, Spikes = 0.0547\n",
            "Epoch 14, Batch 170: Loss = 0.6891, Acc = 76.77%, Spikes = 0.0550\n",
            "Epoch 14, Batch 180: Loss = 0.8930, Acc = 76.74%, Spikes = 0.0526\n",
            "Epoch 14, Batch 190: Loss = 0.6524, Acc = 76.85%, Spikes = 0.0553\n",
            "Epoch 14, Batch 200: Loss = 0.7378, Acc = 76.74%, Spikes = 0.0534\n",
            "Epoch 14, Batch 210: Loss = 1.0292, Acc = 76.79%, Spikes = 0.0558\n",
            "Epoch 14, Batch 220: Loss = 0.7971, Acc = 76.78%, Spikes = 0.0532\n",
            "Epoch 14, Batch 230: Loss = 0.6160, Acc = 76.85%, Spikes = 0.0560\n",
            "Epoch 14, Batch 240: Loss = 0.4718, Acc = 76.89%, Spikes = 0.0572\n",
            "Epoch 14, Batch 250: Loss = 0.7234, Acc = 76.86%, Spikes = 0.0533\n",
            "Epoch 14, Batch 260: Loss = 0.5923, Acc = 76.93%, Spikes = 0.0548\n",
            "Epoch 14, Batch 270: Loss = 0.6866, Acc = 76.85%, Spikes = 0.0532\n",
            "Epoch 14, Batch 280: Loss = 0.9547, Acc = 76.78%, Spikes = 0.0557\n",
            "Epoch 14, Batch 290: Loss = 0.9687, Acc = 76.74%, Spikes = 0.0541\n",
            "Epoch 14, Batch 300: Loss = 0.9412, Acc = 76.66%, Spikes = 0.0585\n",
            "Epoch 14, Batch 310: Loss = 0.8501, Acc = 76.60%, Spikes = 0.0552\n",
            "Epoch 14, Batch 320: Loss = 0.8633, Acc = 76.64%, Spikes = 0.0517\n",
            "Epoch 14, Batch 330: Loss = 0.8760, Acc = 76.53%, Spikes = 0.0557\n",
            "Epoch 14, Batch 340: Loss = 0.6784, Acc = 76.44%, Spikes = 0.0539\n",
            "Epoch 14, Batch 350: Loss = 0.8417, Acc = 76.36%, Spikes = 0.0544\n",
            "Epoch 14, Batch 360: Loss = 0.6321, Acc = 76.36%, Spikes = 0.0540\n",
            "Epoch 14, Batch 370: Loss = 0.8669, Acc = 76.26%, Spikes = 0.0515\n",
            "Epoch 14, Batch 380: Loss = 0.6645, Acc = 76.16%, Spikes = 0.0553\n",
            "Epoch 14, Batch 390: Loss = 1.0100, Acc = 76.08%, Spikes = 0.0551\n",
            "Epoch 14, Batch 400: Loss = 0.8686, Acc = 76.10%, Spikes = 0.0544\n",
            "Epoch 14, Batch 410: Loss = 0.6017, Acc = 76.26%, Spikes = 0.0542\n",
            "Epoch 14, Batch 420: Loss = 0.5634, Acc = 76.25%, Spikes = 0.0559\n",
            "Epoch 14, Batch 430: Loss = 0.8139, Acc = 76.31%, Spikes = 0.0542\n",
            "Epoch 14, Batch 440: Loss = 0.5843, Acc = 76.32%, Spikes = 0.0536\n",
            "Epoch 14, Batch 450: Loss = 0.6601, Acc = 76.30%, Spikes = 0.0514\n",
            "Epoch 14, Batch 460: Loss = 0.6459, Acc = 76.25%, Spikes = 0.0540\n",
            "Epoch 14, Batch 470: Loss = 0.7276, Acc = 76.23%, Spikes = 0.0579\n",
            "Epoch 14, Batch 480: Loss = 0.7243, Acc = 76.20%, Spikes = 0.0548\n",
            "Epoch 14, Batch 490: Loss = 0.5954, Acc = 76.18%, Spikes = 0.0586\n",
            "Epoch 14, Batch 500: Loss = 0.8579, Acc = 76.14%, Spikes = 0.0522\n",
            "Epoch 14, Batch 510: Loss = 0.7729, Acc = 76.10%, Spikes = 0.0589\n",
            "Epoch 14, Batch 520: Loss = 0.6120, Acc = 76.07%, Spikes = 0.0564\n",
            "Epoch 14, Batch 530: Loss = 0.9729, Acc = 76.03%, Spikes = 0.0568\n",
            "Epoch 14, Batch 540: Loss = 0.8797, Acc = 75.96%, Spikes = 0.0561\n",
            "Epoch 14, Batch 550: Loss = 0.6454, Acc = 75.86%, Spikes = 0.0590\n",
            "Epoch 14, Batch 560: Loss = 1.1472, Acc = 75.79%, Spikes = 0.0542\n",
            "Epoch 14, Batch 570: Loss = 0.5242, Acc = 75.80%, Spikes = 0.0588\n",
            "Epoch 14, Batch 580: Loss = 0.8086, Acc = 75.87%, Spikes = 0.0529\n",
            "Epoch 14, Batch 590: Loss = 0.7635, Acc = 75.82%, Spikes = 0.0573\n",
            "Epoch 14, Batch 600: Loss = 0.6355, Acc = 75.80%, Spikes = 0.0572\n",
            "Epoch 14, Batch 610: Loss = 0.6462, Acc = 75.80%, Spikes = 0.0579\n",
            "Epoch 14, Batch 620: Loss = 0.8928, Acc = 75.82%, Spikes = 0.0531\n",
            "Epoch 14, Batch 630: Loss = 0.5800, Acc = 75.82%, Spikes = 0.0570\n",
            "Epoch 14, Batch 640: Loss = 0.5636, Acc = 75.86%, Spikes = 0.0597\n",
            "Epoch 14, Batch 650: Loss = 0.6300, Acc = 75.94%, Spikes = 0.0593\n",
            "Epoch 14, Batch 660: Loss = 0.9385, Acc = 75.91%, Spikes = 0.0521\n",
            "Epoch 14, Batch 670: Loss = 0.9799, Acc = 75.85%, Spikes = 0.0537\n",
            "Epoch 14, Batch 680: Loss = 1.2409, Acc = 75.85%, Spikes = 0.0564\n",
            "Epoch 14, Batch 690: Loss = 0.8493, Acc = 75.84%, Spikes = 0.0585\n",
            "Epoch 14, Batch 700: Loss = 0.6964, Acc = 75.90%, Spikes = 0.0580\n",
            "Epoch 14, Batch 710: Loss = 0.8256, Acc = 75.88%, Spikes = 0.0536\n",
            "Epoch 14, Batch 720: Loss = 0.7057, Acc = 75.89%, Spikes = 0.0589\n",
            "Epoch 14, Batch 730: Loss = 0.7437, Acc = 75.92%, Spikes = 0.0522\n",
            "Epoch 14, Batch 740: Loss = 0.9230, Acc = 75.92%, Spikes = 0.0490\n",
            "Epoch 14, Batch 750: Loss = 0.8856, Acc = 75.93%, Spikes = 0.0546\n",
            "Epoch 14, Batch 760: Loss = 1.0018, Acc = 75.92%, Spikes = 0.0563\n",
            "Epoch 14, Batch 770: Loss = 0.8244, Acc = 75.89%, Spikes = 0.0618\n",
            "Epoch 14, Batch 780: Loss = 1.0726, Acc = 75.87%, Spikes = 0.0556\n",
            "Epoch 14, Batch 790: Loss = 0.7055, Acc = 75.90%, Spikes = 0.0573\n",
            "Epoch 14, Batch 800: Loss = 0.2750, Acc = 75.92%, Spikes = 0.0585\n",
            "Epoch 14, Batch 810: Loss = 0.8023, Acc = 75.91%, Spikes = 0.0514\n",
            "Epoch 14, Batch 820: Loss = 0.8382, Acc = 75.91%, Spikes = 0.0569\n",
            "Epoch 14, Batch 830: Loss = 0.9070, Acc = 75.90%, Spikes = 0.0505\n",
            "Epoch 14, Batch 840: Loss = 0.8072, Acc = 75.93%, Spikes = 0.0555\n",
            "Epoch 14, Batch 850: Loss = 0.5371, Acc = 75.95%, Spikes = 0.0563\n",
            "Epoch 14, Batch 860: Loss = 0.7992, Acc = 75.97%, Spikes = 0.0553\n",
            "Epoch 14, Batch 870: Loss = 0.8168, Acc = 75.95%, Spikes = 0.0555\n",
            "Epoch 14, Batch 880: Loss = 0.8674, Acc = 75.95%, Spikes = 0.0558\n",
            "Epoch 14, Batch 890: Loss = 0.5791, Acc = 75.94%, Spikes = 0.0547\n",
            "Epoch 14, Batch 900: Loss = 0.8403, Acc = 75.93%, Spikes = 0.0586\n",
            "Epoch 14, Batch 910: Loss = 0.6478, Acc = 75.95%, Spikes = 0.0577\n",
            "Epoch 14, Batch 920: Loss = 1.0484, Acc = 75.91%, Spikes = 0.0540\n",
            "Epoch 14, Batch 930: Loss = 0.7860, Acc = 75.91%, Spikes = 0.0537\n",
            "Epoch 14, Batch 940: Loss = 0.7478, Acc = 75.92%, Spikes = 0.0545\n",
            "Epoch 14, Batch 950: Loss = 0.8616, Acc = 75.92%, Spikes = 0.0548\n",
            "Epoch 14, Batch 960: Loss = 0.6108, Acc = 75.94%, Spikes = 0.0557\n",
            "Epoch 14, Batch 970: Loss = 0.7501, Acc = 75.92%, Spikes = 0.0571\n",
            "Epoch 14, Batch 980: Loss = 0.8130, Acc = 75.93%, Spikes = 0.0549\n",
            "Epoch 14, Batch 990: Loss = 0.5857, Acc = 75.94%, Spikes = 0.0571\n",
            "Epoch 14, Batch 1000: Loss = 0.5581, Acc = 75.94%, Spikes = 0.0558\n",
            "Epoch 14, Batch 1010: Loss = 0.8757, Acc = 75.96%, Spikes = 0.0512\n",
            "Epoch 14, Batch 1020: Loss = 0.5854, Acc = 75.95%, Spikes = 0.0570\n",
            "Epoch 14, Batch 1030: Loss = 0.8711, Acc = 75.95%, Spikes = 0.0597\n",
            "Epoch 14, Batch 1040: Loss = 1.2718, Acc = 75.95%, Spikes = 0.0545\n",
            "Epoch 14, Batch 1050: Loss = 0.5257, Acc = 75.96%, Spikes = 0.0540\n",
            "Epoch 14, Batch 1060: Loss = 0.9390, Acc = 75.92%, Spikes = 0.0578\n",
            "Epoch 14, Batch 1070: Loss = 0.6467, Acc = 75.90%, Spikes = 0.0527\n",
            "Epoch 14, Batch 1080: Loss = 1.0761, Acc = 75.90%, Spikes = 0.0549\n",
            "Epoch 14, Batch 1090: Loss = 1.0705, Acc = 75.91%, Spikes = 0.0575\n",
            "Epoch 14, Batch 1100: Loss = 1.3259, Acc = 75.90%, Spikes = 0.0501\n",
            "Epoch 14, Batch 1110: Loss = 0.9031, Acc = 75.86%, Spikes = 0.0554\n",
            "Epoch 14, Batch 1120: Loss = 0.6317, Acc = 75.85%, Spikes = 0.0577\n",
            "Epoch 14, Batch 1130: Loss = 1.0311, Acc = 75.85%, Spikes = 0.0561\n",
            "Epoch 14, Batch 1140: Loss = 0.9426, Acc = 75.83%, Spikes = 0.0551\n",
            "Epoch 14, Batch 1150: Loss = 0.6928, Acc = 75.83%, Spikes = 0.0566\n",
            "Epoch 14, Batch 1160: Loss = 0.5716, Acc = 75.81%, Spikes = 0.0565\n",
            "Epoch 14, Batch 1170: Loss = 0.8017, Acc = 75.81%, Spikes = 0.0546\n",
            "Epoch 14, Batch 1180: Loss = 0.8814, Acc = 75.80%, Spikes = 0.0543\n",
            "Epoch 14, Batch 1190: Loss = 0.5726, Acc = 75.78%, Spikes = 0.0564\n",
            "Epoch 14, Batch 1200: Loss = 0.6297, Acc = 75.76%, Spikes = 0.0565\n",
            "Epoch 14, Batch 1210: Loss = 0.8655, Acc = 75.72%, Spikes = 0.0543\n",
            "Epoch 14, Batch 1220: Loss = 0.8238, Acc = 75.71%, Spikes = 0.0532\n",
            "Epoch 14, Batch 1230: Loss = 0.7562, Acc = 75.72%, Spikes = 0.0558\n",
            "Epoch 14, Batch 1240: Loss = 0.7436, Acc = 75.72%, Spikes = 0.0516\n",
            "Epoch 14, Batch 1250: Loss = 0.7832, Acc = 75.73%, Spikes = 0.0576\n",
            "Epoch 14, Batch 1260: Loss = 0.9771, Acc = 75.72%, Spikes = 0.0515\n",
            "Epoch 14, Batch 1270: Loss = 0.8580, Acc = 75.68%, Spikes = 0.0522\n",
            "Epoch 14, Batch 1280: Loss = 0.6611, Acc = 75.71%, Spikes = 0.0566\n",
            "Epoch 14, Batch 1290: Loss = 0.8915, Acc = 75.69%, Spikes = 0.0560\n",
            "Epoch 14, Batch 1300: Loss = 0.5447, Acc = 75.70%, Spikes = 0.0551\n",
            "Epoch 14, Batch 1310: Loss = 0.7636, Acc = 75.70%, Spikes = 0.0571\n",
            "Epoch 14, Batch 1320: Loss = 0.7897, Acc = 75.71%, Spikes = 0.0558\n",
            "Epoch 14, Batch 1330: Loss = 0.7065, Acc = 75.71%, Spikes = 0.0585\n",
            "Epoch 14, Batch 1340: Loss = 0.6886, Acc = 75.75%, Spikes = 0.0516\n",
            "Epoch 14, Batch 1350: Loss = 1.0009, Acc = 75.75%, Spikes = 0.0550\n",
            "Epoch 14, Batch 1360: Loss = 0.8324, Acc = 75.74%, Spikes = 0.0546\n",
            "Epoch 14, Batch 1370: Loss = 0.8011, Acc = 75.76%, Spikes = 0.0552\n",
            "Epoch 14, Batch 1380: Loss = 0.7677, Acc = 75.72%, Spikes = 0.0531\n",
            "Epoch 14, Batch 1390: Loss = 0.8921, Acc = 75.74%, Spikes = 0.0546\n",
            "Epoch 14, Batch 1400: Loss = 0.5993, Acc = 75.74%, Spikes = 0.0585\n",
            "Epoch 14, Batch 1410: Loss = 0.9904, Acc = 75.73%, Spikes = 0.0546\n",
            "Epoch 14, Batch 1420: Loss = 0.6588, Acc = 75.74%, Spikes = 0.0583\n",
            "Epoch 14, Batch 1430: Loss = 0.9192, Acc = 75.73%, Spikes = 0.0573\n",
            "Epoch 14, Batch 1440: Loss = 0.9300, Acc = 75.73%, Spikes = 0.0540\n",
            "Epoch 14, Batch 1450: Loss = 0.6394, Acc = 75.74%, Spikes = 0.0562\n",
            "Epoch 14, Batch 1460: Loss = 0.8044, Acc = 75.73%, Spikes = 0.0541\n",
            "Epoch 14, Batch 1470: Loss = 0.7505, Acc = 75.73%, Spikes = 0.0569\n",
            "Epoch 14, Batch 1480: Loss = 0.4379, Acc = 75.73%, Spikes = 0.0597\n",
            "Epoch 14, Batch 1490: Loss = 0.4799, Acc = 75.74%, Spikes = 0.0564\n",
            "Epoch 14, Batch 1500: Loss = 0.7439, Acc = 75.72%, Spikes = 0.0610\n",
            "Epoch 14, Batch 1510: Loss = 1.0083, Acc = 75.72%, Spikes = 0.0526\n",
            "Epoch 14, Batch 1520: Loss = 0.7882, Acc = 75.73%, Spikes = 0.0529\n",
            "Epoch 14, Batch 1530: Loss = 0.8043, Acc = 75.74%, Spikes = 0.0567\n",
            "Epoch 14, Batch 1540: Loss = 0.7777, Acc = 75.74%, Spikes = 0.0560\n",
            "Epoch 14, Batch 1550: Loss = 0.8025, Acc = 75.75%, Spikes = 0.0588\n",
            "Epoch 14, Batch 1560: Loss = 0.8849, Acc = 75.74%, Spikes = 0.0565\n",
            "Epoch 14, Batch 1570: Loss = 1.0242, Acc = 75.73%, Spikes = 0.0534\n",
            "Epoch 14, Batch 1580: Loss = 0.5496, Acc = 75.75%, Spikes = 0.0536\n",
            "Epoch 14, Batch 1590: Loss = 0.4711, Acc = 75.75%, Spikes = 0.0566\n",
            "Epoch 14, Batch 1600: Loss = 0.7340, Acc = 75.77%, Spikes = 0.0544\n",
            "Epoch 14, Batch 1610: Loss = 0.5178, Acc = 75.79%, Spikes = 0.0540\n",
            "Epoch 14, Batch 1620: Loss = 0.6450, Acc = 75.78%, Spikes = 0.0521\n",
            "Epoch 14, Batch 1630: Loss = 0.7233, Acc = 75.79%, Spikes = 0.0517\n",
            "Epoch 14, Batch 1640: Loss = 1.0082, Acc = 75.77%, Spikes = 0.0537\n",
            "Epoch 14, Batch 1650: Loss = 0.5678, Acc = 75.77%, Spikes = 0.0532\n",
            "Epoch 14, Batch 1660: Loss = 0.8137, Acc = 75.77%, Spikes = 0.0572\n",
            "Epoch 14, Batch 1670: Loss = 0.7177, Acc = 75.78%, Spikes = 0.0550\n",
            "Epoch 14, Batch 1680: Loss = 0.6240, Acc = 75.80%, Spikes = 0.0575\n",
            "Epoch 14, Batch 1690: Loss = 0.6260, Acc = 75.81%, Spikes = 0.0584\n",
            "Epoch 14, Batch 1700: Loss = 0.6769, Acc = 75.82%, Spikes = 0.0548\n",
            "Epoch 14, Batch 1710: Loss = 0.7628, Acc = 75.82%, Spikes = 0.0555\n",
            "Epoch 14, Batch 1720: Loss = 0.9314, Acc = 75.82%, Spikes = 0.0523\n",
            "Epoch 14, Batch 1730: Loss = 0.6446, Acc = 75.84%, Spikes = 0.0559\n",
            "Epoch 14, Batch 1740: Loss = 0.6917, Acc = 75.82%, Spikes = 0.0596\n",
            "Epoch 14, Batch 1750: Loss = 0.6651, Acc = 75.81%, Spikes = 0.0543\n",
            "Epoch 14, Batch 1760: Loss = 0.8686, Acc = 75.80%, Spikes = 0.0550\n",
            "Epoch 14, Batch 1770: Loss = 1.1854, Acc = 75.80%, Spikes = 0.0584\n",
            "Epoch 14, Batch 1780: Loss = 0.5941, Acc = 75.82%, Spikes = 0.0549\n",
            "Epoch 14, Batch 1790: Loss = 0.6569, Acc = 75.82%, Spikes = 0.0565\n",
            "Epoch 14, Batch 1800: Loss = 0.5864, Acc = 75.83%, Spikes = 0.0546\n",
            "Epoch 14, Batch 1810: Loss = 0.6364, Acc = 75.81%, Spikes = 0.0573\n",
            "Epoch 14, Batch 1820: Loss = 0.8004, Acc = 75.80%, Spikes = 0.0562\n",
            "Epoch 14, Batch 1830: Loss = 0.5293, Acc = 75.83%, Spikes = 0.0575\n",
            "Epoch 14, Batch 1840: Loss = 0.5244, Acc = 75.82%, Spikes = 0.0567\n",
            "Epoch 14, Batch 1850: Loss = 0.6729, Acc = 75.83%, Spikes = 0.0553\n",
            "Epoch 14, Batch 1860: Loss = 0.6701, Acc = 75.83%, Spikes = 0.0569\n",
            "Epoch 14, Batch 1870: Loss = 0.7563, Acc = 75.82%, Spikes = 0.0543\n",
            "Epoch 14/15:\n",
            "Train Loss: 0.7680 | Train Acc: 75.82% | Train Spikes: 0.0553\n",
            "Test Acc: 76.97% | Test Spikes: 0.0563\n",
            "------------------------------------------------------------\n",
            "Epoch 15, Batch 0: Loss = 1.0149, Acc = 71.88%, Spikes = 0.0518\n",
            "Epoch 15, Batch 10: Loss = 0.6818, Acc = 77.56%, Spikes = 0.0559\n",
            "Epoch 15, Batch 20: Loss = 0.7472, Acc = 75.74%, Spikes = 0.0554\n",
            "Epoch 15, Batch 30: Loss = 0.8927, Acc = 74.09%, Spikes = 0.0546\n",
            "Epoch 15, Batch 40: Loss = 0.5507, Acc = 75.00%, Spikes = 0.0601\n",
            "Epoch 15, Batch 50: Loss = 0.9173, Acc = 74.08%, Spikes = 0.0567\n",
            "Epoch 15, Batch 60: Loss = 0.4951, Acc = 75.00%, Spikes = 0.0546\n",
            "Epoch 15, Batch 70: Loss = 0.7038, Acc = 74.87%, Spikes = 0.0567\n",
            "Epoch 15, Batch 80: Loss = 0.8013, Acc = 75.04%, Spikes = 0.0523\n",
            "Epoch 15, Batch 90: Loss = 0.5746, Acc = 75.17%, Spikes = 0.0624\n",
            "Epoch 15, Batch 100: Loss = 0.7098, Acc = 75.25%, Spikes = 0.0570\n",
            "Epoch 15, Batch 110: Loss = 0.8237, Acc = 75.48%, Spikes = 0.0580\n",
            "Epoch 15, Batch 120: Loss = 0.6175, Acc = 75.49%, Spikes = 0.0590\n",
            "Epoch 15, Batch 130: Loss = 0.6875, Acc = 75.67%, Spikes = 0.0572\n",
            "Epoch 15, Batch 140: Loss = 0.7300, Acc = 75.58%, Spikes = 0.0598\n",
            "Epoch 15, Batch 150: Loss = 0.8390, Acc = 75.62%, Spikes = 0.0539\n",
            "Epoch 15, Batch 160: Loss = 0.9084, Acc = 75.41%, Spikes = 0.0562\n",
            "Epoch 15, Batch 170: Loss = 0.4805, Acc = 75.53%, Spikes = 0.0589\n",
            "Epoch 15, Batch 180: Loss = 0.5467, Acc = 75.47%, Spikes = 0.0589\n",
            "Epoch 15, Batch 190: Loss = 0.5476, Acc = 75.62%, Spikes = 0.0557\n",
            "Epoch 15, Batch 200: Loss = 0.5427, Acc = 75.62%, Spikes = 0.0604\n",
            "Epoch 15, Batch 210: Loss = 0.6694, Acc = 75.65%, Spikes = 0.0593\n",
            "Epoch 15, Batch 220: Loss = 0.8852, Acc = 75.54%, Spikes = 0.0548\n",
            "Epoch 15, Batch 230: Loss = 0.5680, Acc = 75.72%, Spikes = 0.0603\n",
            "Epoch 15, Batch 240: Loss = 0.8295, Acc = 75.64%, Spikes = 0.0578\n",
            "Epoch 15, Batch 250: Loss = 0.7365, Acc = 75.62%, Spikes = 0.0649\n",
            "Epoch 15, Batch 260: Loss = 0.6532, Acc = 75.55%, Spikes = 0.0615\n",
            "Epoch 15, Batch 270: Loss = 0.5442, Acc = 75.71%, Spikes = 0.0579\n",
            "Epoch 15, Batch 280: Loss = 0.8012, Acc = 75.65%, Spikes = 0.0542\n",
            "Epoch 15, Batch 290: Loss = 0.8689, Acc = 75.63%, Spikes = 0.0589\n",
            "Epoch 15, Batch 300: Loss = 0.7399, Acc = 75.81%, Spikes = 0.0604\n",
            "Epoch 15, Batch 310: Loss = 1.1428, Acc = 75.74%, Spikes = 0.0524\n",
            "Epoch 15, Batch 320: Loss = 0.7072, Acc = 75.63%, Spikes = 0.0609\n",
            "Epoch 15, Batch 330: Loss = 0.6756, Acc = 75.64%, Spikes = 0.0546\n",
            "Epoch 15, Batch 340: Loss = 0.4907, Acc = 75.69%, Spikes = 0.0576\n",
            "Epoch 15, Batch 350: Loss = 0.6389, Acc = 75.67%, Spikes = 0.0546\n",
            "Epoch 15, Batch 360: Loss = 0.6974, Acc = 75.66%, Spikes = 0.0594\n",
            "Epoch 15, Batch 370: Loss = 0.6948, Acc = 75.69%, Spikes = 0.0576\n",
            "Epoch 15, Batch 380: Loss = 0.6877, Acc = 75.73%, Spikes = 0.0556\n",
            "Epoch 15, Batch 390: Loss = 0.6677, Acc = 75.79%, Spikes = 0.0591\n",
            "Epoch 15, Batch 400: Loss = 0.7283, Acc = 75.76%, Spikes = 0.0565\n",
            "Epoch 15, Batch 410: Loss = 1.0062, Acc = 75.69%, Spikes = 0.0563\n",
            "Epoch 15, Batch 420: Loss = 0.6421, Acc = 75.72%, Spikes = 0.0545\n",
            "Epoch 15, Batch 430: Loss = 0.7678, Acc = 75.74%, Spikes = 0.0577\n",
            "Epoch 15, Batch 440: Loss = 0.7354, Acc = 75.75%, Spikes = 0.0552\n",
            "Epoch 15, Batch 450: Loss = 0.7197, Acc = 75.77%, Spikes = 0.0576\n",
            "Epoch 15, Batch 460: Loss = 0.8293, Acc = 75.74%, Spikes = 0.0549\n",
            "Epoch 15, Batch 470: Loss = 0.5282, Acc = 75.83%, Spikes = 0.0580\n",
            "Epoch 15, Batch 480: Loss = 0.5708, Acc = 75.90%, Spikes = 0.0574\n",
            "Epoch 15, Batch 490: Loss = 0.6307, Acc = 75.96%, Spikes = 0.0595\n",
            "Epoch 15, Batch 500: Loss = 0.5686, Acc = 75.97%, Spikes = 0.0591\n",
            "Epoch 15, Batch 510: Loss = 0.7411, Acc = 75.94%, Spikes = 0.0586\n",
            "Epoch 15, Batch 520: Loss = 0.7042, Acc = 75.90%, Spikes = 0.0543\n",
            "Epoch 15, Batch 530: Loss = 0.7576, Acc = 75.92%, Spikes = 0.0595\n",
            "Epoch 15, Batch 540: Loss = 0.9578, Acc = 75.90%, Spikes = 0.0534\n",
            "Epoch 15, Batch 550: Loss = 0.6696, Acc = 75.95%, Spikes = 0.0603\n",
            "Epoch 15, Batch 560: Loss = 0.5992, Acc = 75.92%, Spikes = 0.0559\n",
            "Epoch 15, Batch 570: Loss = 0.5059, Acc = 75.99%, Spikes = 0.0602\n",
            "Epoch 15, Batch 580: Loss = 0.6408, Acc = 75.92%, Spikes = 0.0561\n",
            "Epoch 15, Batch 590: Loss = 1.0346, Acc = 75.96%, Spikes = 0.0555\n",
            "Epoch 15, Batch 600: Loss = 0.5228, Acc = 75.95%, Spikes = 0.0527\n",
            "Epoch 15, Batch 610: Loss = 0.9992, Acc = 75.89%, Spikes = 0.0555\n",
            "Epoch 15, Batch 620: Loss = 0.7065, Acc = 75.92%, Spikes = 0.0562\n",
            "Epoch 15, Batch 630: Loss = 1.0169, Acc = 75.95%, Spikes = 0.0560\n",
            "Epoch 15, Batch 640: Loss = 0.5907, Acc = 75.97%, Spikes = 0.0575\n",
            "Epoch 15, Batch 650: Loss = 0.8029, Acc = 76.04%, Spikes = 0.0596\n",
            "Epoch 15, Batch 660: Loss = 0.5010, Acc = 76.07%, Spikes = 0.0588\n",
            "Epoch 15, Batch 670: Loss = 0.8508, Acc = 76.10%, Spikes = 0.0620\n",
            "Epoch 15, Batch 680: Loss = 0.7099, Acc = 76.09%, Spikes = 0.0547\n",
            "Epoch 15, Batch 690: Loss = 0.8192, Acc = 76.12%, Spikes = 0.0585\n",
            "Epoch 15, Batch 700: Loss = 0.5942, Acc = 76.11%, Spikes = 0.0599\n",
            "Epoch 15, Batch 710: Loss = 0.4760, Acc = 76.14%, Spikes = 0.0577\n",
            "Epoch 15, Batch 720: Loss = 0.5036, Acc = 76.16%, Spikes = 0.0558\n",
            "Epoch 15, Batch 730: Loss = 0.6051, Acc = 76.19%, Spikes = 0.0563\n",
            "Epoch 15, Batch 740: Loss = 0.5742, Acc = 76.21%, Spikes = 0.0556\n",
            "Epoch 15, Batch 750: Loss = 1.0341, Acc = 76.24%, Spikes = 0.0552\n",
            "Epoch 15, Batch 760: Loss = 1.0591, Acc = 76.25%, Spikes = 0.0478\n",
            "Epoch 15, Batch 770: Loss = 0.8095, Acc = 76.24%, Spikes = 0.0537\n",
            "Epoch 15, Batch 780: Loss = 0.7667, Acc = 76.24%, Spikes = 0.0606\n",
            "Epoch 15, Batch 790: Loss = 0.8633, Acc = 76.22%, Spikes = 0.0585\n",
            "Epoch 15, Batch 800: Loss = 1.0259, Acc = 76.22%, Spikes = 0.0537\n",
            "Epoch 15, Batch 810: Loss = 0.9105, Acc = 76.22%, Spikes = 0.0530\n",
            "Epoch 15, Batch 820: Loss = 0.5182, Acc = 76.18%, Spikes = 0.0589\n",
            "Epoch 15, Batch 830: Loss = 0.6915, Acc = 76.20%, Spikes = 0.0533\n",
            "Epoch 15, Batch 840: Loss = 0.7017, Acc = 76.22%, Spikes = 0.0601\n",
            "Epoch 15, Batch 850: Loss = 0.6188, Acc = 76.23%, Spikes = 0.0564\n",
            "Epoch 15, Batch 860: Loss = 0.9876, Acc = 76.23%, Spikes = 0.0532\n",
            "Epoch 15, Batch 870: Loss = 0.5799, Acc = 76.21%, Spikes = 0.0596\n",
            "Epoch 15, Batch 880: Loss = 0.8530, Acc = 76.21%, Spikes = 0.0577\n",
            "Epoch 15, Batch 890: Loss = 0.9996, Acc = 76.17%, Spikes = 0.0598\n",
            "Epoch 15, Batch 900: Loss = 0.4478, Acc = 76.21%, Spikes = 0.0553\n",
            "Epoch 15, Batch 910: Loss = 0.9485, Acc = 76.13%, Spikes = 0.0570\n",
            "Epoch 15, Batch 920: Loss = 0.9154, Acc = 76.17%, Spikes = 0.0523\n",
            "Epoch 15, Batch 930: Loss = 0.4750, Acc = 76.22%, Spikes = 0.0551\n",
            "Epoch 15, Batch 940: Loss = 0.9360, Acc = 76.24%, Spikes = 0.0541\n",
            "Epoch 15, Batch 950: Loss = 0.9405, Acc = 76.25%, Spikes = 0.0541\n",
            "Epoch 15, Batch 960: Loss = 0.7576, Acc = 76.23%, Spikes = 0.0541\n",
            "Epoch 15, Batch 970: Loss = 0.6214, Acc = 76.28%, Spikes = 0.0578\n",
            "Epoch 15, Batch 980: Loss = 0.7671, Acc = 76.28%, Spikes = 0.0605\n",
            "Epoch 15, Batch 990: Loss = 1.1453, Acc = 76.28%, Spikes = 0.0557\n",
            "Epoch 15, Batch 1000: Loss = 0.5993, Acc = 76.26%, Spikes = 0.0588\n",
            "Epoch 15, Batch 1010: Loss = 0.6454, Acc = 76.30%, Spikes = 0.0570\n",
            "Epoch 15, Batch 1020: Loss = 0.4505, Acc = 76.30%, Spikes = 0.0595\n",
            "Epoch 15, Batch 1030: Loss = 0.9384, Acc = 76.27%, Spikes = 0.0543\n",
            "Epoch 15, Batch 1040: Loss = 0.7887, Acc = 76.29%, Spikes = 0.0559\n",
            "Epoch 15, Batch 1050: Loss = 0.7692, Acc = 76.31%, Spikes = 0.0567\n",
            "Epoch 15, Batch 1060: Loss = 0.8617, Acc = 76.28%, Spikes = 0.0508\n",
            "Epoch 15, Batch 1070: Loss = 0.8315, Acc = 76.28%, Spikes = 0.0553\n",
            "Epoch 15, Batch 1080: Loss = 1.0296, Acc = 76.29%, Spikes = 0.0525\n",
            "Epoch 15, Batch 1090: Loss = 0.8840, Acc = 76.29%, Spikes = 0.0556\n",
            "Epoch 15, Batch 1100: Loss = 0.7126, Acc = 76.31%, Spikes = 0.0540\n",
            "Epoch 15, Batch 1110: Loss = 0.7785, Acc = 76.27%, Spikes = 0.0575\n",
            "Epoch 15, Batch 1120: Loss = 0.7114, Acc = 76.27%, Spikes = 0.0573\n",
            "Epoch 15, Batch 1130: Loss = 1.0873, Acc = 76.25%, Spikes = 0.0531\n",
            "Epoch 15, Batch 1140: Loss = 0.9744, Acc = 76.25%, Spikes = 0.0612\n",
            "Epoch 15, Batch 1150: Loss = 0.5870, Acc = 76.28%, Spikes = 0.0576\n",
            "Epoch 15, Batch 1160: Loss = 0.5842, Acc = 76.34%, Spikes = 0.0607\n",
            "Epoch 15, Batch 1170: Loss = 0.9606, Acc = 76.31%, Spikes = 0.0564\n",
            "Epoch 15, Batch 1180: Loss = 0.7181, Acc = 76.29%, Spikes = 0.0551\n",
            "Epoch 15, Batch 1190: Loss = 0.6783, Acc = 76.29%, Spikes = 0.0588\n",
            "Epoch 15, Batch 1200: Loss = 0.6919, Acc = 76.28%, Spikes = 0.0598\n",
            "Epoch 15, Batch 1210: Loss = 0.8617, Acc = 76.24%, Spikes = 0.0529\n",
            "Epoch 15, Batch 1220: Loss = 0.9138, Acc = 76.23%, Spikes = 0.0588\n",
            "Epoch 15, Batch 1230: Loss = 0.6424, Acc = 76.22%, Spikes = 0.0564\n",
            "Epoch 15, Batch 1240: Loss = 0.6803, Acc = 76.23%, Spikes = 0.0552\n",
            "Epoch 15, Batch 1250: Loss = 0.5020, Acc = 76.25%, Spikes = 0.0595\n",
            "Epoch 15, Batch 1260: Loss = 0.6592, Acc = 76.26%, Spikes = 0.0601\n",
            "Epoch 15, Batch 1270: Loss = 0.6539, Acc = 76.25%, Spikes = 0.0561\n",
            "Epoch 15, Batch 1280: Loss = 0.6631, Acc = 76.25%, Spikes = 0.0566\n",
            "Epoch 15, Batch 1290: Loss = 0.8283, Acc = 76.26%, Spikes = 0.0612\n",
            "Epoch 15, Batch 1300: Loss = 0.6586, Acc = 76.24%, Spikes = 0.0559\n",
            "Epoch 15, Batch 1310: Loss = 1.0099, Acc = 76.24%, Spikes = 0.0531\n",
            "Epoch 15, Batch 1320: Loss = 0.7782, Acc = 76.24%, Spikes = 0.0573\n",
            "Epoch 15, Batch 1330: Loss = 0.6835, Acc = 76.26%, Spikes = 0.0595\n",
            "Epoch 15, Batch 1340: Loss = 0.7734, Acc = 76.25%, Spikes = 0.0521\n",
            "Epoch 15, Batch 1350: Loss = 0.8324, Acc = 76.26%, Spikes = 0.0558\n",
            "Epoch 15, Batch 1360: Loss = 0.6002, Acc = 76.27%, Spikes = 0.0594\n",
            "Epoch 15, Batch 1370: Loss = 0.9444, Acc = 76.24%, Spikes = 0.0548\n",
            "Epoch 15, Batch 1380: Loss = 0.6794, Acc = 76.24%, Spikes = 0.0582\n",
            "Epoch 15, Batch 1390: Loss = 0.7480, Acc = 76.23%, Spikes = 0.0585\n",
            "Epoch 15, Batch 1400: Loss = 0.6319, Acc = 76.26%, Spikes = 0.0570\n",
            "Epoch 15, Batch 1410: Loss = 0.8647, Acc = 76.26%, Spikes = 0.0575\n",
            "Epoch 15, Batch 1420: Loss = 0.5721, Acc = 76.29%, Spikes = 0.0581\n",
            "Epoch 15, Batch 1430: Loss = 0.7991, Acc = 76.24%, Spikes = 0.0570\n",
            "Epoch 15, Batch 1440: Loss = 0.7073, Acc = 76.24%, Spikes = 0.0591\n",
            "Epoch 15, Batch 1450: Loss = 0.6811, Acc = 76.22%, Spikes = 0.0570\n",
            "Epoch 15, Batch 1460: Loss = 0.5530, Acc = 76.21%, Spikes = 0.0594\n",
            "Epoch 15, Batch 1470: Loss = 0.9063, Acc = 76.22%, Spikes = 0.0584\n",
            "Epoch 15, Batch 1480: Loss = 0.7421, Acc = 76.24%, Spikes = 0.0614\n",
            "Epoch 15, Batch 1490: Loss = 0.7228, Acc = 76.24%, Spikes = 0.0591\n",
            "Epoch 15, Batch 1500: Loss = 1.0238, Acc = 76.23%, Spikes = 0.0562\n",
            "Epoch 15, Batch 1510: Loss = 1.0562, Acc = 76.22%, Spikes = 0.0593\n",
            "Epoch 15, Batch 1520: Loss = 0.9420, Acc = 76.21%, Spikes = 0.0581\n",
            "Epoch 15, Batch 1530: Loss = 0.8302, Acc = 76.19%, Spikes = 0.0582\n",
            "Epoch 15, Batch 1540: Loss = 0.5486, Acc = 76.19%, Spikes = 0.0620\n",
            "Epoch 15, Batch 1550: Loss = 0.5136, Acc = 76.21%, Spikes = 0.0554\n",
            "Epoch 15, Batch 1560: Loss = 0.8034, Acc = 76.23%, Spikes = 0.0625\n",
            "Epoch 15, Batch 1570: Loss = 0.8999, Acc = 76.23%, Spikes = 0.0603\n",
            "Epoch 15, Batch 1580: Loss = 0.8137, Acc = 76.24%, Spikes = 0.0615\n",
            "Epoch 15, Batch 1590: Loss = 1.0926, Acc = 76.23%, Spikes = 0.0543\n",
            "Epoch 15, Batch 1600: Loss = 0.5644, Acc = 76.19%, Spikes = 0.0581\n",
            "Epoch 15, Batch 1610: Loss = 0.6305, Acc = 76.19%, Spikes = 0.0575\n",
            "Epoch 15, Batch 1620: Loss = 0.6899, Acc = 76.18%, Spikes = 0.0577\n",
            "Epoch 15, Batch 1630: Loss = 0.5297, Acc = 76.16%, Spikes = 0.0582\n",
            "Epoch 15, Batch 1640: Loss = 0.5561, Acc = 76.18%, Spikes = 0.0642\n",
            "Epoch 15, Batch 1650: Loss = 0.8082, Acc = 76.19%, Spikes = 0.0575\n",
            "Epoch 15, Batch 1660: Loss = 0.6947, Acc = 76.21%, Spikes = 0.0550\n",
            "Epoch 15, Batch 1670: Loss = 0.6301, Acc = 76.22%, Spikes = 0.0580\n",
            "Epoch 15, Batch 1680: Loss = 1.1354, Acc = 76.22%, Spikes = 0.0579\n",
            "Epoch 15, Batch 1690: Loss = 0.6410, Acc = 76.23%, Spikes = 0.0628\n",
            "Epoch 15, Batch 1700: Loss = 0.7465, Acc = 76.22%, Spikes = 0.0620\n",
            "Epoch 15, Batch 1710: Loss = 0.6429, Acc = 76.20%, Spikes = 0.0624\n",
            "Epoch 15, Batch 1720: Loss = 1.0270, Acc = 76.18%, Spikes = 0.0638\n",
            "Epoch 15, Batch 1730: Loss = 0.7098, Acc = 76.17%, Spikes = 0.0614\n",
            "Epoch 15, Batch 1740: Loss = 0.6524, Acc = 76.16%, Spikes = 0.0599\n",
            "Epoch 15, Batch 1750: Loss = 0.7944, Acc = 76.15%, Spikes = 0.0627\n",
            "Epoch 15, Batch 1760: Loss = 0.8112, Acc = 76.17%, Spikes = 0.0568\n",
            "Epoch 15, Batch 1770: Loss = 0.6549, Acc = 76.16%, Spikes = 0.0613\n",
            "Epoch 15, Batch 1780: Loss = 0.9456, Acc = 76.15%, Spikes = 0.0580\n",
            "Epoch 15, Batch 1790: Loss = 1.1622, Acc = 76.15%, Spikes = 0.0559\n",
            "Epoch 15, Batch 1800: Loss = 0.5989, Acc = 76.15%, Spikes = 0.0624\n",
            "Epoch 15, Batch 1810: Loss = 0.8093, Acc = 76.17%, Spikes = 0.0579\n",
            "Epoch 15, Batch 1820: Loss = 0.4886, Acc = 76.18%, Spikes = 0.0619\n",
            "Epoch 15, Batch 1830: Loss = 0.5727, Acc = 76.17%, Spikes = 0.0580\n",
            "Epoch 15, Batch 1840: Loss = 0.7376, Acc = 76.16%, Spikes = 0.0604\n",
            "Epoch 15, Batch 1850: Loss = 0.7598, Acc = 76.16%, Spikes = 0.0559\n",
            "Epoch 15, Batch 1860: Loss = 0.7270, Acc = 76.16%, Spikes = 0.0582\n",
            "Epoch 15, Batch 1870: Loss = 0.6052, Acc = 76.17%, Spikes = 0.0592\n",
            "Epoch 15/15:\n",
            "Train Loss: 0.7541 | Train Acc: 76.17% | Train Spikes: 0.0570\n",
            "Test Acc: 77.02% | Test Spikes: 0.0590\n",
            "------------------------------------------------------------\n",
            "\n",
            "Training completed in 1264.66 seconds\n",
            "Final train accuracy: 76.17%\n",
            "Final test accuracy: 77.02%\n",
            "Average spikes per neuron: 0.0590\n",
            "Best accuracy: 77.02%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to imsnn_model.pth\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# Explicitly use CPU\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Reduced hyperparameters\n",
        "batch_size = 32\n",
        "time_steps = 20\n",
        "input_size = 784\n",
        "hidden_size = 200  # Reduced significantly\n",
        "output_size = 10\n",
        "beta = 0.99\n",
        "theta = 1.0\n",
        "lr = 1e-4\n",
        "epochs = 15\n",
        "model_type = 'snn'  # 'imsnn' or 'snn'\n",
        "\n",
        "# For tracking metrics\n",
        "metrics = {\n",
        "    'epoch': [], 'train_loss': [], 'train_acc': [], 'test_acc': [],\n",
        "    'train_spikes': [], 'test_spikes': [], 'layer_spikes': []\n",
        "}\n",
        "\n",
        "# Data Loading - use a smaller subset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "# # Use a much smaller subset for testing\n",
        "# train_size = 5000  # Just 5000 samples\n",
        "# test_size = 1000   # Just 1000 samples\n",
        "# indices = list(range(len(train_dataset)))\n",
        "# test_indices = list(range(len(test_dataset)))\n",
        "# train_dataset = torch.utils.data.Subset(train_dataset, indices[:train_size])\n",
        "# test_dataset = torch.utils.data.Subset(test_dataset, test_indices[:test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "print(f\"Training on {len(train_dataset)} samples, testing on {len(test_dataset)} samples\")\n",
        "\n",
        "# Very simple Poisson Encoder\n",
        "def poisson_encoder(image, time_steps, fr_min=28.5, fr_max=100.0):\n",
        "    dt = 1e-3\n",
        "    rates = (fr_min + (fr_max - fr_min) * image) * dt\n",
        "    spikes = torch.rand(time_steps, *image.shape) < rates.unsqueeze(0)\n",
        "    return spikes.float()\n",
        "\n",
        "# Simplified Surrogate Gradient Function\n",
        "class SurrGradSpike(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return (input > theta).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad = grad_output * 0.3 * torch.exp(-0.5 * torch.abs(input - theta))\n",
        "        return grad\n",
        "\n",
        "spike_fn = SurrGradSpike.apply\n",
        "\n",
        "# Simple implementation of ISI Layer\n",
        "class ISILayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)  # Use standard linear layer internally\n",
        "        self.mu = nn.Parameter(torch.ones(output_size) * 12.0)  # Single mu per output neuron\n",
        "        self.sigma = nn.Parameter(torch.ones(output_size) * 4.0)  # Single sigma per output neuron\n",
        "\n",
        "    def forward(self, s_in, phi_prev):\n",
        "        # Regular linear transformation\n",
        "        output = self.linear(s_in)\n",
        "\n",
        "        # Calculate average ISI for each input\n",
        "        avg_phi = phi_prev.mean(dim=1, keepdim=True)\n",
        "\n",
        "        # Simple modulation\n",
        "        # Calculate Gaussian factor - one per output neuron\n",
        "        phi_factors = torch.exp(-2.0 * ((avg_phi - self.mu.unsqueeze(0)) / self.sigma.unsqueeze(0))**2)\n",
        "\n",
        "        # Modulate output\n",
        "        modulated_output = output * phi_factors\n",
        "\n",
        "        return modulated_output\n",
        "\n",
        "# LIF Neuron\n",
        "class LIFNeuron(nn.Module):\n",
        "    def __init__(self, layer_size):\n",
        "        super().__init__()\n",
        "        self.layer_size = layer_size\n",
        "        self.mem = None\n",
        "        self.phi = None\n",
        "\n",
        "    def reset_state(self, batch_size):\n",
        "        self.mem = torch.zeros(batch_size, self.layer_size)\n",
        "        self.phi = torch.zeros(batch_size, self.layer_size)\n",
        "\n",
        "    def forward(self, I):\n",
        "        self.mem = beta * self.mem + I\n",
        "        spikes = spike_fn(self.mem)\n",
        "        self.mem = self.mem * (1 - spikes)\n",
        "        self.phi = (1 + self.phi) * (1 - spikes)\n",
        "        return spikes\n",
        "\n",
        "# Neural Network Model\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, model_type='imsnn'):\n",
        "        super().__init__()\n",
        "        self.model_type = model_type\n",
        "\n",
        "        if model_type == 'imsnn':\n",
        "            self.fc1 = ISILayer(input_size, hidden_size)\n",
        "        else:\n",
        "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        self.lif1 = LIFNeuron(hidden_size)\n",
        "\n",
        "        if model_type == 'imsnn':\n",
        "            self.fc2 = ISILayer(hidden_size, output_size)\n",
        "        else:\n",
        "            self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(1)\n",
        "        self.lif1.reset_state(batch_size)\n",
        "\n",
        "        if self.model_type == 'imsnn':\n",
        "            input_phi = torch.zeros(batch_size, input_size)\n",
        "\n",
        "        outputs = []\n",
        "        spike_counts = 0\n",
        "\n",
        "        for t in range(x.size(0)):\n",
        "            s_in = x[t]\n",
        "\n",
        "            if self.model_type == 'imsnn':\n",
        "                input_phi = (1 + input_phi) * (1 - s_in)\n",
        "                I1 = self.fc1(s_in, input_phi)\n",
        "            else:\n",
        "                I1 = self.fc1(s_in)\n",
        "\n",
        "            s1 = self.lif1(I1)\n",
        "            spike_counts += s1.sum()\n",
        "\n",
        "            if self.model_type == 'imsnn':\n",
        "                I2 = self.fc2(s1, self.lif1.phi)\n",
        "            else:\n",
        "                I2 = self.fc2(s1)\n",
        "\n",
        "            outputs.append(I2)\n",
        "\n",
        "        avg_spikes_per_neuron = spike_counts / (batch_size * hidden_size * x.size(0))\n",
        "        return torch.stack(outputs).mean(dim=0), avg_spikes_per_neuron\n",
        "\n",
        "# Initialize Model and Optimizer\n",
        "print(f\"Creating {model_type} model...\")\n",
        "model = SNN(model_type).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "print(\"Model created successfully!\")\n",
        "\n",
        "# Training Loop\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "best_accuracy = 0\n",
        "\n",
        "try:\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        train_spikes = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Generate spikes\n",
        "            spikes = poisson_encoder(images, time_steps)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs, avg_spikes = model(spikes)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Add spike regularization\n",
        "            if model_type == 'imsnn':\n",
        "                loss += 0.2 * avg_spikes\n",
        "\n",
        "            elif model_type == 'snn':\n",
        "                loss += 0.001 * avg_spikes\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track metrics\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            train_spikes += avg_spikes.item()\n",
        "\n",
        "            # Print progress\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: Loss = {loss.item():.4f}, Acc = {100*correct/total:.2f}%, Spikes = {avg_spikes.item():.4f}\")\n",
        "\n",
        "        # Epoch stats\n",
        "        train_loss_avg = train_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "        train_spikes_avg = train_spikes / len(train_loader)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        test_spikes = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Generate spikes\n",
        "                spikes = poisson_encoder(images, time_steps)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs, avg_spikes = model(spikes)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Track metrics\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "                test_spikes += avg_spikes.item()\n",
        "\n",
        "        # Test stats\n",
        "        test_acc = 100 * correct / total\n",
        "        test_spikes_avg = test_spikes / len(test_loader)\n",
        "        test_loss_avg = test_loss / len(test_loader)\n",
        "\n",
        "        scheduler.step(test_loss_avg)\n",
        "\n",
        "        # Store metrics\n",
        "        metrics['epoch'].append(epoch + 1)\n",
        "        metrics['train_loss'].append(train_loss_avg)\n",
        "        metrics['train_acc'].append(train_acc)\n",
        "        metrics['test_acc'].append(test_acc)\n",
        "        metrics['train_spikes'].append(train_spikes_avg)\n",
        "        metrics['test_spikes'].append(test_spikes_avg)\n",
        "        metrics['layer_spikes'].append(test_spikes_avg)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"Train Loss: {train_loss_avg:.4f} | Train Acc: {train_acc:.2f}% | Train Spikes: {train_spikes_avg:.4f}\")\n",
        "        print(f\"Test Acc: {test_acc:.2f}% | Test Spikes: {test_spikes_avg:.4f}\")\n",
        "        print('-' * 60)\n",
        "\n",
        "        # Update best accuracy\n",
        "        if test_acc > best_accuracy:\n",
        "            best_accuracy = test_acc\n",
        "            best_epoch = epoch\n",
        "except Exception as e:\n",
        "    print(f\"Training error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Calculate total time and print final results\n",
        "total_time = time.time() - start_time\n",
        "print(f'\\nTraining completed in {total_time:.2f} seconds')\n",
        "\n",
        "if len(metrics['train_acc']) > 0:\n",
        "    print(f'Final train accuracy: {metrics[\"train_acc\"][-1]:.2f}%')\n",
        "    print(f'Final test accuracy: {metrics[\"test_acc\"][-1]:.2f}%')\n",
        "    print(f'Average spikes per neuron: {metrics[\"test_spikes\"][-1]:.4f}')\n",
        "    print(f'Best accuracy: {max(metrics[\"test_acc\"]):.2f}%')\n",
        "else:\n",
        "    print(\"No training completed.\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "if len(metrics['epoch']) > 0:\n",
        "    # Accuracy and loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['epoch'], metrics['train_acc'], 'b-', label='Train Accuracy')\n",
        "    plt.plot(metrics['epoch'], metrics['test_acc'], 'r-', label='Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Testing Accuracy')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Spike activity plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(metrics['epoch'], metrics['train_spikes'], 'g-', label='Train Spikes/Neuron')\n",
        "    plt.plot(metrics['epoch'], metrics['test_spikes'], 'm-', label='Test Spikes/Neuron')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Spikes per Neuron')\n",
        "    plt.legend()\n",
        "    plt.title('Spike Activity During Training')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{model_type}_results.png', dpi=300)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data to plot.\")\n",
        "\n",
        "# Save model if we have data\n",
        "if len(metrics['train_acc']) > 0:\n",
        "    try:\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'model_type': model_type\n",
        "        }, f'{model_type}_model.pth')\n",
        "        print(f\"Model saved to {model_type}_model.pth\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SKg_UPx7bS66",
        "outputId": "3e5d554a-d81e-442c-98ab-29f74ac1968e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "Using device: cpu\n",
            "Training on 60000 samples, testing on 10000 samples\n",
            "Creating snn model...\n",
            "Model created successfully!\n",
            "Starting training...\n",
            "Epoch 1, Batch 0: Loss = 2.2963, Acc = 15.62%, Spikes = 0.0061\n",
            "Epoch 1, Batch 10: Loss = 2.2974, Acc = 9.38%, Spikes = 0.0054\n",
            "Epoch 1, Batch 20: Loss = 2.2992, Acc = 9.82%, Spikes = 0.0062\n",
            "Epoch 1, Batch 30: Loss = 2.3039, Acc = 9.98%, Spikes = 0.0055\n",
            "Epoch 1, Batch 40: Loss = 2.3115, Acc = 10.67%, Spikes = 0.0061\n",
            "Epoch 1, Batch 50: Loss = 2.3002, Acc = 10.78%, Spikes = 0.0062\n",
            "Epoch 1, Batch 60: Loss = 2.3015, Acc = 10.76%, Spikes = 0.0063\n",
            "Epoch 1, Batch 70: Loss = 2.3020, Acc = 10.52%, Spikes = 0.0063\n",
            "Epoch 1, Batch 80: Loss = 2.3116, Acc = 10.49%, Spikes = 0.0059\n",
            "Epoch 1, Batch 90: Loss = 2.2858, Acc = 11.09%, Spikes = 0.0058\n",
            "Epoch 1, Batch 100: Loss = 2.2936, Acc = 11.54%, Spikes = 0.0058\n",
            "Epoch 1, Batch 110: Loss = 2.3005, Acc = 11.57%, Spikes = 0.0050\n",
            "Epoch 1, Batch 120: Loss = 2.2967, Acc = 11.52%, Spikes = 0.0047\n",
            "Epoch 1, Batch 130: Loss = 2.2960, Acc = 11.81%, Spikes = 0.0047\n",
            "Epoch 1, Batch 140: Loss = 2.2974, Acc = 12.26%, Spikes = 0.0040\n",
            "Epoch 1, Batch 150: Loss = 2.2943, Acc = 12.50%, Spikes = 0.0040\n",
            "Epoch 1, Batch 160: Loss = 2.2827, Acc = 12.60%, Spikes = 0.0042\n",
            "Epoch 1, Batch 170: Loss = 2.2985, Acc = 12.77%, Spikes = 0.0042\n",
            "Epoch 1, Batch 180: Loss = 2.3000, Acc = 12.81%, Spikes = 0.0039\n",
            "Epoch 1, Batch 190: Loss = 2.2873, Acc = 13.12%, Spikes = 0.0034\n",
            "Epoch 1, Batch 200: Loss = 2.2896, Acc = 13.20%, Spikes = 0.0029\n",
            "Epoch 1, Batch 210: Loss = 2.2916, Acc = 13.26%, Spikes = 0.0029\n",
            "Epoch 1, Batch 220: Loss = 2.2836, Acc = 13.26%, Spikes = 0.0025\n",
            "Epoch 1, Batch 230: Loss = 2.3105, Acc = 13.33%, Spikes = 0.0023\n",
            "Epoch 1, Batch 240: Loss = 2.2951, Acc = 13.28%, Spikes = 0.0020\n",
            "Epoch 1, Batch 250: Loss = 2.2866, Acc = 13.28%, Spikes = 0.0020\n",
            "Epoch 1, Batch 260: Loss = 2.3028, Acc = 13.25%, Spikes = 0.0015\n",
            "Epoch 1, Batch 270: Loss = 2.3224, Acc = 13.28%, Spikes = 0.0017\n",
            "Epoch 1, Batch 280: Loss = 2.3016, Acc = 13.29%, Spikes = 0.0012\n",
            "Epoch 1, Batch 290: Loss = 2.2928, Acc = 13.38%, Spikes = 0.0015\n",
            "Epoch 1, Batch 300: Loss = 2.2975, Acc = 13.36%, Spikes = 0.0013\n",
            "Epoch 1, Batch 310: Loss = 2.3004, Acc = 13.44%, Spikes = 0.0011\n",
            "Epoch 1, Batch 320: Loss = 2.2858, Acc = 13.51%, Spikes = 0.0010\n",
            "Epoch 1, Batch 330: Loss = 2.2997, Acc = 13.46%, Spikes = 0.0013\n",
            "Epoch 1, Batch 340: Loss = 2.3012, Acc = 13.40%, Spikes = 0.0009\n",
            "Epoch 1, Batch 350: Loss = 2.3005, Acc = 13.39%, Spikes = 0.0006\n",
            "Epoch 1, Batch 360: Loss = 2.2950, Acc = 13.37%, Spikes = 0.0008\n",
            "Epoch 1, Batch 370: Loss = 2.2974, Acc = 13.35%, Spikes = 0.0009\n",
            "Epoch 1, Batch 380: Loss = 2.3053, Acc = 13.30%, Spikes = 0.0006\n",
            "Epoch 1, Batch 390: Loss = 2.2836, Acc = 13.28%, Spikes = 0.0004\n",
            "Epoch 1, Batch 400: Loss = 2.2902, Acc = 13.25%, Spikes = 0.0008\n",
            "Epoch 1, Batch 410: Loss = 2.3136, Acc = 13.25%, Spikes = 0.0007\n",
            "Epoch 1, Batch 420: Loss = 2.2928, Acc = 13.24%, Spikes = 0.0005\n",
            "Epoch 1, Batch 430: Loss = 2.2971, Acc = 13.22%, Spikes = 0.0008\n",
            "Epoch 1, Batch 440: Loss = 2.2888, Acc = 13.18%, Spikes = 0.0011\n",
            "Epoch 1, Batch 450: Loss = 2.3005, Acc = 13.21%, Spikes = 0.0008\n",
            "Epoch 1, Batch 460: Loss = 2.2980, Acc = 13.23%, Spikes = 0.0011\n",
            "Epoch 1, Batch 470: Loss = 2.2882, Acc = 13.15%, Spikes = 0.0009\n",
            "Epoch 1, Batch 480: Loss = 2.2955, Acc = 13.20%, Spikes = 0.0008\n",
            "Epoch 1, Batch 490: Loss = 2.3037, Acc = 13.22%, Spikes = 0.0010\n",
            "Epoch 1, Batch 500: Loss = 2.3026, Acc = 13.18%, Spikes = 0.0011\n",
            "Epoch 1, Batch 510: Loss = 2.2991, Acc = 13.14%, Spikes = 0.0014\n",
            "Epoch 1, Batch 520: Loss = 2.2959, Acc = 13.15%, Spikes = 0.0013\n",
            "Epoch 1, Batch 530: Loss = 2.2928, Acc = 13.18%, Spikes = 0.0012\n",
            "Epoch 1, Batch 540: Loss = 2.2860, Acc = 13.23%, Spikes = 0.0013\n",
            "Epoch 1, Batch 550: Loss = 2.2944, Acc = 13.26%, Spikes = 0.0009\n",
            "Epoch 1, Batch 560: Loss = 2.2925, Acc = 13.34%, Spikes = 0.0011\n",
            "Epoch 1, Batch 570: Loss = 2.2922, Acc = 13.36%, Spikes = 0.0011\n",
            "Epoch 1, Batch 580: Loss = 2.2798, Acc = 13.44%, Spikes = 0.0015\n",
            "Epoch 1, Batch 590: Loss = 2.2911, Acc = 13.41%, Spikes = 0.0012\n",
            "Epoch 1, Batch 600: Loss = 2.2861, Acc = 13.49%, Spikes = 0.0007\n",
            "Epoch 1, Batch 610: Loss = 2.2798, Acc = 13.54%, Spikes = 0.0015\n",
            "Epoch 1, Batch 620: Loss = 2.2794, Acc = 13.59%, Spikes = 0.0011\n",
            "Epoch 1, Batch 630: Loss = 2.2812, Acc = 13.64%, Spikes = 0.0012\n",
            "Epoch 1, Batch 640: Loss = 2.3080, Acc = 13.70%, Spikes = 0.0011\n",
            "Epoch 1, Batch 650: Loss = 2.2912, Acc = 13.81%, Spikes = 0.0013\n",
            "Epoch 1, Batch 660: Loss = 2.2939, Acc = 13.84%, Spikes = 0.0017\n",
            "Epoch 1, Batch 670: Loss = 2.2895, Acc = 13.86%, Spikes = 0.0012\n",
            "Epoch 1, Batch 680: Loss = 2.2984, Acc = 13.94%, Spikes = 0.0016\n",
            "Epoch 1, Batch 690: Loss = 2.2862, Acc = 14.05%, Spikes = 0.0014\n",
            "Epoch 1, Batch 700: Loss = 2.2901, Acc = 14.06%, Spikes = 0.0015\n",
            "Epoch 1, Batch 710: Loss = 2.2806, Acc = 14.13%, Spikes = 0.0017\n",
            "Epoch 1, Batch 720: Loss = 2.2776, Acc = 14.24%, Spikes = 0.0019\n",
            "Epoch 1, Batch 730: Loss = 2.2874, Acc = 14.38%, Spikes = 0.0017\n",
            "Epoch 1, Batch 740: Loss = 2.2664, Acc = 14.47%, Spikes = 0.0025\n",
            "Epoch 1, Batch 750: Loss = 2.2719, Acc = 14.63%, Spikes = 0.0019\n",
            "Epoch 1, Batch 760: Loss = 2.2769, Acc = 14.78%, Spikes = 0.0023\n",
            "Epoch 1, Batch 770: Loss = 2.2725, Acc = 14.93%, Spikes = 0.0019\n",
            "Epoch 1, Batch 780: Loss = 2.2617, Acc = 15.06%, Spikes = 0.0027\n",
            "Epoch 1, Batch 790: Loss = 2.2958, Acc = 15.21%, Spikes = 0.0019\n",
            "Epoch 1, Batch 800: Loss = 2.2418, Acc = 15.36%, Spikes = 0.0039\n",
            "Epoch 1, Batch 810: Loss = 2.2576, Acc = 15.55%, Spikes = 0.0030\n",
            "Epoch 1, Batch 820: Loss = 2.2613, Acc = 15.69%, Spikes = 0.0029\n",
            "Epoch 1, Batch 830: Loss = 2.2425, Acc = 15.89%, Spikes = 0.0039\n",
            "Epoch 1, Batch 840: Loss = 2.2794, Acc = 16.06%, Spikes = 0.0021\n",
            "Epoch 1, Batch 850: Loss = 2.2645, Acc = 16.24%, Spikes = 0.0028\n",
            "Epoch 1, Batch 860: Loss = 2.2512, Acc = 16.52%, Spikes = 0.0029\n",
            "Epoch 1, Batch 870: Loss = 2.2620, Acc = 16.76%, Spikes = 0.0027\n",
            "Epoch 1, Batch 880: Loss = 2.2269, Acc = 16.99%, Spikes = 0.0040\n",
            "Epoch 1, Batch 890: Loss = 2.2405, Acc = 17.19%, Spikes = 0.0040\n",
            "Epoch 1, Batch 900: Loss = 2.2424, Acc = 17.38%, Spikes = 0.0042\n",
            "Epoch 1, Batch 910: Loss = 2.2730, Acc = 17.57%, Spikes = 0.0023\n",
            "Epoch 1, Batch 920: Loss = 2.2536, Acc = 17.81%, Spikes = 0.0038\n",
            "Epoch 1, Batch 930: Loss = 2.2303, Acc = 18.05%, Spikes = 0.0042\n",
            "Epoch 1, Batch 940: Loss = 2.2093, Acc = 18.29%, Spikes = 0.0051\n",
            "Epoch 1, Batch 950: Loss = 2.2556, Acc = 18.54%, Spikes = 0.0029\n",
            "Epoch 1, Batch 960: Loss = 2.2361, Acc = 18.77%, Spikes = 0.0043\n",
            "Epoch 1, Batch 970: Loss = 2.2528, Acc = 19.02%, Spikes = 0.0037\n",
            "Epoch 1, Batch 980: Loss = 2.2206, Acc = 19.27%, Spikes = 0.0042\n",
            "Epoch 1, Batch 990: Loss = 2.2380, Acc = 19.51%, Spikes = 0.0036\n",
            "Epoch 1, Batch 1000: Loss = 2.2507, Acc = 19.76%, Spikes = 0.0035\n",
            "Epoch 1, Batch 1010: Loss = 2.2438, Acc = 20.05%, Spikes = 0.0048\n",
            "Epoch 1, Batch 1020: Loss = 2.2286, Acc = 20.31%, Spikes = 0.0039\n",
            "Epoch 1, Batch 1030: Loss = 2.1996, Acc = 20.53%, Spikes = 0.0057\n",
            "Epoch 1, Batch 1040: Loss = 2.2109, Acc = 20.77%, Spikes = 0.0052\n",
            "Epoch 1, Batch 1050: Loss = 2.1737, Acc = 21.02%, Spikes = 0.0064\n",
            "Epoch 1, Batch 1060: Loss = 2.2073, Acc = 21.29%, Spikes = 0.0047\n",
            "Epoch 1, Batch 1070: Loss = 2.2210, Acc = 21.52%, Spikes = 0.0043\n",
            "Epoch 1, Batch 1080: Loss = 2.2044, Acc = 21.74%, Spikes = 0.0063\n",
            "Epoch 1, Batch 1090: Loss = 2.2276, Acc = 21.95%, Spikes = 0.0045\n",
            "Epoch 1, Batch 1100: Loss = 2.2071, Acc = 22.19%, Spikes = 0.0051\n",
            "Epoch 1, Batch 1110: Loss = 2.2399, Acc = 22.42%, Spikes = 0.0040\n",
            "Epoch 1, Batch 1120: Loss = 2.1873, Acc = 22.68%, Spikes = 0.0057\n",
            "Epoch 1, Batch 1130: Loss = 2.1982, Acc = 22.95%, Spikes = 0.0069\n",
            "Epoch 1, Batch 1140: Loss = 2.1962, Acc = 23.18%, Spikes = 0.0062\n",
            "Epoch 1, Batch 1150: Loss = 2.1431, Acc = 23.45%, Spikes = 0.0079\n",
            "Epoch 1, Batch 1160: Loss = 2.1564, Acc = 23.67%, Spikes = 0.0065\n",
            "Epoch 1, Batch 1170: Loss = 2.1782, Acc = 23.96%, Spikes = 0.0058\n",
            "Epoch 1, Batch 1180: Loss = 2.1757, Acc = 24.18%, Spikes = 0.0057\n",
            "Epoch 1, Batch 1190: Loss = 2.1622, Acc = 24.42%, Spikes = 0.0067\n",
            "Epoch 1, Batch 1200: Loss = 2.1857, Acc = 24.69%, Spikes = 0.0062\n",
            "Epoch 1, Batch 1210: Loss = 2.0643, Acc = 24.95%, Spikes = 0.0102\n",
            "Epoch 1, Batch 1220: Loss = 2.2099, Acc = 25.18%, Spikes = 0.0057\n",
            "Epoch 1, Batch 1230: Loss = 2.1728, Acc = 25.42%, Spikes = 0.0069\n",
            "Epoch 1, Batch 1240: Loss = 2.1930, Acc = 25.66%, Spikes = 0.0058\n",
            "Epoch 1, Batch 1250: Loss = 2.1277, Acc = 25.92%, Spikes = 0.0080\n",
            "Epoch 1, Batch 1260: Loss = 2.1240, Acc = 26.15%, Spikes = 0.0074\n",
            "Epoch 1, Batch 1270: Loss = 2.1259, Acc = 26.37%, Spikes = 0.0082\n",
            "Epoch 1, Batch 1280: Loss = 2.1039, Acc = 26.62%, Spikes = 0.0085\n",
            "Epoch 1, Batch 1290: Loss = 2.1255, Acc = 26.85%, Spikes = 0.0082\n",
            "Epoch 1, Batch 1300: Loss = 2.1715, Acc = 27.06%, Spikes = 0.0061\n",
            "Epoch 1, Batch 1310: Loss = 2.1017, Acc = 27.28%, Spikes = 0.0082\n",
            "Epoch 1, Batch 1320: Loss = 2.1620, Acc = 27.47%, Spikes = 0.0072\n",
            "Epoch 1, Batch 1330: Loss = 2.1720, Acc = 27.69%, Spikes = 0.0066\n",
            "Epoch 1, Batch 1340: Loss = 2.1309, Acc = 27.90%, Spikes = 0.0072\n",
            "Epoch 1, Batch 1350: Loss = 2.0843, Acc = 28.12%, Spikes = 0.0100\n",
            "Epoch 1, Batch 1360: Loss = 2.1291, Acc = 28.34%, Spikes = 0.0077\n",
            "Epoch 1, Batch 1370: Loss = 2.1167, Acc = 28.52%, Spikes = 0.0086\n",
            "Epoch 1, Batch 1380: Loss = 2.0641, Acc = 28.70%, Spikes = 0.0098\n",
            "Epoch 1, Batch 1390: Loss = 2.1290, Acc = 28.86%, Spikes = 0.0086\n",
            "Epoch 1, Batch 1400: Loss = 2.1067, Acc = 29.04%, Spikes = 0.0088\n",
            "Epoch 1, Batch 1410: Loss = 2.0619, Acc = 29.26%, Spikes = 0.0100\n",
            "Epoch 1, Batch 1420: Loss = 2.1590, Acc = 29.44%, Spikes = 0.0073\n",
            "Epoch 1, Batch 1430: Loss = 2.0584, Acc = 29.62%, Spikes = 0.0101\n",
            "Epoch 1, Batch 1440: Loss = 2.0485, Acc = 29.81%, Spikes = 0.0106\n",
            "Epoch 1, Batch 1450: Loss = 1.9857, Acc = 30.04%, Spikes = 0.0128\n",
            "Epoch 1, Batch 1460: Loss = 2.0439, Acc = 30.23%, Spikes = 0.0094\n",
            "Epoch 1, Batch 1470: Loss = 2.0066, Acc = 30.41%, Spikes = 0.0113\n",
            "Epoch 1, Batch 1480: Loss = 1.9842, Acc = 30.58%, Spikes = 0.0117\n",
            "Epoch 1, Batch 1490: Loss = 2.0210, Acc = 30.77%, Spikes = 0.0112\n",
            "Epoch 1, Batch 1500: Loss = 1.9558, Acc = 30.95%, Spikes = 0.0130\n",
            "Epoch 1, Batch 1510: Loss = 2.0075, Acc = 31.14%, Spikes = 0.0127\n",
            "Epoch 1, Batch 1520: Loss = 2.0771, Acc = 31.31%, Spikes = 0.0090\n",
            "Epoch 1, Batch 1530: Loss = 2.0391, Acc = 31.48%, Spikes = 0.0102\n",
            "Epoch 1, Batch 1540: Loss = 1.8927, Acc = 31.67%, Spikes = 0.0145\n",
            "Epoch 1, Batch 1550: Loss = 1.9722, Acc = 31.86%, Spikes = 0.0114\n",
            "Epoch 1, Batch 1560: Loss = 2.0341, Acc = 32.03%, Spikes = 0.0101\n",
            "Epoch 1, Batch 1570: Loss = 2.0496, Acc = 32.18%, Spikes = 0.0095\n",
            "Epoch 1, Batch 1580: Loss = 2.0143, Acc = 32.34%, Spikes = 0.0117\n",
            "Epoch 1, Batch 1590: Loss = 1.9373, Acc = 32.53%, Spikes = 0.0132\n",
            "Epoch 1, Batch 1600: Loss = 2.0281, Acc = 32.68%, Spikes = 0.0109\n",
            "Epoch 1, Batch 1610: Loss = 2.0626, Acc = 32.85%, Spikes = 0.0098\n",
            "Epoch 1, Batch 1620: Loss = 2.0467, Acc = 33.02%, Spikes = 0.0105\n",
            "Epoch 1, Batch 1630: Loss = 2.0010, Acc = 33.17%, Spikes = 0.0128\n",
            "Epoch 1, Batch 1640: Loss = 1.8596, Acc = 33.32%, Spikes = 0.0153\n",
            "Epoch 1, Batch 1650: Loss = 2.0575, Acc = 33.46%, Spikes = 0.0095\n",
            "Epoch 1, Batch 1660: Loss = 2.0472, Acc = 33.60%, Spikes = 0.0101\n",
            "Epoch 1, Batch 1670: Loss = 1.9570, Acc = 33.73%, Spikes = 0.0127\n",
            "Epoch 1, Batch 1680: Loss = 1.8801, Acc = 33.86%, Spikes = 0.0146\n",
            "Epoch 1, Batch 1690: Loss = 1.9167, Acc = 34.02%, Spikes = 0.0129\n",
            "Epoch 1, Batch 1700: Loss = 2.0755, Acc = 34.19%, Spikes = 0.0099\n",
            "Epoch 1, Batch 1710: Loss = 1.9119, Acc = 34.30%, Spikes = 0.0134\n",
            "Epoch 1, Batch 1720: Loss = 1.9828, Acc = 34.45%, Spikes = 0.0128\n",
            "Epoch 1, Batch 1730: Loss = 1.9334, Acc = 34.62%, Spikes = 0.0141\n",
            "Epoch 1, Batch 1740: Loss = 1.9109, Acc = 34.76%, Spikes = 0.0146\n",
            "Epoch 1, Batch 1750: Loss = 1.8898, Acc = 34.91%, Spikes = 0.0148\n",
            "Epoch 1, Batch 1760: Loss = 1.8772, Acc = 35.06%, Spikes = 0.0143\n",
            "Epoch 1, Batch 1770: Loss = 1.8370, Acc = 35.20%, Spikes = 0.0152\n",
            "Epoch 1, Batch 1780: Loss = 1.8702, Acc = 35.33%, Spikes = 0.0145\n",
            "Epoch 1, Batch 1790: Loss = 1.8173, Acc = 35.48%, Spikes = 0.0162\n",
            "Epoch 1, Batch 1800: Loss = 1.9357, Acc = 35.61%, Spikes = 0.0126\n",
            "Epoch 1, Batch 1810: Loss = 1.8023, Acc = 35.75%, Spikes = 0.0158\n",
            "Epoch 1, Batch 1820: Loss = 1.7647, Acc = 35.86%, Spikes = 0.0178\n",
            "Epoch 1, Batch 1830: Loss = 1.9211, Acc = 35.99%, Spikes = 0.0136\n",
            "Epoch 1, Batch 1840: Loss = 1.9051, Acc = 36.10%, Spikes = 0.0133\n",
            "Epoch 1, Batch 1850: Loss = 1.9124, Acc = 36.23%, Spikes = 0.0128\n",
            "Epoch 1, Batch 1860: Loss = 1.8593, Acc = 36.39%, Spikes = 0.0157\n",
            "Epoch 1, Batch 1870: Loss = 1.9241, Acc = 36.50%, Spikes = 0.0135\n",
            "Epoch 1/15:\n",
            "Train Loss: 2.1777 | Train Acc: 36.56% | Train Spikes: 0.0059\n",
            "Test Acc: 60.73% | Test Spikes: 0.0160\n",
            "------------------------------------------------------------\n",
            "Epoch 2, Batch 0: Loss = 1.8701, Acc = 62.50%, Spikes = 0.0149\n",
            "Epoch 2, Batch 10: Loss = 1.5824, Acc = 59.09%, Spikes = 0.0230\n",
            "Epoch 2, Batch 20: Loss = 1.8711, Acc = 61.16%, Spikes = 0.0169\n",
            "Epoch 2, Batch 30: Loss = 1.8586, Acc = 62.30%, Spikes = 0.0155\n",
            "Epoch 2, Batch 40: Loss = 1.9119, Acc = 61.97%, Spikes = 0.0138\n",
            "Epoch 2, Batch 50: Loss = 1.9208, Acc = 60.91%, Spikes = 0.0146\n",
            "Epoch 2, Batch 60: Loss = 1.8479, Acc = 61.07%, Spikes = 0.0143\n",
            "Epoch 2, Batch 70: Loss = 1.9088, Acc = 60.39%, Spikes = 0.0137\n",
            "Epoch 2, Batch 80: Loss = 1.8529, Acc = 60.15%, Spikes = 0.0136\n",
            "Epoch 2, Batch 90: Loss = 1.9136, Acc = 60.27%, Spikes = 0.0144\n",
            "Epoch 2, Batch 100: Loss = 1.9065, Acc = 60.06%, Spikes = 0.0134\n",
            "Epoch 2, Batch 110: Loss = 1.7109, Acc = 59.77%, Spikes = 0.0186\n",
            "Epoch 2, Batch 120: Loss = 1.8621, Acc = 59.35%, Spikes = 0.0153\n",
            "Epoch 2, Batch 130: Loss = 1.9003, Acc = 59.45%, Spikes = 0.0132\n",
            "Epoch 2, Batch 140: Loss = 1.9045, Acc = 59.82%, Spikes = 0.0134\n",
            "Epoch 2, Batch 150: Loss = 1.5078, Acc = 59.71%, Spikes = 0.0237\n",
            "Epoch 2, Batch 160: Loss = 1.8435, Acc = 59.67%, Spikes = 0.0173\n",
            "Epoch 2, Batch 170: Loss = 1.6660, Acc = 59.72%, Spikes = 0.0201\n",
            "Epoch 2, Batch 180: Loss = 1.6691, Acc = 59.44%, Spikes = 0.0199\n",
            "Epoch 2, Batch 190: Loss = 1.8586, Acc = 59.26%, Spikes = 0.0156\n",
            "Epoch 2, Batch 200: Loss = 1.6381, Acc = 59.39%, Spikes = 0.0212\n",
            "Epoch 2, Batch 210: Loss = 1.7336, Acc = 59.51%, Spikes = 0.0169\n",
            "Epoch 2, Batch 220: Loss = 1.8496, Acc = 59.87%, Spikes = 0.0158\n",
            "Epoch 2, Batch 230: Loss = 1.7416, Acc = 59.97%, Spikes = 0.0200\n",
            "Epoch 2, Batch 240: Loss = 1.6849, Acc = 59.91%, Spikes = 0.0196\n",
            "Epoch 2, Batch 250: Loss = 1.6420, Acc = 60.02%, Spikes = 0.0212\n",
            "Epoch 2, Batch 260: Loss = 1.7649, Acc = 60.09%, Spikes = 0.0158\n",
            "Epoch 2, Batch 270: Loss = 1.6504, Acc = 60.00%, Spikes = 0.0196\n",
            "Epoch 2, Batch 280: Loss = 1.6719, Acc = 60.20%, Spikes = 0.0192\n",
            "Epoch 2, Batch 290: Loss = 1.8854, Acc = 60.20%, Spikes = 0.0129\n",
            "Epoch 2, Batch 300: Loss = 1.7253, Acc = 60.31%, Spikes = 0.0179\n",
            "Epoch 2, Batch 310: Loss = 1.7442, Acc = 60.36%, Spikes = 0.0176\n",
            "Epoch 2, Batch 320: Loss = 1.6062, Acc = 60.48%, Spikes = 0.0208\n",
            "Epoch 2, Batch 330: Loss = 1.6273, Acc = 60.61%, Spikes = 0.0193\n",
            "Epoch 2, Batch 340: Loss = 1.6381, Acc = 60.58%, Spikes = 0.0193\n",
            "Epoch 2, Batch 350: Loss = 1.7147, Acc = 60.59%, Spikes = 0.0184\n",
            "Epoch 2, Batch 360: Loss = 1.5720, Acc = 60.66%, Spikes = 0.0209\n",
            "Epoch 2, Batch 370: Loss = 1.5694, Acc = 60.76%, Spikes = 0.0206\n",
            "Epoch 2, Batch 380: Loss = 1.7017, Acc = 60.78%, Spikes = 0.0184\n",
            "Epoch 2, Batch 390: Loss = 1.7491, Acc = 60.89%, Spikes = 0.0168\n",
            "Epoch 2, Batch 400: Loss = 1.8334, Acc = 60.85%, Spikes = 0.0163\n",
            "Epoch 2, Batch 410: Loss = 1.7323, Acc = 60.80%, Spikes = 0.0182\n",
            "Epoch 2, Batch 420: Loss = 1.5337, Acc = 60.79%, Spikes = 0.0236\n",
            "Epoch 2, Batch 430: Loss = 1.5496, Acc = 60.72%, Spikes = 0.0218\n",
            "Epoch 2, Batch 440: Loss = 1.7753, Acc = 60.64%, Spikes = 0.0158\n",
            "Epoch 2, Batch 450: Loss = 1.5676, Acc = 60.71%, Spikes = 0.0208\n",
            "Epoch 2, Batch 460: Loss = 1.6785, Acc = 60.73%, Spikes = 0.0190\n",
            "Epoch 2, Batch 470: Loss = 1.5777, Acc = 60.77%, Spikes = 0.0240\n",
            "Epoch 2, Batch 480: Loss = 1.5138, Acc = 60.85%, Spikes = 0.0231\n",
            "Epoch 2, Batch 490: Loss = 1.5552, Acc = 60.95%, Spikes = 0.0205\n",
            "Epoch 2, Batch 500: Loss = 1.5815, Acc = 60.95%, Spikes = 0.0208\n",
            "Epoch 2, Batch 510: Loss = 1.5082, Acc = 61.09%, Spikes = 0.0218\n",
            "Epoch 2, Batch 520: Loss = 1.5594, Acc = 61.11%, Spikes = 0.0241\n",
            "Epoch 2, Batch 530: Loss = 1.5669, Acc = 61.18%, Spikes = 0.0213\n",
            "Epoch 2, Batch 540: Loss = 1.6539, Acc = 61.25%, Spikes = 0.0223\n",
            "Epoch 2, Batch 550: Loss = 1.4824, Acc = 61.34%, Spikes = 0.0221\n",
            "Epoch 2, Batch 560: Loss = 1.6856, Acc = 61.39%, Spikes = 0.0190\n",
            "Epoch 2, Batch 570: Loss = 1.6125, Acc = 61.42%, Spikes = 0.0209\n",
            "Epoch 2, Batch 580: Loss = 1.5700, Acc = 61.42%, Spikes = 0.0232\n",
            "Epoch 2, Batch 590: Loss = 1.5536, Acc = 61.48%, Spikes = 0.0206\n",
            "Epoch 2, Batch 600: Loss = 1.5587, Acc = 61.54%, Spikes = 0.0224\n",
            "Epoch 2, Batch 610: Loss = 1.5795, Acc = 61.61%, Spikes = 0.0201\n",
            "Epoch 2, Batch 620: Loss = 1.5072, Acc = 61.65%, Spikes = 0.0231\n",
            "Epoch 2, Batch 630: Loss = 1.5982, Acc = 61.64%, Spikes = 0.0208\n",
            "Epoch 2, Batch 640: Loss = 1.6193, Acc = 61.69%, Spikes = 0.0207\n",
            "Epoch 2, Batch 650: Loss = 1.3558, Acc = 61.63%, Spikes = 0.0287\n",
            "Epoch 2, Batch 660: Loss = 1.6053, Acc = 61.69%, Spikes = 0.0203\n",
            "Epoch 2, Batch 670: Loss = 1.5007, Acc = 61.69%, Spikes = 0.0227\n",
            "Epoch 2, Batch 680: Loss = 1.4066, Acc = 61.73%, Spikes = 0.0246\n",
            "Epoch 2, Batch 690: Loss = 1.5226, Acc = 61.80%, Spikes = 0.0213\n",
            "Epoch 2, Batch 700: Loss = 1.5226, Acc = 61.78%, Spikes = 0.0248\n",
            "Epoch 2, Batch 710: Loss = 1.4482, Acc = 61.84%, Spikes = 0.0252\n",
            "Epoch 2, Batch 720: Loss = 1.6518, Acc = 61.87%, Spikes = 0.0203\n",
            "Epoch 2, Batch 730: Loss = 1.4089, Acc = 61.91%, Spikes = 0.0234\n",
            "Epoch 2, Batch 740: Loss = 1.7659, Acc = 61.88%, Spikes = 0.0199\n",
            "Epoch 2, Batch 750: Loss = 1.6220, Acc = 61.91%, Spikes = 0.0200\n",
            "Epoch 2, Batch 760: Loss = 1.2744, Acc = 61.91%, Spikes = 0.0302\n",
            "Epoch 2, Batch 770: Loss = 1.2285, Acc = 61.93%, Spikes = 0.0283\n",
            "Epoch 2, Batch 780: Loss = 1.4880, Acc = 61.94%, Spikes = 0.0238\n",
            "Epoch 2, Batch 790: Loss = 1.4280, Acc = 61.99%, Spikes = 0.0242\n",
            "Epoch 2, Batch 800: Loss = 1.6662, Acc = 61.97%, Spikes = 0.0186\n",
            "Epoch 2, Batch 810: Loss = 1.4658, Acc = 62.03%, Spikes = 0.0228\n",
            "Epoch 2, Batch 820: Loss = 1.4009, Acc = 62.10%, Spikes = 0.0247\n",
            "Epoch 2, Batch 830: Loss = 1.6086, Acc = 62.10%, Spikes = 0.0211\n",
            "Epoch 2, Batch 840: Loss = 1.4202, Acc = 62.14%, Spikes = 0.0243\n",
            "Epoch 2, Batch 850: Loss = 1.7245, Acc = 62.14%, Spikes = 0.0196\n",
            "Epoch 2, Batch 860: Loss = 1.4314, Acc = 62.14%, Spikes = 0.0261\n",
            "Epoch 2, Batch 870: Loss = 1.5593, Acc = 62.18%, Spikes = 0.0221\n",
            "Epoch 2, Batch 880: Loss = 1.4014, Acc = 62.21%, Spikes = 0.0247\n",
            "Epoch 2, Batch 890: Loss = 1.4649, Acc = 62.30%, Spikes = 0.0240\n",
            "Epoch 2, Batch 900: Loss = 1.6572, Acc = 62.34%, Spikes = 0.0210\n",
            "Epoch 2, Batch 910: Loss = 1.3758, Acc = 62.38%, Spikes = 0.0269\n",
            "Epoch 2, Batch 920: Loss = 1.4290, Acc = 62.41%, Spikes = 0.0231\n",
            "Epoch 2, Batch 930: Loss = 1.6577, Acc = 62.44%, Spikes = 0.0215\n",
            "Epoch 2, Batch 940: Loss = 1.3863, Acc = 62.49%, Spikes = 0.0234\n",
            "Epoch 2, Batch 950: Loss = 1.4836, Acc = 62.52%, Spikes = 0.0250\n",
            "Epoch 2, Batch 960: Loss = 1.4871, Acc = 62.52%, Spikes = 0.0268\n",
            "Epoch 2, Batch 970: Loss = 1.4959, Acc = 62.54%, Spikes = 0.0258\n",
            "Epoch 2, Batch 980: Loss = 1.5081, Acc = 62.58%, Spikes = 0.0239\n",
            "Epoch 2, Batch 990: Loss = 1.3309, Acc = 62.62%, Spikes = 0.0281\n",
            "Epoch 2, Batch 1000: Loss = 1.3661, Acc = 62.66%, Spikes = 0.0249\n",
            "Epoch 2, Batch 1010: Loss = 1.4237, Acc = 62.66%, Spikes = 0.0269\n",
            "Epoch 2, Batch 1020: Loss = 1.3312, Acc = 62.70%, Spikes = 0.0286\n",
            "Epoch 2, Batch 1030: Loss = 1.4576, Acc = 62.78%, Spikes = 0.0236\n",
            "Epoch 2, Batch 1040: Loss = 1.3264, Acc = 62.83%, Spikes = 0.0315\n",
            "Epoch 2, Batch 1050: Loss = 1.4254, Acc = 62.88%, Spikes = 0.0255\n",
            "Epoch 2, Batch 1060: Loss = 1.4150, Acc = 62.84%, Spikes = 0.0235\n",
            "Epoch 2, Batch 1070: Loss = 1.5044, Acc = 62.82%, Spikes = 0.0241\n",
            "Epoch 2, Batch 1080: Loss = 1.5055, Acc = 62.86%, Spikes = 0.0251\n",
            "Epoch 2, Batch 1090: Loss = 1.5844, Acc = 62.88%, Spikes = 0.0203\n",
            "Epoch 2, Batch 1100: Loss = 1.3983, Acc = 62.92%, Spikes = 0.0262\n",
            "Epoch 2, Batch 1110: Loss = 1.4156, Acc = 62.96%, Spikes = 0.0234\n",
            "Epoch 2, Batch 1120: Loss = 1.5023, Acc = 62.95%, Spikes = 0.0208\n",
            "Epoch 2, Batch 1130: Loss = 1.5335, Acc = 62.98%, Spikes = 0.0249\n",
            "Epoch 2, Batch 1140: Loss = 1.4594, Acc = 63.02%, Spikes = 0.0219\n",
            "Epoch 2, Batch 1150: Loss = 1.3876, Acc = 63.08%, Spikes = 0.0271\n",
            "Epoch 2, Batch 1160: Loss = 1.4720, Acc = 63.09%, Spikes = 0.0252\n",
            "Epoch 2, Batch 1170: Loss = 1.5514, Acc = 63.12%, Spikes = 0.0251\n",
            "Epoch 2, Batch 1180: Loss = 1.2997, Acc = 63.12%, Spikes = 0.0289\n",
            "Epoch 2, Batch 1190: Loss = 1.2844, Acc = 63.13%, Spikes = 0.0285\n",
            "Epoch 2, Batch 1200: Loss = 1.4761, Acc = 63.13%, Spikes = 0.0244\n",
            "Epoch 2, Batch 1210: Loss = 1.3728, Acc = 63.13%, Spikes = 0.0235\n",
            "Epoch 2, Batch 1220: Loss = 1.3363, Acc = 63.19%, Spikes = 0.0249\n",
            "Epoch 2, Batch 1230: Loss = 1.3766, Acc = 63.22%, Spikes = 0.0270\n",
            "Epoch 2, Batch 1240: Loss = 1.1099, Acc = 63.24%, Spikes = 0.0292\n",
            "Epoch 2, Batch 1250: Loss = 1.2627, Acc = 63.28%, Spikes = 0.0299\n",
            "Epoch 2, Batch 1260: Loss = 1.3854, Acc = 63.34%, Spikes = 0.0244\n",
            "Epoch 2, Batch 1270: Loss = 1.1751, Acc = 63.37%, Spikes = 0.0292\n",
            "Epoch 2, Batch 1280: Loss = 1.2507, Acc = 63.41%, Spikes = 0.0293\n",
            "Epoch 2, Batch 1290: Loss = 1.3021, Acc = 63.43%, Spikes = 0.0295\n",
            "Epoch 2, Batch 1300: Loss = 1.2981, Acc = 63.47%, Spikes = 0.0275\n",
            "Epoch 2, Batch 1310: Loss = 1.2800, Acc = 63.49%, Spikes = 0.0268\n",
            "Epoch 2, Batch 1320: Loss = 1.5063, Acc = 63.49%, Spikes = 0.0236\n",
            "Epoch 2, Batch 1330: Loss = 1.3317, Acc = 63.49%, Spikes = 0.0275\n",
            "Epoch 2, Batch 1340: Loss = 1.2741, Acc = 63.53%, Spikes = 0.0290\n",
            "Epoch 2, Batch 1350: Loss = 1.3583, Acc = 63.56%, Spikes = 0.0280\n",
            "Epoch 2, Batch 1360: Loss = 1.4560, Acc = 63.60%, Spikes = 0.0222\n",
            "Epoch 2, Batch 1370: Loss = 1.4781, Acc = 63.62%, Spikes = 0.0249\n",
            "Epoch 2, Batch 1380: Loss = 1.3257, Acc = 63.63%, Spikes = 0.0290\n",
            "Epoch 2, Batch 1390: Loss = 1.3294, Acc = 63.69%, Spikes = 0.0268\n",
            "Epoch 2, Batch 1400: Loss = 1.3131, Acc = 63.70%, Spikes = 0.0274\n",
            "Epoch 2, Batch 1410: Loss = 1.2033, Acc = 63.72%, Spikes = 0.0299\n",
            "Epoch 2, Batch 1420: Loss = 1.5240, Acc = 63.72%, Spikes = 0.0257\n",
            "Epoch 2, Batch 1430: Loss = 1.3693, Acc = 63.74%, Spikes = 0.0239\n",
            "Epoch 2, Batch 1440: Loss = 1.5759, Acc = 63.75%, Spikes = 0.0249\n",
            "Epoch 2, Batch 1450: Loss = 1.2839, Acc = 63.75%, Spikes = 0.0293\n",
            "Epoch 2, Batch 1460: Loss = 1.2502, Acc = 63.78%, Spikes = 0.0290\n",
            "Epoch 2, Batch 1470: Loss = 1.2121, Acc = 63.83%, Spikes = 0.0310\n",
            "Epoch 2, Batch 1480: Loss = 1.2672, Acc = 63.87%, Spikes = 0.0263\n",
            "Epoch 2, Batch 1490: Loss = 1.2829, Acc = 63.89%, Spikes = 0.0254\n",
            "Epoch 2, Batch 1500: Loss = 1.3061, Acc = 63.95%, Spikes = 0.0260\n",
            "Epoch 2, Batch 1510: Loss = 1.4240, Acc = 63.97%, Spikes = 0.0263\n",
            "Epoch 2, Batch 1520: Loss = 1.4095, Acc = 63.99%, Spikes = 0.0245\n",
            "Epoch 2, Batch 1530: Loss = 0.9618, Acc = 64.00%, Spikes = 0.0348\n",
            "Epoch 2, Batch 1540: Loss = 1.2088, Acc = 64.03%, Spikes = 0.0274\n",
            "Epoch 2, Batch 1550: Loss = 1.5753, Acc = 64.04%, Spikes = 0.0251\n",
            "Epoch 2, Batch 1560: Loss = 1.1372, Acc = 64.06%, Spikes = 0.0322\n",
            "Epoch 2, Batch 1570: Loss = 1.3396, Acc = 64.05%, Spikes = 0.0271\n",
            "Epoch 2, Batch 1580: Loss = 1.2698, Acc = 64.08%, Spikes = 0.0263\n",
            "Epoch 2, Batch 1590: Loss = 1.2997, Acc = 64.10%, Spikes = 0.0299\n",
            "Epoch 2, Batch 1600: Loss = 1.2995, Acc = 64.13%, Spikes = 0.0274\n",
            "Epoch 2, Batch 1610: Loss = 1.3315, Acc = 64.14%, Spikes = 0.0285\n",
            "Epoch 2, Batch 1620: Loss = 1.2980, Acc = 64.16%, Spikes = 0.0303\n",
            "Epoch 2, Batch 1630: Loss = 1.1059, Acc = 64.18%, Spikes = 0.0316\n",
            "Epoch 2, Batch 1640: Loss = 1.3356, Acc = 64.19%, Spikes = 0.0265\n",
            "Epoch 2, Batch 1650: Loss = 1.3085, Acc = 64.25%, Spikes = 0.0286\n",
            "Epoch 2, Batch 1660: Loss = 1.3543, Acc = 64.28%, Spikes = 0.0288\n",
            "Epoch 2, Batch 1670: Loss = 1.0447, Acc = 64.30%, Spikes = 0.0340\n",
            "Epoch 2, Batch 1680: Loss = 1.2809, Acc = 64.31%, Spikes = 0.0247\n",
            "Epoch 2, Batch 1690: Loss = 1.1816, Acc = 64.34%, Spikes = 0.0296\n",
            "Epoch 2, Batch 1700: Loss = 1.2663, Acc = 64.36%, Spikes = 0.0303\n",
            "Epoch 2, Batch 1710: Loss = 1.5132, Acc = 64.35%, Spikes = 0.0252\n",
            "Epoch 2, Batch 1720: Loss = 1.2833, Acc = 64.37%, Spikes = 0.0284\n",
            "Epoch 2, Batch 1730: Loss = 1.3144, Acc = 64.36%, Spikes = 0.0270\n",
            "Epoch 2, Batch 1740: Loss = 1.2440, Acc = 64.38%, Spikes = 0.0294\n",
            "Epoch 2, Batch 1750: Loss = 1.3104, Acc = 64.38%, Spikes = 0.0273\n",
            "Epoch 2, Batch 1760: Loss = 1.0962, Acc = 64.39%, Spikes = 0.0301\n",
            "Epoch 2, Batch 1770: Loss = 1.1640, Acc = 64.40%, Spikes = 0.0272\n",
            "Epoch 2, Batch 1780: Loss = 1.4497, Acc = 64.41%, Spikes = 0.0311\n",
            "Epoch 2, Batch 1790: Loss = 1.0772, Acc = 64.43%, Spikes = 0.0306\n",
            "Epoch 2, Batch 1800: Loss = 1.1651, Acc = 64.48%, Spikes = 0.0292\n",
            "Epoch 2, Batch 1810: Loss = 1.2977, Acc = 64.49%, Spikes = 0.0295\n",
            "Epoch 2, Batch 1820: Loss = 1.2402, Acc = 64.53%, Spikes = 0.0328\n",
            "Epoch 2, Batch 1830: Loss = 1.3567, Acc = 64.58%, Spikes = 0.0263\n",
            "Epoch 2, Batch 1840: Loss = 1.2335, Acc = 64.60%, Spikes = 0.0303\n",
            "Epoch 2, Batch 1850: Loss = 1.0268, Acc = 64.64%, Spikes = 0.0338\n",
            "Epoch 2, Batch 1860: Loss = 1.2462, Acc = 64.64%, Spikes = 0.0295\n",
            "Epoch 2, Batch 1870: Loss = 1.3134, Acc = 64.67%, Spikes = 0.0258\n",
            "Epoch 2/15:\n",
            "Train Loss: 1.4790 | Train Acc: 64.71% | Train Spikes: 0.0240\n",
            "Test Acc: 69.58% | Test Spikes: 0.0314\n",
            "------------------------------------------------------------\n",
            "Epoch 3, Batch 0: Loss = 1.0856, Acc = 68.75%, Spikes = 0.0340\n",
            "Epoch 3, Batch 10: Loss = 1.2203, Acc = 71.88%, Spikes = 0.0298\n",
            "Epoch 3, Batch 20: Loss = 1.4441, Acc = 70.54%, Spikes = 0.0276\n",
            "Epoch 3, Batch 30: Loss = 1.2432, Acc = 68.55%, Spikes = 0.0290\n",
            "Epoch 3, Batch 40: Loss = 1.1779, Acc = 68.37%, Spikes = 0.0324\n",
            "Epoch 3, Batch 50: Loss = 1.3260, Acc = 68.63%, Spikes = 0.0278\n",
            "Epoch 3, Batch 60: Loss = 1.3201, Acc = 68.90%, Spikes = 0.0253\n",
            "Epoch 3, Batch 70: Loss = 1.2307, Acc = 69.63%, Spikes = 0.0316\n",
            "Epoch 3, Batch 80: Loss = 1.0837, Acc = 69.44%, Spikes = 0.0348\n",
            "Epoch 3, Batch 90: Loss = 1.0432, Acc = 69.54%, Spikes = 0.0344\n",
            "Epoch 3, Batch 100: Loss = 1.4710, Acc = 69.46%, Spikes = 0.0268\n",
            "Epoch 3, Batch 110: Loss = 1.0906, Acc = 69.85%, Spikes = 0.0305\n",
            "Epoch 3, Batch 120: Loss = 1.1694, Acc = 69.96%, Spikes = 0.0297\n",
            "Epoch 3, Batch 130: Loss = 0.9211, Acc = 69.92%, Spikes = 0.0342\n",
            "Epoch 3, Batch 140: Loss = 1.2629, Acc = 69.77%, Spikes = 0.0274\n",
            "Epoch 3, Batch 150: Loss = 1.0514, Acc = 69.95%, Spikes = 0.0320\n",
            "Epoch 3, Batch 160: Loss = 1.1314, Acc = 70.05%, Spikes = 0.0292\n",
            "Epoch 3, Batch 170: Loss = 1.2259, Acc = 69.99%, Spikes = 0.0335\n",
            "Epoch 3, Batch 180: Loss = 1.1098, Acc = 69.70%, Spikes = 0.0310\n",
            "Epoch 3, Batch 190: Loss = 1.1801, Acc = 69.68%, Spikes = 0.0325\n",
            "Epoch 3, Batch 200: Loss = 1.2527, Acc = 69.54%, Spikes = 0.0314\n",
            "Epoch 3, Batch 210: Loss = 1.5246, Acc = 69.36%, Spikes = 0.0262\n",
            "Epoch 3, Batch 220: Loss = 1.2636, Acc = 69.39%, Spikes = 0.0310\n",
            "Epoch 3, Batch 230: Loss = 1.0754, Acc = 69.41%, Spikes = 0.0348\n",
            "Epoch 3, Batch 240: Loss = 1.1472, Acc = 69.54%, Spikes = 0.0333\n",
            "Epoch 3, Batch 250: Loss = 1.2648, Acc = 69.75%, Spikes = 0.0268\n",
            "Epoch 3, Batch 260: Loss = 1.0577, Acc = 69.62%, Spikes = 0.0345\n",
            "Epoch 3, Batch 270: Loss = 1.0170, Acc = 69.66%, Spikes = 0.0371\n",
            "Epoch 3, Batch 280: Loss = 1.2201, Acc = 69.68%, Spikes = 0.0321\n",
            "Epoch 3, Batch 290: Loss = 1.0826, Acc = 69.65%, Spikes = 0.0297\n",
            "Epoch 3, Batch 300: Loss = 1.1832, Acc = 69.56%, Spikes = 0.0315\n",
            "Epoch 3, Batch 310: Loss = 1.2478, Acc = 69.59%, Spikes = 0.0299\n",
            "Epoch 3, Batch 320: Loss = 1.1029, Acc = 69.61%, Spikes = 0.0309\n",
            "Epoch 3, Batch 330: Loss = 1.1036, Acc = 69.66%, Spikes = 0.0335\n",
            "Epoch 3, Batch 340: Loss = 1.1282, Acc = 69.64%, Spikes = 0.0304\n",
            "Epoch 3, Batch 350: Loss = 1.1697, Acc = 69.56%, Spikes = 0.0322\n",
            "Epoch 3, Batch 360: Loss = 1.1593, Acc = 69.76%, Spikes = 0.0325\n",
            "Epoch 3, Batch 370: Loss = 1.0606, Acc = 69.72%, Spikes = 0.0348\n",
            "Epoch 3, Batch 380: Loss = 1.1616, Acc = 69.64%, Spikes = 0.0328\n",
            "Epoch 3, Batch 390: Loss = 1.3613, Acc = 69.63%, Spikes = 0.0290\n",
            "Epoch 3, Batch 400: Loss = 1.2398, Acc = 69.58%, Spikes = 0.0334\n",
            "Epoch 3, Batch 410: Loss = 1.1279, Acc = 69.61%, Spikes = 0.0302\n",
            "Epoch 3, Batch 420: Loss = 1.3180, Acc = 69.71%, Spikes = 0.0326\n",
            "Epoch 3, Batch 430: Loss = 1.1670, Acc = 69.79%, Spikes = 0.0305\n",
            "Epoch 3, Batch 440: Loss = 1.0377, Acc = 69.73%, Spikes = 0.0343\n",
            "Epoch 3, Batch 450: Loss = 1.0656, Acc = 69.71%, Spikes = 0.0308\n",
            "Epoch 3, Batch 460: Loss = 1.0071, Acc = 69.71%, Spikes = 0.0342\n",
            "Epoch 3, Batch 470: Loss = 1.0742, Acc = 69.79%, Spikes = 0.0350\n",
            "Epoch 3, Batch 480: Loss = 1.1860, Acc = 69.87%, Spikes = 0.0295\n",
            "Epoch 3, Batch 490: Loss = 1.0123, Acc = 69.88%, Spikes = 0.0371\n",
            "Epoch 3, Batch 500: Loss = 1.1928, Acc = 69.85%, Spikes = 0.0301\n",
            "Epoch 3, Batch 510: Loss = 1.2016, Acc = 69.91%, Spikes = 0.0324\n",
            "Epoch 3, Batch 520: Loss = 1.0804, Acc = 69.97%, Spikes = 0.0338\n",
            "Epoch 3, Batch 530: Loss = 1.4364, Acc = 69.90%, Spikes = 0.0335\n",
            "Epoch 3, Batch 540: Loss = 1.0839, Acc = 69.89%, Spikes = 0.0310\n",
            "Epoch 3, Batch 550: Loss = 0.9919, Acc = 70.03%, Spikes = 0.0359\n",
            "Epoch 3, Batch 560: Loss = 1.2410, Acc = 70.02%, Spikes = 0.0293\n",
            "Epoch 3, Batch 570: Loss = 1.3343, Acc = 69.95%, Spikes = 0.0300\n",
            "Epoch 3, Batch 580: Loss = 1.0241, Acc = 70.02%, Spikes = 0.0355\n",
            "Epoch 3, Batch 590: Loss = 0.9236, Acc = 69.99%, Spikes = 0.0376\n",
            "Epoch 3, Batch 600: Loss = 1.2755, Acc = 69.95%, Spikes = 0.0331\n",
            "Epoch 3, Batch 610: Loss = 0.9894, Acc = 69.99%, Spikes = 0.0354\n",
            "Epoch 3, Batch 620: Loss = 1.1172, Acc = 70.05%, Spikes = 0.0369\n",
            "Epoch 3, Batch 630: Loss = 1.1197, Acc = 70.00%, Spikes = 0.0371\n",
            "Epoch 3, Batch 640: Loss = 1.1589, Acc = 69.98%, Spikes = 0.0286\n",
            "Epoch 3, Batch 650: Loss = 1.1092, Acc = 69.98%, Spikes = 0.0325\n",
            "Epoch 3, Batch 660: Loss = 1.1461, Acc = 70.04%, Spikes = 0.0360\n",
            "Epoch 3, Batch 670: Loss = 1.0749, Acc = 70.07%, Spikes = 0.0360\n",
            "Epoch 3, Batch 680: Loss = 0.7689, Acc = 70.09%, Spikes = 0.0391\n",
            "Epoch 3, Batch 690: Loss = 1.1835, Acc = 70.07%, Spikes = 0.0339\n",
            "Epoch 3, Batch 700: Loss = 1.0225, Acc = 70.10%, Spikes = 0.0361\n",
            "Epoch 3, Batch 710: Loss = 1.2666, Acc = 70.08%, Spikes = 0.0349\n",
            "Epoch 3, Batch 720: Loss = 1.3240, Acc = 70.12%, Spikes = 0.0288\n",
            "Epoch 3, Batch 730: Loss = 0.9942, Acc = 70.16%, Spikes = 0.0336\n",
            "Epoch 3, Batch 740: Loss = 1.1458, Acc = 70.17%, Spikes = 0.0307\n",
            "Epoch 3, Batch 750: Loss = 1.2765, Acc = 70.19%, Spikes = 0.0286\n",
            "Epoch 3, Batch 760: Loss = 1.1007, Acc = 70.23%, Spikes = 0.0325\n",
            "Epoch 3, Batch 770: Loss = 0.8583, Acc = 70.26%, Spikes = 0.0368\n",
            "Epoch 3, Batch 780: Loss = 1.2885, Acc = 70.25%, Spikes = 0.0355\n",
            "Epoch 3, Batch 790: Loss = 1.1493, Acc = 70.27%, Spikes = 0.0355\n",
            "Epoch 3, Batch 800: Loss = 1.1578, Acc = 70.28%, Spikes = 0.0333\n",
            "Epoch 3, Batch 810: Loss = 0.7926, Acc = 70.33%, Spikes = 0.0376\n",
            "Epoch 3, Batch 820: Loss = 1.2284, Acc = 70.35%, Spikes = 0.0296\n",
            "Epoch 3, Batch 830: Loss = 1.3040, Acc = 70.38%, Spikes = 0.0317\n",
            "Epoch 3, Batch 840: Loss = 0.9391, Acc = 70.42%, Spikes = 0.0348\n",
            "Epoch 3, Batch 850: Loss = 0.9120, Acc = 70.43%, Spikes = 0.0407\n",
            "Epoch 3, Batch 860: Loss = 0.8996, Acc = 70.47%, Spikes = 0.0386\n",
            "Epoch 3, Batch 870: Loss = 0.8614, Acc = 70.54%, Spikes = 0.0354\n",
            "Epoch 3, Batch 880: Loss = 1.1536, Acc = 70.57%, Spikes = 0.0354\n",
            "Epoch 3, Batch 890: Loss = 1.0502, Acc = 70.56%, Spikes = 0.0385\n",
            "Epoch 3, Batch 900: Loss = 1.1053, Acc = 70.56%, Spikes = 0.0331\n",
            "Epoch 3, Batch 910: Loss = 1.1459, Acc = 70.55%, Spikes = 0.0348\n",
            "Epoch 3, Batch 920: Loss = 1.0339, Acc = 70.58%, Spikes = 0.0361\n",
            "Epoch 3, Batch 930: Loss = 0.8679, Acc = 70.59%, Spikes = 0.0386\n",
            "Epoch 3, Batch 940: Loss = 1.1363, Acc = 70.59%, Spikes = 0.0354\n",
            "Epoch 3, Batch 950: Loss = 1.0442, Acc = 70.62%, Spikes = 0.0365\n",
            "Epoch 3, Batch 960: Loss = 0.9877, Acc = 70.63%, Spikes = 0.0329\n",
            "Epoch 3, Batch 970: Loss = 1.0078, Acc = 70.69%, Spikes = 0.0351\n",
            "Epoch 3, Batch 980: Loss = 1.1745, Acc = 70.73%, Spikes = 0.0335\n",
            "Epoch 3, Batch 990: Loss = 1.0764, Acc = 70.72%, Spikes = 0.0378\n",
            "Epoch 3, Batch 1000: Loss = 1.1663, Acc = 70.73%, Spikes = 0.0377\n",
            "Epoch 3, Batch 1010: Loss = 1.0533, Acc = 70.75%, Spikes = 0.0363\n",
            "Epoch 3, Batch 1020: Loss = 1.1192, Acc = 70.78%, Spikes = 0.0345\n",
            "Epoch 3, Batch 1030: Loss = 1.0656, Acc = 70.79%, Spikes = 0.0350\n",
            "Epoch 3, Batch 1040: Loss = 0.8769, Acc = 70.85%, Spikes = 0.0412\n",
            "Epoch 3, Batch 1050: Loss = 1.1644, Acc = 70.84%, Spikes = 0.0349\n",
            "Epoch 3, Batch 1060: Loss = 1.0103, Acc = 70.82%, Spikes = 0.0390\n",
            "Epoch 3, Batch 1070: Loss = 1.1978, Acc = 70.82%, Spikes = 0.0335\n",
            "Epoch 3, Batch 1080: Loss = 0.9307, Acc = 70.83%, Spikes = 0.0372\n",
            "Epoch 3, Batch 1090: Loss = 0.7821, Acc = 70.88%, Spikes = 0.0345\n",
            "Epoch 3, Batch 1100: Loss = 0.9693, Acc = 70.89%, Spikes = 0.0367\n",
            "Epoch 3, Batch 1110: Loss = 0.8723, Acc = 70.88%, Spikes = 0.0422\n",
            "Epoch 3, Batch 1120: Loss = 1.0855, Acc = 70.86%, Spikes = 0.0366\n",
            "Epoch 3, Batch 1130: Loss = 0.9791, Acc = 70.85%, Spikes = 0.0379\n",
            "Epoch 3, Batch 1140: Loss = 0.9734, Acc = 70.88%, Spikes = 0.0384\n",
            "Epoch 3, Batch 1150: Loss = 0.9441, Acc = 70.89%, Spikes = 0.0388\n",
            "Epoch 3, Batch 1160: Loss = 1.1021, Acc = 70.90%, Spikes = 0.0307\n",
            "Epoch 3, Batch 1170: Loss = 1.0743, Acc = 70.88%, Spikes = 0.0328\n",
            "Epoch 3, Batch 1180: Loss = 1.2707, Acc = 70.91%, Spikes = 0.0364\n",
            "Epoch 3, Batch 1190: Loss = 0.9931, Acc = 70.96%, Spikes = 0.0368\n",
            "Epoch 3, Batch 1200: Loss = 1.0449, Acc = 70.97%, Spikes = 0.0339\n",
            "Epoch 3, Batch 1210: Loss = 0.9960, Acc = 71.00%, Spikes = 0.0336\n",
            "Epoch 3, Batch 1220: Loss = 1.0665, Acc = 71.00%, Spikes = 0.0355\n",
            "Epoch 3, Batch 1230: Loss = 1.0570, Acc = 71.01%, Spikes = 0.0370\n",
            "Epoch 3, Batch 1240: Loss = 1.0391, Acc = 71.04%, Spikes = 0.0318\n",
            "Epoch 3, Batch 1250: Loss = 1.1124, Acc = 71.05%, Spikes = 0.0379\n",
            "Epoch 3, Batch 1260: Loss = 1.0791, Acc = 71.07%, Spikes = 0.0366\n",
            "Epoch 3, Batch 1270: Loss = 0.9097, Acc = 71.06%, Spikes = 0.0402\n",
            "Epoch 3, Batch 1280: Loss = 0.9779, Acc = 71.05%, Spikes = 0.0334\n",
            "Epoch 3, Batch 1290: Loss = 1.2766, Acc = 71.06%, Spikes = 0.0319\n",
            "Epoch 3, Batch 1300: Loss = 1.0100, Acc = 71.07%, Spikes = 0.0371\n",
            "Epoch 3, Batch 1310: Loss = 0.9628, Acc = 71.08%, Spikes = 0.0356\n",
            "Epoch 3, Batch 1320: Loss = 0.9459, Acc = 71.11%, Spikes = 0.0333\n",
            "Epoch 3, Batch 1330: Loss = 1.3400, Acc = 71.12%, Spikes = 0.0305\n",
            "Epoch 3, Batch 1340: Loss = 0.9271, Acc = 71.13%, Spikes = 0.0378\n",
            "Epoch 3, Batch 1350: Loss = 0.8496, Acc = 71.16%, Spikes = 0.0373\n",
            "Epoch 3, Batch 1360: Loss = 0.7161, Acc = 71.19%, Spikes = 0.0443\n",
            "Epoch 3, Batch 1370: Loss = 1.1405, Acc = 71.20%, Spikes = 0.0339\n",
            "Epoch 3, Batch 1380: Loss = 1.0535, Acc = 71.23%, Spikes = 0.0382\n",
            "Epoch 3, Batch 1390: Loss = 0.8518, Acc = 71.26%, Spikes = 0.0359\n",
            "Epoch 3, Batch 1400: Loss = 1.1253, Acc = 71.26%, Spikes = 0.0322\n",
            "Epoch 3, Batch 1410: Loss = 0.9189, Acc = 71.25%, Spikes = 0.0355\n",
            "Epoch 3, Batch 1420: Loss = 0.9367, Acc = 71.25%, Spikes = 0.0371\n",
            "Epoch 3, Batch 1430: Loss = 0.8314, Acc = 71.28%, Spikes = 0.0441\n",
            "Epoch 3, Batch 1440: Loss = 1.0033, Acc = 71.29%, Spikes = 0.0337\n",
            "Epoch 3, Batch 1450: Loss = 1.2058, Acc = 71.32%, Spikes = 0.0339\n",
            "Epoch 3, Batch 1460: Loss = 0.9413, Acc = 71.34%, Spikes = 0.0357\n",
            "Epoch 3, Batch 1470: Loss = 0.9660, Acc = 71.36%, Spikes = 0.0363\n",
            "Epoch 3, Batch 1480: Loss = 0.8389, Acc = 71.35%, Spikes = 0.0362\n",
            "Epoch 3, Batch 1490: Loss = 1.0297, Acc = 71.36%, Spikes = 0.0379\n",
            "Epoch 3, Batch 1500: Loss = 1.0195, Acc = 71.36%, Spikes = 0.0366\n",
            "Epoch 3, Batch 1510: Loss = 0.9141, Acc = 71.39%, Spikes = 0.0340\n",
            "Epoch 3, Batch 1520: Loss = 1.0669, Acc = 71.41%, Spikes = 0.0351\n",
            "Epoch 3, Batch 1530: Loss = 1.0352, Acc = 71.44%, Spikes = 0.0297\n",
            "Epoch 3, Batch 1540: Loss = 0.8530, Acc = 71.46%, Spikes = 0.0421\n",
            "Epoch 3, Batch 1550: Loss = 0.7095, Acc = 71.50%, Spikes = 0.0397\n",
            "Epoch 3, Batch 1560: Loss = 0.8186, Acc = 71.49%, Spikes = 0.0386\n",
            "Epoch 3, Batch 1570: Loss = 1.1535, Acc = 71.48%, Spikes = 0.0332\n",
            "Epoch 3, Batch 1580: Loss = 1.1027, Acc = 71.49%, Spikes = 0.0383\n",
            "Epoch 3, Batch 1590: Loss = 1.3360, Acc = 71.49%, Spikes = 0.0367\n",
            "Epoch 3, Batch 1600: Loss = 0.9768, Acc = 71.48%, Spikes = 0.0414\n",
            "Epoch 3, Batch 1610: Loss = 0.9226, Acc = 71.49%, Spikes = 0.0395\n",
            "Epoch 3, Batch 1620: Loss = 1.0044, Acc = 71.51%, Spikes = 0.0375\n",
            "Epoch 3, Batch 1630: Loss = 0.5936, Acc = 71.54%, Spikes = 0.0444\n",
            "Epoch 3, Batch 1640: Loss = 1.1696, Acc = 71.55%, Spikes = 0.0308\n",
            "Epoch 3, Batch 1650: Loss = 1.1051, Acc = 71.57%, Spikes = 0.0397\n",
            "Epoch 3, Batch 1660: Loss = 1.0604, Acc = 71.58%, Spikes = 0.0362\n",
            "Epoch 3, Batch 1670: Loss = 1.2116, Acc = 71.59%, Spikes = 0.0373\n",
            "Epoch 3, Batch 1680: Loss = 1.1177, Acc = 71.61%, Spikes = 0.0337\n",
            "Epoch 3, Batch 1690: Loss = 1.1652, Acc = 71.62%, Spikes = 0.0354\n",
            "Epoch 3, Batch 1700: Loss = 0.9980, Acc = 71.65%, Spikes = 0.0399\n",
            "Epoch 3, Batch 1710: Loss = 0.7706, Acc = 71.67%, Spikes = 0.0454\n",
            "Epoch 3, Batch 1720: Loss = 1.1479, Acc = 71.69%, Spikes = 0.0345\n",
            "Epoch 3, Batch 1730: Loss = 1.0499, Acc = 71.71%, Spikes = 0.0351\n",
            "Epoch 3, Batch 1740: Loss = 1.0860, Acc = 71.72%, Spikes = 0.0386\n",
            "Epoch 3, Batch 1750: Loss = 0.6756, Acc = 71.75%, Spikes = 0.0427\n",
            "Epoch 3, Batch 1760: Loss = 0.9186, Acc = 71.75%, Spikes = 0.0369\n",
            "Epoch 3, Batch 1770: Loss = 1.3715, Acc = 71.77%, Spikes = 0.0325\n",
            "Epoch 3, Batch 1780: Loss = 0.9882, Acc = 71.79%, Spikes = 0.0370\n",
            "Epoch 3, Batch 1790: Loss = 1.0217, Acc = 71.79%, Spikes = 0.0346\n",
            "Epoch 3, Batch 1800: Loss = 0.8707, Acc = 71.81%, Spikes = 0.0386\n",
            "Epoch 3, Batch 1810: Loss = 1.1251, Acc = 71.82%, Spikes = 0.0398\n",
            "Epoch 3, Batch 1820: Loss = 0.9791, Acc = 71.85%, Spikes = 0.0395\n",
            "Epoch 3, Batch 1830: Loss = 1.0110, Acc = 71.86%, Spikes = 0.0388\n",
            "Epoch 3, Batch 1840: Loss = 1.0681, Acc = 71.87%, Spikes = 0.0359\n",
            "Epoch 3, Batch 1850: Loss = 0.8530, Acc = 71.89%, Spikes = 0.0423\n",
            "Epoch 3, Batch 1860: Loss = 1.0728, Acc = 71.90%, Spikes = 0.0411\n",
            "Epoch 3, Batch 1870: Loss = 0.9434, Acc = 71.89%, Spikes = 0.0392\n",
            "Epoch 3/15:\n",
            "Train Loss: 1.0650 | Train Acc: 71.88% | Train Spikes: 0.0350\n",
            "Test Acc: 75.19% | Test Spikes: 0.0401\n",
            "------------------------------------------------------------\n",
            "Epoch 4, Batch 0: Loss = 0.8032, Acc = 87.50%, Spikes = 0.0364\n",
            "Epoch 4, Batch 10: Loss = 0.9795, Acc = 73.01%, Spikes = 0.0390\n",
            "Epoch 4, Batch 20: Loss = 0.9659, Acc = 73.07%, Spikes = 0.0356\n",
            "Epoch 4, Batch 30: Loss = 1.0571, Acc = 73.29%, Spikes = 0.0397\n",
            "Epoch 4, Batch 40: Loss = 0.8030, Acc = 73.93%, Spikes = 0.0425\n",
            "Epoch 4, Batch 50: Loss = 0.9748, Acc = 74.14%, Spikes = 0.0336\n",
            "Epoch 4, Batch 60: Loss = 0.8470, Acc = 73.98%, Spikes = 0.0356\n",
            "Epoch 4, Batch 70: Loss = 0.8624, Acc = 74.30%, Spikes = 0.0375\n",
            "Epoch 4, Batch 80: Loss = 0.8353, Acc = 74.50%, Spikes = 0.0418\n",
            "Epoch 4, Batch 90: Loss = 0.8076, Acc = 74.62%, Spikes = 0.0416\n",
            "Epoch 4, Batch 100: Loss = 0.8634, Acc = 74.66%, Spikes = 0.0379\n",
            "Epoch 4, Batch 110: Loss = 0.9440, Acc = 74.72%, Spikes = 0.0414\n",
            "Epoch 4, Batch 120: Loss = 1.0871, Acc = 74.69%, Spikes = 0.0349\n",
            "Epoch 4, Batch 130: Loss = 0.8397, Acc = 74.86%, Spikes = 0.0373\n",
            "Epoch 4, Batch 140: Loss = 0.9672, Acc = 74.73%, Spikes = 0.0364\n",
            "Epoch 4, Batch 150: Loss = 0.7289, Acc = 75.12%, Spikes = 0.0428\n",
            "Epoch 4, Batch 160: Loss = 0.8997, Acc = 74.98%, Spikes = 0.0408\n",
            "Epoch 4, Batch 170: Loss = 0.8975, Acc = 74.78%, Spikes = 0.0440\n",
            "Epoch 4, Batch 180: Loss = 0.8554, Acc = 74.79%, Spikes = 0.0401\n",
            "Epoch 4, Batch 190: Loss = 0.9603, Acc = 74.87%, Spikes = 0.0348\n",
            "Epoch 4, Batch 200: Loss = 0.8566, Acc = 74.70%, Spikes = 0.0419\n",
            "Epoch 4, Batch 210: Loss = 0.9584, Acc = 74.59%, Spikes = 0.0427\n",
            "Epoch 4, Batch 220: Loss = 0.7543, Acc = 74.58%, Spikes = 0.0439\n",
            "Epoch 4, Batch 230: Loss = 0.9135, Acc = 74.68%, Spikes = 0.0390\n",
            "Epoch 4, Batch 240: Loss = 0.8270, Acc = 74.62%, Spikes = 0.0434\n",
            "Epoch 4, Batch 250: Loss = 0.9856, Acc = 74.74%, Spikes = 0.0383\n",
            "Epoch 4, Batch 260: Loss = 0.9544, Acc = 74.74%, Spikes = 0.0379\n",
            "Epoch 4, Batch 270: Loss = 0.9233, Acc = 74.90%, Spikes = 0.0390\n",
            "Epoch 4, Batch 280: Loss = 1.1148, Acc = 74.89%, Spikes = 0.0451\n",
            "Epoch 4, Batch 290: Loss = 1.0535, Acc = 74.88%, Spikes = 0.0403\n",
            "Epoch 4, Batch 300: Loss = 0.9077, Acc = 74.79%, Spikes = 0.0420\n",
            "Epoch 4, Batch 310: Loss = 0.9466, Acc = 74.77%, Spikes = 0.0391\n",
            "Epoch 4, Batch 320: Loss = 0.8748, Acc = 75.01%, Spikes = 0.0398\n",
            "Epoch 4, Batch 330: Loss = 0.7484, Acc = 75.11%, Spikes = 0.0440\n",
            "Epoch 4, Batch 340: Loss = 0.8705, Acc = 75.01%, Spikes = 0.0362\n",
            "Epoch 4, Batch 350: Loss = 0.8453, Acc = 75.06%, Spikes = 0.0434\n",
            "Epoch 4, Batch 360: Loss = 0.8928, Acc = 75.06%, Spikes = 0.0407\n",
            "Epoch 4, Batch 370: Loss = 0.8952, Acc = 74.97%, Spikes = 0.0397\n",
            "Epoch 4, Batch 380: Loss = 0.8510, Acc = 74.96%, Spikes = 0.0390\n",
            "Epoch 4, Batch 390: Loss = 0.8982, Acc = 75.00%, Spikes = 0.0383\n",
            "Epoch 4, Batch 400: Loss = 0.8032, Acc = 74.91%, Spikes = 0.0450\n",
            "Epoch 4, Batch 410: Loss = 0.8238, Acc = 74.86%, Spikes = 0.0372\n",
            "Epoch 4, Batch 420: Loss = 1.0143, Acc = 74.95%, Spikes = 0.0382\n",
            "Epoch 4, Batch 430: Loss = 1.0039, Acc = 74.90%, Spikes = 0.0396\n",
            "Epoch 4, Batch 440: Loss = 1.1291, Acc = 74.79%, Spikes = 0.0349\n",
            "Epoch 4, Batch 450: Loss = 0.8657, Acc = 74.82%, Spikes = 0.0411\n",
            "Epoch 4, Batch 460: Loss = 0.9133, Acc = 74.82%, Spikes = 0.0382\n",
            "Epoch 4, Batch 470: Loss = 0.8778, Acc = 74.85%, Spikes = 0.0365\n",
            "Epoch 4, Batch 480: Loss = 0.6985, Acc = 74.98%, Spikes = 0.0415\n",
            "Epoch 4, Batch 490: Loss = 1.0703, Acc = 74.93%, Spikes = 0.0364\n",
            "Epoch 4, Batch 500: Loss = 1.1503, Acc = 74.84%, Spikes = 0.0436\n",
            "Epoch 4, Batch 510: Loss = 1.0152, Acc = 74.85%, Spikes = 0.0401\n",
            "Epoch 4, Batch 520: Loss = 0.8567, Acc = 74.81%, Spikes = 0.0415\n",
            "Epoch 4, Batch 530: Loss = 0.7169, Acc = 74.91%, Spikes = 0.0422\n",
            "Epoch 4, Batch 540: Loss = 1.0271, Acc = 74.83%, Spikes = 0.0396\n",
            "Epoch 4, Batch 550: Loss = 0.7051, Acc = 74.86%, Spikes = 0.0403\n",
            "Epoch 4, Batch 560: Loss = 0.8052, Acc = 74.86%, Spikes = 0.0442\n",
            "Epoch 4, Batch 570: Loss = 0.9726, Acc = 74.76%, Spikes = 0.0375\n",
            "Epoch 4, Batch 580: Loss = 0.9815, Acc = 74.78%, Spikes = 0.0418\n",
            "Epoch 4, Batch 590: Loss = 0.6466, Acc = 74.85%, Spikes = 0.0479\n",
            "Epoch 4, Batch 600: Loss = 0.7053, Acc = 74.85%, Spikes = 0.0431\n",
            "Epoch 4, Batch 610: Loss = 0.9889, Acc = 74.85%, Spikes = 0.0387\n",
            "Epoch 4, Batch 620: Loss = 0.7811, Acc = 74.81%, Spikes = 0.0435\n",
            "Epoch 4, Batch 630: Loss = 0.7375, Acc = 74.80%, Spikes = 0.0452\n",
            "Epoch 4, Batch 640: Loss = 0.8952, Acc = 74.83%, Spikes = 0.0435\n",
            "Epoch 4, Batch 650: Loss = 1.0645, Acc = 74.73%, Spikes = 0.0399\n",
            "Epoch 4, Batch 660: Loss = 0.8239, Acc = 74.76%, Spikes = 0.0456\n",
            "Epoch 4, Batch 670: Loss = 0.9321, Acc = 74.73%, Spikes = 0.0377\n",
            "Epoch 4, Batch 680: Loss = 0.9605, Acc = 74.70%, Spikes = 0.0353\n",
            "Epoch 4, Batch 690: Loss = 1.0062, Acc = 74.66%, Spikes = 0.0429\n",
            "Epoch 4, Batch 700: Loss = 0.8670, Acc = 74.69%, Spikes = 0.0369\n",
            "Epoch 4, Batch 710: Loss = 1.0287, Acc = 74.70%, Spikes = 0.0363\n",
            "Epoch 4, Batch 720: Loss = 0.9004, Acc = 74.68%, Spikes = 0.0427\n",
            "Epoch 4, Batch 730: Loss = 0.9195, Acc = 74.74%, Spikes = 0.0389\n",
            "Epoch 4, Batch 740: Loss = 1.1928, Acc = 74.74%, Spikes = 0.0365\n",
            "Epoch 4, Batch 750: Loss = 0.8845, Acc = 74.71%, Spikes = 0.0433\n",
            "Epoch 4, Batch 760: Loss = 1.0479, Acc = 74.73%, Spikes = 0.0391\n",
            "Epoch 4, Batch 770: Loss = 0.9541, Acc = 74.72%, Spikes = 0.0433\n",
            "Epoch 4, Batch 780: Loss = 0.7714, Acc = 74.71%, Spikes = 0.0400\n",
            "Epoch 4, Batch 790: Loss = 0.7617, Acc = 74.66%, Spikes = 0.0489\n",
            "Epoch 4, Batch 800: Loss = 1.0443, Acc = 74.67%, Spikes = 0.0416\n",
            "Epoch 4, Batch 810: Loss = 0.8159, Acc = 74.70%, Spikes = 0.0418\n",
            "Epoch 4, Batch 820: Loss = 0.9039, Acc = 74.71%, Spikes = 0.0443\n",
            "Epoch 4, Batch 830: Loss = 1.0459, Acc = 74.71%, Spikes = 0.0393\n",
            "Epoch 4, Batch 840: Loss = 0.6980, Acc = 74.71%, Spikes = 0.0453\n",
            "Epoch 4, Batch 850: Loss = 1.1318, Acc = 74.73%, Spikes = 0.0398\n",
            "Epoch 4, Batch 860: Loss = 1.2214, Acc = 74.74%, Spikes = 0.0389\n",
            "Epoch 4, Batch 870: Loss = 0.9558, Acc = 74.73%, Spikes = 0.0377\n",
            "Epoch 4, Batch 880: Loss = 0.8344, Acc = 74.73%, Spikes = 0.0466\n",
            "Epoch 4, Batch 890: Loss = 0.7770, Acc = 74.74%, Spikes = 0.0412\n",
            "Epoch 4, Batch 900: Loss = 1.0345, Acc = 74.73%, Spikes = 0.0335\n",
            "Epoch 4, Batch 910: Loss = 0.8409, Acc = 74.70%, Spikes = 0.0462\n",
            "Epoch 4, Batch 920: Loss = 0.8718, Acc = 74.72%, Spikes = 0.0445\n",
            "Epoch 4, Batch 930: Loss = 1.0384, Acc = 74.68%, Spikes = 0.0408\n",
            "Epoch 4, Batch 940: Loss = 1.0549, Acc = 74.66%, Spikes = 0.0448\n",
            "Epoch 4, Batch 950: Loss = 0.9507, Acc = 74.65%, Spikes = 0.0414\n",
            "Epoch 4, Batch 960: Loss = 0.7803, Acc = 74.66%, Spikes = 0.0460\n",
            "Epoch 4, Batch 970: Loss = 1.1326, Acc = 74.66%, Spikes = 0.0373\n",
            "Epoch 4, Batch 980: Loss = 1.0302, Acc = 74.68%, Spikes = 0.0427\n",
            "Epoch 4, Batch 990: Loss = 0.8926, Acc = 74.65%, Spikes = 0.0434\n",
            "Epoch 4, Batch 1000: Loss = 0.9611, Acc = 74.68%, Spikes = 0.0405\n",
            "Epoch 4, Batch 1010: Loss = 0.7483, Acc = 74.69%, Spikes = 0.0447\n",
            "Epoch 4, Batch 1020: Loss = 0.8236, Acc = 74.72%, Spikes = 0.0416\n",
            "Epoch 4, Batch 1030: Loss = 0.8944, Acc = 74.69%, Spikes = 0.0432\n",
            "Epoch 4, Batch 1040: Loss = 0.7253, Acc = 74.69%, Spikes = 0.0475\n",
            "Epoch 4, Batch 1050: Loss = 0.9847, Acc = 74.71%, Spikes = 0.0426\n",
            "Epoch 4, Batch 1060: Loss = 0.9680, Acc = 74.71%, Spikes = 0.0411\n",
            "Epoch 4, Batch 1070: Loss = 1.0914, Acc = 74.70%, Spikes = 0.0474\n",
            "Epoch 4, Batch 1080: Loss = 0.7894, Acc = 74.71%, Spikes = 0.0396\n",
            "Epoch 4, Batch 1090: Loss = 0.7085, Acc = 74.72%, Spikes = 0.0468\n",
            "Epoch 4, Batch 1100: Loss = 0.8523, Acc = 74.73%, Spikes = 0.0433\n",
            "Epoch 4, Batch 1110: Loss = 1.2407, Acc = 74.73%, Spikes = 0.0419\n",
            "Epoch 4, Batch 1120: Loss = 0.9710, Acc = 74.72%, Spikes = 0.0419\n",
            "Epoch 4, Batch 1130: Loss = 0.8370, Acc = 74.72%, Spikes = 0.0415\n",
            "Epoch 4, Batch 1140: Loss = 0.7428, Acc = 74.76%, Spikes = 0.0411\n",
            "Epoch 4, Batch 1150: Loss = 1.0619, Acc = 74.75%, Spikes = 0.0438\n",
            "Epoch 4, Batch 1160: Loss = 0.7720, Acc = 74.73%, Spikes = 0.0429\n",
            "Epoch 4, Batch 1170: Loss = 0.8259, Acc = 74.76%, Spikes = 0.0389\n",
            "Epoch 4, Batch 1180: Loss = 1.0394, Acc = 74.76%, Spikes = 0.0426\n",
            "Epoch 4, Batch 1190: Loss = 0.9304, Acc = 74.78%, Spikes = 0.0424\n",
            "Epoch 4, Batch 1200: Loss = 1.0806, Acc = 74.75%, Spikes = 0.0382\n",
            "Epoch 4, Batch 1210: Loss = 0.8472, Acc = 74.76%, Spikes = 0.0409\n",
            "Epoch 4, Batch 1220: Loss = 0.9789, Acc = 74.80%, Spikes = 0.0480\n",
            "Epoch 4, Batch 1230: Loss = 0.6804, Acc = 74.79%, Spikes = 0.0437\n",
            "Epoch 4, Batch 1240: Loss = 1.0036, Acc = 74.81%, Spikes = 0.0401\n",
            "Epoch 4, Batch 1250: Loss = 0.7628, Acc = 74.80%, Spikes = 0.0440\n",
            "Epoch 4, Batch 1260: Loss = 0.9309, Acc = 74.80%, Spikes = 0.0391\n",
            "Epoch 4, Batch 1270: Loss = 0.9428, Acc = 74.80%, Spikes = 0.0484\n",
            "Epoch 4, Batch 1280: Loss = 1.2308, Acc = 74.81%, Spikes = 0.0403\n",
            "Epoch 4, Batch 1290: Loss = 0.8615, Acc = 74.83%, Spikes = 0.0433\n",
            "Epoch 4, Batch 1300: Loss = 0.7361, Acc = 74.83%, Spikes = 0.0458\n",
            "Epoch 4, Batch 1310: Loss = 0.8668, Acc = 74.84%, Spikes = 0.0470\n",
            "Epoch 4, Batch 1320: Loss = 0.6652, Acc = 74.86%, Spikes = 0.0461\n",
            "Epoch 4, Batch 1330: Loss = 0.7994, Acc = 74.85%, Spikes = 0.0446\n",
            "Epoch 4, Batch 1340: Loss = 0.8580, Acc = 74.83%, Spikes = 0.0453\n",
            "Epoch 4, Batch 1350: Loss = 0.9209, Acc = 74.80%, Spikes = 0.0424\n",
            "Epoch 4, Batch 1360: Loss = 0.7682, Acc = 74.80%, Spikes = 0.0472\n",
            "Epoch 4, Batch 1370: Loss = 0.8608, Acc = 74.79%, Spikes = 0.0450\n",
            "Epoch 4, Batch 1380: Loss = 0.9045, Acc = 74.77%, Spikes = 0.0418\n",
            "Epoch 4, Batch 1390: Loss = 0.9111, Acc = 74.78%, Spikes = 0.0411\n",
            "Epoch 4, Batch 1400: Loss = 0.9668, Acc = 74.77%, Spikes = 0.0462\n",
            "Epoch 4, Batch 1410: Loss = 1.1445, Acc = 74.75%, Spikes = 0.0397\n",
            "Epoch 4, Batch 1420: Loss = 0.6955, Acc = 74.77%, Spikes = 0.0473\n",
            "Epoch 4, Batch 1430: Loss = 0.7798, Acc = 74.77%, Spikes = 0.0459\n",
            "Epoch 4, Batch 1440: Loss = 1.0031, Acc = 74.80%, Spikes = 0.0435\n",
            "Epoch 4, Batch 1450: Loss = 0.7024, Acc = 74.80%, Spikes = 0.0459\n",
            "Epoch 4, Batch 1460: Loss = 0.7992, Acc = 74.80%, Spikes = 0.0394\n",
            "Epoch 4, Batch 1470: Loss = 1.0592, Acc = 74.81%, Spikes = 0.0367\n",
            "Epoch 4, Batch 1480: Loss = 0.8359, Acc = 74.84%, Spikes = 0.0427\n",
            "Epoch 4, Batch 1490: Loss = 0.9521, Acc = 74.85%, Spikes = 0.0437\n",
            "Epoch 4, Batch 1500: Loss = 0.8143, Acc = 74.87%, Spikes = 0.0467\n",
            "Epoch 4, Batch 1510: Loss = 0.8787, Acc = 74.88%, Spikes = 0.0412\n",
            "Epoch 4, Batch 1520: Loss = 0.8673, Acc = 74.91%, Spikes = 0.0459\n",
            "Epoch 4, Batch 1530: Loss = 0.5740, Acc = 74.92%, Spikes = 0.0460\n",
            "Epoch 4, Batch 1540: Loss = 0.7132, Acc = 74.92%, Spikes = 0.0468\n",
            "Epoch 4, Batch 1550: Loss = 0.7037, Acc = 74.94%, Spikes = 0.0470\n",
            "Epoch 4, Batch 1560: Loss = 0.8219, Acc = 74.97%, Spikes = 0.0441\n",
            "Epoch 4, Batch 1570: Loss = 0.6555, Acc = 74.96%, Spikes = 0.0466\n",
            "Epoch 4, Batch 1580: Loss = 0.5200, Acc = 74.98%, Spikes = 0.0500\n",
            "Epoch 4, Batch 1590: Loss = 0.7959, Acc = 74.99%, Spikes = 0.0419\n",
            "Epoch 4, Batch 1600: Loss = 0.8006, Acc = 74.98%, Spikes = 0.0443\n",
            "Epoch 4, Batch 1610: Loss = 0.8990, Acc = 74.98%, Spikes = 0.0437\n",
            "Epoch 4, Batch 1620: Loss = 0.6040, Acc = 74.99%, Spikes = 0.0522\n",
            "Epoch 4, Batch 1630: Loss = 0.7273, Acc = 74.99%, Spikes = 0.0434\n",
            "Epoch 4, Batch 1640: Loss = 0.9864, Acc = 74.99%, Spikes = 0.0392\n",
            "Epoch 4, Batch 1650: Loss = 0.8124, Acc = 75.01%, Spikes = 0.0525\n",
            "Epoch 4, Batch 1660: Loss = 0.7400, Acc = 75.05%, Spikes = 0.0363\n",
            "Epoch 4, Batch 1670: Loss = 0.9870, Acc = 75.07%, Spikes = 0.0429\n",
            "Epoch 4, Batch 1680: Loss = 0.7066, Acc = 75.12%, Spikes = 0.0444\n",
            "Epoch 4, Batch 1690: Loss = 0.6389, Acc = 75.11%, Spikes = 0.0456\n",
            "Epoch 4, Batch 1700: Loss = 1.0371, Acc = 75.12%, Spikes = 0.0409\n",
            "Epoch 4, Batch 1710: Loss = 1.0521, Acc = 75.11%, Spikes = 0.0454\n",
            "Epoch 4, Batch 1720: Loss = 0.7371, Acc = 75.12%, Spikes = 0.0429\n",
            "Epoch 4, Batch 1730: Loss = 0.8783, Acc = 75.11%, Spikes = 0.0438\n",
            "Epoch 4, Batch 1740: Loss = 0.8363, Acc = 75.12%, Spikes = 0.0395\n",
            "Epoch 4, Batch 1750: Loss = 0.9587, Acc = 75.15%, Spikes = 0.0465\n",
            "Epoch 4, Batch 1760: Loss = 0.7160, Acc = 75.13%, Spikes = 0.0476\n",
            "Epoch 4, Batch 1770: Loss = 0.6221, Acc = 75.13%, Spikes = 0.0445\n",
            "Epoch 4, Batch 1780: Loss = 0.9358, Acc = 75.12%, Spikes = 0.0377\n",
            "Epoch 4, Batch 1790: Loss = 0.7535, Acc = 75.12%, Spikes = 0.0441\n",
            "Epoch 4, Batch 1800: Loss = 0.8244, Acc = 75.16%, Spikes = 0.0433\n",
            "Epoch 4, Batch 1810: Loss = 0.8692, Acc = 75.18%, Spikes = 0.0390\n",
            "Epoch 4, Batch 1820: Loss = 0.9921, Acc = 75.18%, Spikes = 0.0466\n",
            "Epoch 4, Batch 1830: Loss = 0.8584, Acc = 75.18%, Spikes = 0.0459\n",
            "Epoch 4, Batch 1840: Loss = 0.8127, Acc = 75.18%, Spikes = 0.0460\n",
            "Epoch 4, Batch 1850: Loss = 0.7831, Acc = 75.17%, Spikes = 0.0457\n",
            "Epoch 4, Batch 1860: Loss = 0.6963, Acc = 75.17%, Spikes = 0.0430\n",
            "Epoch 4, Batch 1870: Loss = 1.1262, Acc = 75.15%, Spikes = 0.0408\n",
            "Epoch 4/15:\n",
            "Train Loss: 0.8768 | Train Acc: 75.15% | Train Spikes: 0.0422\n",
            "Test Acc: 76.42% | Test Spikes: 0.0454\n",
            "------------------------------------------------------------\n",
            "Epoch 5, Batch 0: Loss = 0.8202, Acc = 68.75%, Spikes = 0.0437\n",
            "Epoch 5, Batch 10: Loss = 0.8088, Acc = 74.43%, Spikes = 0.0434\n",
            "Epoch 5, Batch 20: Loss = 0.7327, Acc = 75.60%, Spikes = 0.0419\n",
            "Epoch 5, Batch 30: Loss = 0.6806, Acc = 76.61%, Spikes = 0.0436\n",
            "Epoch 5, Batch 40: Loss = 0.7357, Acc = 76.45%, Spikes = 0.0442\n",
            "Epoch 5, Batch 50: Loss = 0.7059, Acc = 75.98%, Spikes = 0.0384\n",
            "Epoch 5, Batch 60: Loss = 0.5913, Acc = 75.87%, Spikes = 0.0483\n",
            "Epoch 5, Batch 70: Loss = 0.6449, Acc = 75.75%, Spikes = 0.0482\n",
            "Epoch 5, Batch 80: Loss = 1.0481, Acc = 75.31%, Spikes = 0.0406\n",
            "Epoch 5, Batch 90: Loss = 0.8704, Acc = 75.27%, Spikes = 0.0466\n",
            "Epoch 5, Batch 100: Loss = 0.7492, Acc = 75.53%, Spikes = 0.0535\n",
            "Epoch 5, Batch 110: Loss = 0.8605, Acc = 75.51%, Spikes = 0.0435\n",
            "Epoch 5, Batch 120: Loss = 0.7212, Acc = 75.72%, Spikes = 0.0438\n",
            "Epoch 5, Batch 130: Loss = 0.9981, Acc = 75.50%, Spikes = 0.0431\n",
            "Epoch 5, Batch 140: Loss = 0.8396, Acc = 75.42%, Spikes = 0.0479\n",
            "Epoch 5, Batch 150: Loss = 0.7095, Acc = 75.52%, Spikes = 0.0474\n",
            "Epoch 5, Batch 160: Loss = 0.7387, Acc = 75.64%, Spikes = 0.0467\n",
            "Epoch 5, Batch 170: Loss = 0.9987, Acc = 75.44%, Spikes = 0.0483\n",
            "Epoch 5, Batch 180: Loss = 0.6369, Acc = 75.60%, Spikes = 0.0468\n",
            "Epoch 5, Batch 190: Loss = 0.7513, Acc = 75.51%, Spikes = 0.0494\n",
            "Epoch 5, Batch 200: Loss = 0.7424, Acc = 75.39%, Spikes = 0.0473\n",
            "Epoch 5, Batch 210: Loss = 0.8219, Acc = 75.49%, Spikes = 0.0444\n",
            "Epoch 5, Batch 220: Loss = 0.6714, Acc = 75.57%, Spikes = 0.0452\n",
            "Epoch 5, Batch 230: Loss = 0.7356, Acc = 75.41%, Spikes = 0.0464\n",
            "Epoch 5, Batch 240: Loss = 1.1422, Acc = 75.45%, Spikes = 0.0412\n",
            "Epoch 5, Batch 250: Loss = 0.8536, Acc = 75.45%, Spikes = 0.0423\n",
            "Epoch 5, Batch 260: Loss = 0.7880, Acc = 75.55%, Spikes = 0.0426\n",
            "Epoch 5, Batch 270: Loss = 0.7677, Acc = 75.63%, Spikes = 0.0459\n",
            "Epoch 5, Batch 280: Loss = 0.9259, Acc = 75.62%, Spikes = 0.0455\n",
            "Epoch 5, Batch 290: Loss = 0.7897, Acc = 75.53%, Spikes = 0.0485\n",
            "Epoch 5, Batch 300: Loss = 0.7373, Acc = 75.58%, Spikes = 0.0429\n",
            "Epoch 5, Batch 310: Loss = 0.9135, Acc = 75.51%, Spikes = 0.0418\n",
            "Epoch 5, Batch 320: Loss = 1.2530, Acc = 75.49%, Spikes = 0.0471\n",
            "Epoch 5, Batch 330: Loss = 1.0628, Acc = 75.57%, Spikes = 0.0458\n",
            "Epoch 5, Batch 340: Loss = 0.8892, Acc = 75.56%, Spikes = 0.0466\n",
            "Epoch 5, Batch 350: Loss = 1.0644, Acc = 75.69%, Spikes = 0.0429\n",
            "Epoch 5, Batch 360: Loss = 0.7449, Acc = 75.61%, Spikes = 0.0462\n",
            "Epoch 5, Batch 370: Loss = 0.8284, Acc = 75.55%, Spikes = 0.0482\n",
            "Epoch 5, Batch 380: Loss = 0.9462, Acc = 75.63%, Spikes = 0.0395\n",
            "Epoch 5, Batch 390: Loss = 0.6311, Acc = 75.67%, Spikes = 0.0503\n",
            "Epoch 5, Batch 400: Loss = 0.5695, Acc = 75.74%, Spikes = 0.0473\n",
            "Epoch 5, Batch 410: Loss = 0.9351, Acc = 75.77%, Spikes = 0.0449\n",
            "Epoch 5, Batch 420: Loss = 0.4628, Acc = 75.79%, Spikes = 0.0492\n",
            "Epoch 5, Batch 430: Loss = 0.6197, Acc = 75.78%, Spikes = 0.0508\n",
            "Epoch 5, Batch 440: Loss = 0.7189, Acc = 75.88%, Spikes = 0.0503\n",
            "Epoch 5, Batch 450: Loss = 0.7982, Acc = 75.94%, Spikes = 0.0452\n",
            "Epoch 5, Batch 460: Loss = 0.7620, Acc = 75.85%, Spikes = 0.0434\n",
            "Epoch 5, Batch 470: Loss = 0.8367, Acc = 75.89%, Spikes = 0.0470\n",
            "Epoch 5, Batch 480: Loss = 0.8115, Acc = 75.97%, Spikes = 0.0465\n",
            "Epoch 5, Batch 490: Loss = 0.6458, Acc = 76.02%, Spikes = 0.0472\n",
            "Epoch 5, Batch 500: Loss = 0.7770, Acc = 76.04%, Spikes = 0.0487\n",
            "Epoch 5, Batch 510: Loss = 0.8654, Acc = 76.05%, Spikes = 0.0451\n",
            "Epoch 5, Batch 520: Loss = 0.8561, Acc = 76.07%, Spikes = 0.0417\n",
            "Epoch 5, Batch 530: Loss = 0.8263, Acc = 76.02%, Spikes = 0.0477\n",
            "Epoch 5, Batch 540: Loss = 0.9474, Acc = 76.02%, Spikes = 0.0420\n",
            "Epoch 5, Batch 550: Loss = 0.9063, Acc = 76.03%, Spikes = 0.0439\n",
            "Epoch 5, Batch 560: Loss = 1.0269, Acc = 75.99%, Spikes = 0.0436\n",
            "Epoch 5, Batch 570: Loss = 0.5789, Acc = 76.01%, Spikes = 0.0480\n",
            "Epoch 5, Batch 580: Loss = 0.5691, Acc = 76.00%, Spikes = 0.0496\n",
            "Epoch 5, Batch 590: Loss = 0.7082, Acc = 75.96%, Spikes = 0.0441\n",
            "Epoch 5, Batch 600: Loss = 0.6948, Acc = 76.02%, Spikes = 0.0437\n",
            "Epoch 5, Batch 610: Loss = 0.6344, Acc = 75.96%, Spikes = 0.0470\n",
            "Epoch 5, Batch 620: Loss = 1.0350, Acc = 75.92%, Spikes = 0.0436\n",
            "Epoch 5, Batch 630: Loss = 0.6151, Acc = 75.88%, Spikes = 0.0499\n",
            "Epoch 5, Batch 640: Loss = 0.7748, Acc = 75.91%, Spikes = 0.0502\n",
            "Epoch 5, Batch 650: Loss = 0.6880, Acc = 75.94%, Spikes = 0.0469\n",
            "Epoch 5, Batch 660: Loss = 0.9930, Acc = 75.93%, Spikes = 0.0454\n",
            "Epoch 5, Batch 670: Loss = 0.5742, Acc = 75.92%, Spikes = 0.0491\n",
            "Epoch 5, Batch 680: Loss = 0.6368, Acc = 75.94%, Spikes = 0.0497\n",
            "Epoch 5, Batch 690: Loss = 0.9470, Acc = 75.89%, Spikes = 0.0430\n",
            "Epoch 5, Batch 700: Loss = 0.9369, Acc = 75.88%, Spikes = 0.0462\n",
            "Epoch 5, Batch 710: Loss = 0.8449, Acc = 75.86%, Spikes = 0.0453\n",
            "Epoch 5, Batch 720: Loss = 0.6532, Acc = 75.91%, Spikes = 0.0442\n",
            "Epoch 5, Batch 730: Loss = 0.6482, Acc = 75.95%, Spikes = 0.0499\n",
            "Epoch 5, Batch 740: Loss = 1.0137, Acc = 75.94%, Spikes = 0.0422\n",
            "Epoch 5, Batch 750: Loss = 0.4618, Acc = 75.95%, Spikes = 0.0499\n",
            "Epoch 5, Batch 760: Loss = 1.0300, Acc = 75.94%, Spikes = 0.0397\n",
            "Epoch 5, Batch 770: Loss = 1.0655, Acc = 75.93%, Spikes = 0.0421\n",
            "Epoch 5, Batch 780: Loss = 0.9227, Acc = 75.88%, Spikes = 0.0415\n",
            "Epoch 5, Batch 790: Loss = 0.6326, Acc = 75.92%, Spikes = 0.0456\n",
            "Epoch 5, Batch 800: Loss = 0.8704, Acc = 75.97%, Spikes = 0.0400\n",
            "Epoch 5, Batch 810: Loss = 0.7828, Acc = 76.02%, Spikes = 0.0477\n",
            "Epoch 5, Batch 820: Loss = 0.8508, Acc = 76.02%, Spikes = 0.0477\n",
            "Epoch 5, Batch 830: Loss = 1.0832, Acc = 75.97%, Spikes = 0.0413\n",
            "Epoch 5, Batch 840: Loss = 0.8334, Acc = 76.01%, Spikes = 0.0471\n",
            "Epoch 5, Batch 850: Loss = 0.7883, Acc = 76.03%, Spikes = 0.0489\n",
            "Epoch 5, Batch 860: Loss = 0.8055, Acc = 76.10%, Spikes = 0.0518\n",
            "Epoch 5, Batch 870: Loss = 0.8544, Acc = 76.12%, Spikes = 0.0482\n",
            "Epoch 5, Batch 880: Loss = 0.6980, Acc = 76.16%, Spikes = 0.0445\n",
            "Epoch 5, Batch 890: Loss = 0.8721, Acc = 76.17%, Spikes = 0.0478\n",
            "Epoch 5, Batch 900: Loss = 1.0677, Acc = 76.18%, Spikes = 0.0400\n",
            "Epoch 5, Batch 910: Loss = 1.0720, Acc = 76.17%, Spikes = 0.0389\n",
            "Epoch 5, Batch 920: Loss = 0.8403, Acc = 76.17%, Spikes = 0.0491\n",
            "Epoch 5, Batch 930: Loss = 1.2233, Acc = 76.13%, Spikes = 0.0412\n",
            "Epoch 5, Batch 940: Loss = 0.7872, Acc = 76.14%, Spikes = 0.0470\n",
            "Epoch 5, Batch 950: Loss = 0.7409, Acc = 76.17%, Spikes = 0.0479\n",
            "Epoch 5, Batch 960: Loss = 0.8789, Acc = 76.15%, Spikes = 0.0499\n",
            "Epoch 5, Batch 970: Loss = 0.8782, Acc = 76.14%, Spikes = 0.0499\n",
            "Epoch 5, Batch 980: Loss = 0.7071, Acc = 76.14%, Spikes = 0.0449\n",
            "Epoch 5, Batch 990: Loss = 0.5053, Acc = 76.15%, Spikes = 0.0486\n",
            "Epoch 5, Batch 1000: Loss = 0.5282, Acc = 76.15%, Spikes = 0.0473\n",
            "Epoch 5, Batch 1010: Loss = 0.8190, Acc = 76.17%, Spikes = 0.0509\n",
            "Epoch 5, Batch 1020: Loss = 0.5813, Acc = 76.18%, Spikes = 0.0455\n",
            "Epoch 5, Batch 1030: Loss = 0.7781, Acc = 76.20%, Spikes = 0.0468\n",
            "Epoch 5, Batch 1040: Loss = 0.8267, Acc = 76.21%, Spikes = 0.0484\n",
            "Epoch 5, Batch 1050: Loss = 0.7289, Acc = 76.21%, Spikes = 0.0492\n",
            "Epoch 5, Batch 1060: Loss = 0.5224, Acc = 76.20%, Spikes = 0.0484\n",
            "Epoch 5, Batch 1070: Loss = 0.4974, Acc = 76.22%, Spikes = 0.0486\n",
            "Epoch 5, Batch 1080: Loss = 1.0571, Acc = 76.23%, Spikes = 0.0467\n",
            "Epoch 5, Batch 1090: Loss = 0.7014, Acc = 76.22%, Spikes = 0.0441\n",
            "Epoch 5, Batch 1100: Loss = 0.9413, Acc = 76.16%, Spikes = 0.0403\n",
            "Epoch 5, Batch 1110: Loss = 0.8351, Acc = 76.11%, Spikes = 0.0468\n",
            "Epoch 5, Batch 1120: Loss = 0.9394, Acc = 76.13%, Spikes = 0.0438\n",
            "Epoch 5, Batch 1130: Loss = 0.6714, Acc = 76.10%, Spikes = 0.0530\n",
            "Epoch 5, Batch 1140: Loss = 0.5897, Acc = 76.11%, Spikes = 0.0527\n",
            "Epoch 5, Batch 1150: Loss = 0.5846, Acc = 76.12%, Spikes = 0.0493\n",
            "Epoch 5, Batch 1160: Loss = 0.7854, Acc = 76.14%, Spikes = 0.0445\n",
            "Epoch 5, Batch 1170: Loss = 0.7662, Acc = 76.17%, Spikes = 0.0497\n",
            "Epoch 5, Batch 1180: Loss = 0.6620, Acc = 76.19%, Spikes = 0.0497\n",
            "Epoch 5, Batch 1190: Loss = 0.8611, Acc = 76.21%, Spikes = 0.0454\n",
            "Epoch 5, Batch 1200: Loss = 0.8138, Acc = 76.23%, Spikes = 0.0523\n",
            "Epoch 5, Batch 1210: Loss = 0.4377, Acc = 76.25%, Spikes = 0.0504\n",
            "Epoch 5, Batch 1220: Loss = 0.5773, Acc = 76.23%, Spikes = 0.0530\n",
            "Epoch 5, Batch 1230: Loss = 0.9723, Acc = 76.24%, Spikes = 0.0455\n",
            "Epoch 5, Batch 1240: Loss = 0.7957, Acc = 76.27%, Spikes = 0.0527\n",
            "Epoch 5, Batch 1250: Loss = 0.9647, Acc = 76.24%, Spikes = 0.0486\n",
            "Epoch 5, Batch 1260: Loss = 0.6817, Acc = 76.26%, Spikes = 0.0484\n",
            "Epoch 5, Batch 1270: Loss = 0.8711, Acc = 76.27%, Spikes = 0.0460\n",
            "Epoch 5, Batch 1280: Loss = 0.7637, Acc = 76.29%, Spikes = 0.0485\n",
            "Epoch 5, Batch 1290: Loss = 0.7060, Acc = 76.30%, Spikes = 0.0516\n",
            "Epoch 5, Batch 1300: Loss = 0.4840, Acc = 76.30%, Spikes = 0.0522\n",
            "Epoch 5, Batch 1310: Loss = 0.8727, Acc = 76.32%, Spikes = 0.0492\n",
            "Epoch 5, Batch 1320: Loss = 0.6213, Acc = 76.34%, Spikes = 0.0531\n",
            "Epoch 5, Batch 1330: Loss = 0.8676, Acc = 76.35%, Spikes = 0.0506\n",
            "Epoch 5, Batch 1340: Loss = 0.6873, Acc = 76.39%, Spikes = 0.0494\n",
            "Epoch 5, Batch 1350: Loss = 0.6854, Acc = 76.38%, Spikes = 0.0471\n",
            "Epoch 5, Batch 1360: Loss = 0.6433, Acc = 76.38%, Spikes = 0.0450\n",
            "Epoch 5, Batch 1370: Loss = 0.6029, Acc = 76.39%, Spikes = 0.0476\n",
            "Epoch 5, Batch 1380: Loss = 0.5929, Acc = 76.39%, Spikes = 0.0549\n",
            "Epoch 5, Batch 1390: Loss = 0.7201, Acc = 76.43%, Spikes = 0.0493\n",
            "Epoch 5, Batch 1400: Loss = 0.8100, Acc = 76.45%, Spikes = 0.0445\n",
            "Epoch 5, Batch 1410: Loss = 0.6332, Acc = 76.44%, Spikes = 0.0500\n",
            "Epoch 5, Batch 1420: Loss = 0.9600, Acc = 76.42%, Spikes = 0.0424\n",
            "Epoch 5, Batch 1430: Loss = 0.5858, Acc = 76.44%, Spikes = 0.0554\n",
            "Epoch 5, Batch 1440: Loss = 0.8511, Acc = 76.45%, Spikes = 0.0457\n",
            "Epoch 5, Batch 1450: Loss = 0.6800, Acc = 76.44%, Spikes = 0.0495\n",
            "Epoch 5, Batch 1460: Loss = 0.4176, Acc = 76.45%, Spikes = 0.0556\n",
            "Epoch 5, Batch 1470: Loss = 0.8414, Acc = 76.46%, Spikes = 0.0445\n",
            "Epoch 5, Batch 1480: Loss = 0.6348, Acc = 76.48%, Spikes = 0.0476\n",
            "Epoch 5, Batch 1490: Loss = 0.4730, Acc = 76.49%, Spikes = 0.0531\n",
            "Epoch 5, Batch 1500: Loss = 0.8357, Acc = 76.51%, Spikes = 0.0492\n",
            "Epoch 5, Batch 1510: Loss = 0.8784, Acc = 76.49%, Spikes = 0.0450\n",
            "Epoch 5, Batch 1520: Loss = 0.6956, Acc = 76.50%, Spikes = 0.0490\n",
            "Epoch 5, Batch 1530: Loss = 0.6722, Acc = 76.50%, Spikes = 0.0454\n",
            "Epoch 5, Batch 1540: Loss = 0.7826, Acc = 76.47%, Spikes = 0.0494\n",
            "Epoch 5, Batch 1550: Loss = 0.7042, Acc = 76.43%, Spikes = 0.0513\n",
            "Epoch 5, Batch 1560: Loss = 0.7283, Acc = 76.45%, Spikes = 0.0464\n",
            "Epoch 5, Batch 1570: Loss = 0.4679, Acc = 76.48%, Spikes = 0.0508\n",
            "Epoch 5, Batch 1580: Loss = 0.7206, Acc = 76.50%, Spikes = 0.0525\n",
            "Epoch 5, Batch 1590: Loss = 0.9154, Acc = 76.49%, Spikes = 0.0470\n",
            "Epoch 5, Batch 1600: Loss = 0.6816, Acc = 76.53%, Spikes = 0.0513\n",
            "Epoch 5, Batch 1610: Loss = 0.5688, Acc = 76.56%, Spikes = 0.0494\n",
            "Epoch 5, Batch 1620: Loss = 0.5881, Acc = 76.56%, Spikes = 0.0465\n",
            "Epoch 5, Batch 1630: Loss = 0.7580, Acc = 76.54%, Spikes = 0.0467\n",
            "Epoch 5, Batch 1640: Loss = 0.7905, Acc = 76.52%, Spikes = 0.0473\n",
            "Epoch 5, Batch 1650: Loss = 0.7102, Acc = 76.52%, Spikes = 0.0467\n",
            "Epoch 5, Batch 1660: Loss = 0.6763, Acc = 76.52%, Spikes = 0.0510\n",
            "Epoch 5, Batch 1670: Loss = 0.5463, Acc = 76.53%, Spikes = 0.0505\n",
            "Epoch 5, Batch 1680: Loss = 0.7047, Acc = 76.55%, Spikes = 0.0471\n",
            "Epoch 5, Batch 1690: Loss = 0.8917, Acc = 76.56%, Spikes = 0.0474\n",
            "Epoch 5, Batch 1700: Loss = 0.6150, Acc = 76.57%, Spikes = 0.0507\n",
            "Epoch 5, Batch 1710: Loss = 0.6545, Acc = 76.58%, Spikes = 0.0542\n",
            "Epoch 5, Batch 1720: Loss = 0.8954, Acc = 76.60%, Spikes = 0.0550\n",
            "Epoch 5, Batch 1730: Loss = 0.7394, Acc = 76.62%, Spikes = 0.0494\n",
            "Epoch 5, Batch 1740: Loss = 0.6984, Acc = 76.59%, Spikes = 0.0509\n",
            "Epoch 5, Batch 1750: Loss = 0.6610, Acc = 76.59%, Spikes = 0.0472\n",
            "Epoch 5, Batch 1760: Loss = 0.6690, Acc = 76.57%, Spikes = 0.0503\n",
            "Epoch 5, Batch 1770: Loss = 0.7115, Acc = 76.58%, Spikes = 0.0507\n",
            "Epoch 5, Batch 1780: Loss = 0.6919, Acc = 76.60%, Spikes = 0.0495\n",
            "Epoch 5, Batch 1790: Loss = 0.6860, Acc = 76.61%, Spikes = 0.0501\n",
            "Epoch 5, Batch 1800: Loss = 0.7540, Acc = 76.60%, Spikes = 0.0489\n",
            "Epoch 5, Batch 1810: Loss = 0.6892, Acc = 76.61%, Spikes = 0.0441\n",
            "Epoch 5, Batch 1820: Loss = 0.8525, Acc = 76.59%, Spikes = 0.0486\n",
            "Epoch 5, Batch 1830: Loss = 0.9642, Acc = 76.58%, Spikes = 0.0420\n",
            "Epoch 5, Batch 1840: Loss = 0.6352, Acc = 76.58%, Spikes = 0.0473\n",
            "Epoch 5, Batch 1850: Loss = 0.6616, Acc = 76.58%, Spikes = 0.0539\n",
            "Epoch 5, Batch 1860: Loss = 0.7285, Acc = 76.58%, Spikes = 0.0512\n",
            "Epoch 5, Batch 1870: Loss = 0.5980, Acc = 76.58%, Spikes = 0.0464\n",
            "Epoch 5/15:\n",
            "Train Loss: 0.7769 | Train Acc: 76.57% | Train Spikes: 0.0475\n",
            "Test Acc: 78.00% | Test Spikes: 0.0516\n",
            "------------------------------------------------------------\n",
            "Epoch 6, Batch 0: Loss = 0.8783, Acc = 81.25%, Spikes = 0.0567\n",
            "Epoch 6, Batch 10: Loss = 0.8219, Acc = 79.55%, Spikes = 0.0464\n",
            "Epoch 6, Batch 20: Loss = 0.7113, Acc = 80.21%, Spikes = 0.0484\n",
            "Epoch 6, Batch 30: Loss = 0.7057, Acc = 78.12%, Spikes = 0.0499\n",
            "Epoch 6, Batch 40: Loss = 0.8557, Acc = 78.43%, Spikes = 0.0429\n",
            "Epoch 6, Batch 50: Loss = 0.7394, Acc = 78.43%, Spikes = 0.0511\n",
            "Epoch 6, Batch 60: Loss = 0.6330, Acc = 78.33%, Spikes = 0.0550\n",
            "Epoch 6, Batch 70: Loss = 0.5925, Acc = 77.95%, Spikes = 0.0531\n",
            "Epoch 6, Batch 80: Loss = 0.6667, Acc = 77.70%, Spikes = 0.0490\n",
            "Epoch 6, Batch 90: Loss = 0.6857, Acc = 77.54%, Spikes = 0.0506\n",
            "Epoch 6, Batch 100: Loss = 0.6152, Acc = 77.57%, Spikes = 0.0512\n",
            "Epoch 6, Batch 110: Loss = 1.0118, Acc = 77.48%, Spikes = 0.0571\n",
            "Epoch 6, Batch 120: Loss = 0.6746, Acc = 77.53%, Spikes = 0.0485\n",
            "Epoch 6, Batch 130: Loss = 0.4026, Acc = 77.17%, Spikes = 0.0575\n",
            "Epoch 6, Batch 140: Loss = 0.7832, Acc = 77.11%, Spikes = 0.0504\n",
            "Epoch 6, Batch 150: Loss = 0.7651, Acc = 76.88%, Spikes = 0.0505\n",
            "Epoch 6, Batch 160: Loss = 0.6599, Acc = 76.79%, Spikes = 0.0522\n",
            "Epoch 6, Batch 170: Loss = 0.9371, Acc = 76.70%, Spikes = 0.0478\n",
            "Epoch 6, Batch 180: Loss = 0.7510, Acc = 76.66%, Spikes = 0.0523\n",
            "Epoch 6, Batch 190: Loss = 0.6626, Acc = 76.64%, Spikes = 0.0458\n",
            "Epoch 6, Batch 200: Loss = 0.7822, Acc = 76.57%, Spikes = 0.0514\n",
            "Epoch 6, Batch 210: Loss = 0.4801, Acc = 76.84%, Spikes = 0.0526\n",
            "Epoch 6, Batch 220: Loss = 0.9725, Acc = 76.95%, Spikes = 0.0483\n",
            "Epoch 6, Batch 230: Loss = 0.8076, Acc = 76.93%, Spikes = 0.0505\n",
            "Epoch 6, Batch 240: Loss = 0.8622, Acc = 76.97%, Spikes = 0.0485\n",
            "Epoch 6, Batch 250: Loss = 0.9195, Acc = 77.04%, Spikes = 0.0458\n",
            "Epoch 6, Batch 260: Loss = 0.8088, Acc = 77.01%, Spikes = 0.0472\n",
            "Epoch 6, Batch 270: Loss = 0.5808, Acc = 76.94%, Spikes = 0.0484\n",
            "Epoch 6, Batch 280: Loss = 0.9264, Acc = 76.97%, Spikes = 0.0505\n",
            "Epoch 6, Batch 290: Loss = 0.8455, Acc = 77.06%, Spikes = 0.0489\n",
            "Epoch 6, Batch 300: Loss = 0.5388, Acc = 76.97%, Spikes = 0.0537\n",
            "Epoch 6, Batch 310: Loss = 0.9213, Acc = 77.03%, Spikes = 0.0473\n",
            "Epoch 6, Batch 320: Loss = 0.7067, Acc = 76.93%, Spikes = 0.0513\n",
            "Epoch 6, Batch 330: Loss = 0.6899, Acc = 76.92%, Spikes = 0.0499\n",
            "Epoch 6, Batch 340: Loss = 0.9404, Acc = 76.90%, Spikes = 0.0474\n",
            "Epoch 6, Batch 350: Loss = 0.6815, Acc = 76.92%, Spikes = 0.0479\n",
            "Epoch 6, Batch 360: Loss = 0.6378, Acc = 77.01%, Spikes = 0.0517\n",
            "Epoch 6, Batch 370: Loss = 0.6217, Acc = 76.99%, Spikes = 0.0509\n",
            "Epoch 6, Batch 380: Loss = 0.6847, Acc = 77.01%, Spikes = 0.0480\n",
            "Epoch 6, Batch 390: Loss = 0.5841, Acc = 77.06%, Spikes = 0.0489\n",
            "Epoch 6, Batch 400: Loss = 0.8216, Acc = 76.97%, Spikes = 0.0514\n",
            "Epoch 6, Batch 410: Loss = 0.7919, Acc = 76.94%, Spikes = 0.0531\n",
            "Epoch 6, Batch 420: Loss = 1.0061, Acc = 76.94%, Spikes = 0.0523\n",
            "Epoch 6, Batch 430: Loss = 1.2112, Acc = 76.91%, Spikes = 0.0521\n",
            "Epoch 6, Batch 440: Loss = 0.7335, Acc = 76.88%, Spikes = 0.0542\n",
            "Epoch 6, Batch 450: Loss = 0.7136, Acc = 76.99%, Spikes = 0.0543\n",
            "Epoch 6, Batch 460: Loss = 0.6308, Acc = 77.08%, Spikes = 0.0560\n",
            "Epoch 6, Batch 470: Loss = 0.8169, Acc = 77.10%, Spikes = 0.0500\n",
            "Epoch 6, Batch 480: Loss = 0.5889, Acc = 77.14%, Spikes = 0.0526\n",
            "Epoch 6, Batch 490: Loss = 0.6011, Acc = 77.13%, Spikes = 0.0555\n",
            "Epoch 6, Batch 500: Loss = 1.1626, Acc = 77.08%, Spikes = 0.0504\n",
            "Epoch 6, Batch 510: Loss = 0.6447, Acc = 77.13%, Spikes = 0.0515\n",
            "Epoch 6, Batch 520: Loss = 0.6304, Acc = 77.24%, Spikes = 0.0558\n",
            "Epoch 6, Batch 530: Loss = 0.7818, Acc = 77.21%, Spikes = 0.0505\n",
            "Epoch 6, Batch 540: Loss = 0.8398, Acc = 77.19%, Spikes = 0.0512\n",
            "Epoch 6, Batch 550: Loss = 0.6898, Acc = 77.21%, Spikes = 0.0531\n",
            "Epoch 6, Batch 560: Loss = 0.8917, Acc = 77.18%, Spikes = 0.0479\n",
            "Epoch 6, Batch 570: Loss = 0.9264, Acc = 77.19%, Spikes = 0.0534\n",
            "Epoch 6, Batch 580: Loss = 0.7784, Acc = 77.28%, Spikes = 0.0484\n",
            "Epoch 6, Batch 590: Loss = 0.7984, Acc = 77.26%, Spikes = 0.0476\n",
            "Epoch 6, Batch 600: Loss = 0.7060, Acc = 77.23%, Spikes = 0.0493\n",
            "Epoch 6, Batch 610: Loss = 0.8416, Acc = 77.27%, Spikes = 0.0537\n",
            "Epoch 6, Batch 620: Loss = 0.7628, Acc = 77.23%, Spikes = 0.0531\n",
            "Epoch 6, Batch 630: Loss = 0.6679, Acc = 77.22%, Spikes = 0.0467\n",
            "Epoch 6, Batch 640: Loss = 0.6766, Acc = 77.28%, Spikes = 0.0492\n",
            "Epoch 6, Batch 650: Loss = 0.7967, Acc = 77.30%, Spikes = 0.0495\n",
            "Epoch 6, Batch 660: Loss = 0.7046, Acc = 77.27%, Spikes = 0.0589\n",
            "Epoch 6, Batch 670: Loss = 1.2524, Acc = 77.33%, Spikes = 0.0483\n",
            "Epoch 6, Batch 680: Loss = 0.7878, Acc = 77.34%, Spikes = 0.0548\n",
            "Epoch 6, Batch 690: Loss = 0.9997, Acc = 77.29%, Spikes = 0.0526\n",
            "Epoch 6, Batch 700: Loss = 0.6787, Acc = 77.34%, Spikes = 0.0585\n",
            "Epoch 6, Batch 710: Loss = 0.8577, Acc = 77.32%, Spikes = 0.0546\n",
            "Epoch 6, Batch 720: Loss = 0.4843, Acc = 77.34%, Spikes = 0.0551\n",
            "Epoch 6, Batch 730: Loss = 0.6156, Acc = 77.33%, Spikes = 0.0472\n",
            "Epoch 6, Batch 740: Loss = 0.5654, Acc = 77.33%, Spikes = 0.0543\n",
            "Epoch 6, Batch 750: Loss = 0.4121, Acc = 77.32%, Spikes = 0.0536\n",
            "Epoch 6, Batch 760: Loss = 0.4510, Acc = 77.27%, Spikes = 0.0561\n",
            "Epoch 6, Batch 770: Loss = 0.6113, Acc = 77.26%, Spikes = 0.0547\n",
            "Epoch 6, Batch 780: Loss = 0.9166, Acc = 77.29%, Spikes = 0.0546\n",
            "Epoch 6, Batch 790: Loss = 0.6820, Acc = 77.30%, Spikes = 0.0503\n",
            "Epoch 6, Batch 800: Loss = 1.0590, Acc = 77.34%, Spikes = 0.0478\n",
            "Epoch 6, Batch 810: Loss = 0.7556, Acc = 77.36%, Spikes = 0.0521\n",
            "Epoch 6, Batch 820: Loss = 1.0555, Acc = 77.38%, Spikes = 0.0499\n",
            "Epoch 6, Batch 830: Loss = 0.6151, Acc = 77.37%, Spikes = 0.0519\n",
            "Epoch 6, Batch 840: Loss = 0.7940, Acc = 77.33%, Spikes = 0.0501\n",
            "Epoch 6, Batch 850: Loss = 0.8797, Acc = 77.34%, Spikes = 0.0515\n",
            "Epoch 6, Batch 860: Loss = 0.6100, Acc = 77.38%, Spikes = 0.0517\n",
            "Epoch 6, Batch 870: Loss = 0.5855, Acc = 77.34%, Spikes = 0.0545\n",
            "Epoch 6, Batch 880: Loss = 0.8866, Acc = 77.34%, Spikes = 0.0484\n",
            "Epoch 6, Batch 890: Loss = 0.8400, Acc = 77.35%, Spikes = 0.0491\n",
            "Epoch 6, Batch 900: Loss = 0.9547, Acc = 77.36%, Spikes = 0.0497\n",
            "Epoch 6, Batch 910: Loss = 0.5142, Acc = 77.35%, Spikes = 0.0549\n",
            "Epoch 6, Batch 920: Loss = 0.6034, Acc = 77.39%, Spikes = 0.0494\n",
            "Epoch 6, Batch 930: Loss = 0.5088, Acc = 77.37%, Spikes = 0.0604\n",
            "Epoch 6, Batch 940: Loss = 0.7210, Acc = 77.38%, Spikes = 0.0546\n",
            "Epoch 6, Batch 950: Loss = 0.6370, Acc = 77.40%, Spikes = 0.0528\n",
            "Epoch 6, Batch 960: Loss = 0.6830, Acc = 77.38%, Spikes = 0.0531\n",
            "Epoch 6, Batch 970: Loss = 0.6486, Acc = 77.41%, Spikes = 0.0478\n",
            "Epoch 6, Batch 980: Loss = 0.8031, Acc = 77.41%, Spikes = 0.0496\n",
            "Epoch 6, Batch 990: Loss = 0.4621, Acc = 77.44%, Spikes = 0.0546\n",
            "Epoch 6, Batch 1000: Loss = 0.7481, Acc = 77.48%, Spikes = 0.0517\n",
            "Epoch 6, Batch 1010: Loss = 0.4794, Acc = 77.49%, Spikes = 0.0514\n",
            "Epoch 6, Batch 1020: Loss = 0.4913, Acc = 77.48%, Spikes = 0.0549\n",
            "Epoch 6, Batch 1030: Loss = 0.5298, Acc = 77.54%, Spikes = 0.0548\n",
            "Epoch 6, Batch 1040: Loss = 0.7667, Acc = 77.55%, Spikes = 0.0541\n",
            "Epoch 6, Batch 1050: Loss = 0.6452, Acc = 77.57%, Spikes = 0.0527\n",
            "Epoch 6, Batch 1060: Loss = 0.5014, Acc = 77.58%, Spikes = 0.0560\n",
            "Epoch 6, Batch 1070: Loss = 0.5420, Acc = 77.54%, Spikes = 0.0567\n",
            "Epoch 6, Batch 1080: Loss = 0.8042, Acc = 77.58%, Spikes = 0.0596\n",
            "Epoch 6, Batch 1090: Loss = 0.6181, Acc = 77.58%, Spikes = 0.0579\n",
            "Epoch 6, Batch 1100: Loss = 0.5900, Acc = 77.61%, Spikes = 0.0542\n",
            "Epoch 6, Batch 1110: Loss = 0.6116, Acc = 77.62%, Spikes = 0.0589\n",
            "Epoch 6, Batch 1120: Loss = 0.7447, Acc = 77.64%, Spikes = 0.0505\n",
            "Epoch 6, Batch 1130: Loss = 0.5146, Acc = 77.65%, Spikes = 0.0582\n",
            "Epoch 6, Batch 1140: Loss = 0.7888, Acc = 77.64%, Spikes = 0.0515\n",
            "Epoch 6, Batch 1150: Loss = 0.8759, Acc = 77.61%, Spikes = 0.0574\n",
            "Epoch 6, Batch 1160: Loss = 0.7243, Acc = 77.64%, Spikes = 0.0531\n",
            "Epoch 6, Batch 1170: Loss = 0.6372, Acc = 77.65%, Spikes = 0.0590\n",
            "Epoch 6, Batch 1180: Loss = 0.8455, Acc = 77.66%, Spikes = 0.0537\n",
            "Epoch 6, Batch 1190: Loss = 0.5560, Acc = 77.67%, Spikes = 0.0548\n",
            "Epoch 6, Batch 1200: Loss = 0.5545, Acc = 77.70%, Spikes = 0.0566\n",
            "Epoch 6, Batch 1210: Loss = 0.8064, Acc = 77.70%, Spikes = 0.0489\n",
            "Epoch 6, Batch 1220: Loss = 0.7766, Acc = 77.69%, Spikes = 0.0497\n",
            "Epoch 6, Batch 1230: Loss = 0.9938, Acc = 77.66%, Spikes = 0.0516\n",
            "Epoch 6, Batch 1240: Loss = 0.9349, Acc = 77.65%, Spikes = 0.0571\n",
            "Epoch 6, Batch 1250: Loss = 0.4342, Acc = 77.66%, Spikes = 0.0590\n",
            "Epoch 6, Batch 1260: Loss = 0.8971, Acc = 77.64%, Spikes = 0.0537\n",
            "Epoch 6, Batch 1270: Loss = 0.8823, Acc = 77.60%, Spikes = 0.0575\n",
            "Epoch 6, Batch 1280: Loss = 0.5142, Acc = 77.62%, Spikes = 0.0575\n",
            "Epoch 6, Batch 1290: Loss = 0.5196, Acc = 77.60%, Spikes = 0.0525\n",
            "Epoch 6, Batch 1300: Loss = 0.6598, Acc = 77.63%, Spikes = 0.0525\n",
            "Epoch 6, Batch 1310: Loss = 0.6667, Acc = 77.62%, Spikes = 0.0576\n",
            "Epoch 6, Batch 1320: Loss = 0.7182, Acc = 77.64%, Spikes = 0.0510\n",
            "Epoch 6, Batch 1330: Loss = 0.5096, Acc = 77.63%, Spikes = 0.0533\n",
            "Epoch 6, Batch 1340: Loss = 0.4837, Acc = 77.65%, Spikes = 0.0557\n",
            "Epoch 6, Batch 1350: Loss = 0.5450, Acc = 77.67%, Spikes = 0.0526\n",
            "Epoch 6, Batch 1360: Loss = 0.9987, Acc = 77.62%, Spikes = 0.0607\n",
            "Epoch 6, Batch 1370: Loss = 0.5762, Acc = 77.61%, Spikes = 0.0556\n",
            "Epoch 6, Batch 1380: Loss = 0.6791, Acc = 77.61%, Spikes = 0.0523\n",
            "Epoch 6, Batch 1390: Loss = 0.9693, Acc = 77.61%, Spikes = 0.0473\n",
            "Epoch 6, Batch 1400: Loss = 0.6716, Acc = 77.61%, Spikes = 0.0490\n",
            "Epoch 6, Batch 1410: Loss = 0.7037, Acc = 77.61%, Spikes = 0.0526\n",
            "Epoch 6, Batch 1420: Loss = 0.7278, Acc = 77.61%, Spikes = 0.0498\n",
            "Epoch 6, Batch 1430: Loss = 0.6796, Acc = 77.63%, Spikes = 0.0504\n",
            "Epoch 6, Batch 1440: Loss = 0.6347, Acc = 77.63%, Spikes = 0.0538\n",
            "Epoch 6, Batch 1450: Loss = 0.4589, Acc = 77.64%, Spikes = 0.0581\n",
            "Epoch 6, Batch 1460: Loss = 0.6032, Acc = 77.65%, Spikes = 0.0586\n",
            "Epoch 6, Batch 1470: Loss = 0.6559, Acc = 77.65%, Spikes = 0.0519\n",
            "Epoch 6, Batch 1480: Loss = 0.7244, Acc = 77.63%, Spikes = 0.0523\n",
            "Epoch 6, Batch 1490: Loss = 0.7829, Acc = 77.65%, Spikes = 0.0540\n",
            "Epoch 6, Batch 1500: Loss = 0.6331, Acc = 77.65%, Spikes = 0.0614\n",
            "Epoch 6, Batch 1510: Loss = 1.0075, Acc = 77.66%, Spikes = 0.0580\n",
            "Epoch 6, Batch 1520: Loss = 0.7267, Acc = 77.65%, Spikes = 0.0535\n",
            "Epoch 6, Batch 1530: Loss = 0.7282, Acc = 77.64%, Spikes = 0.0531\n",
            "Epoch 6, Batch 1540: Loss = 0.5517, Acc = 77.66%, Spikes = 0.0518\n",
            "Epoch 6, Batch 1550: Loss = 1.0390, Acc = 77.66%, Spikes = 0.0566\n",
            "Epoch 6, Batch 1560: Loss = 0.4792, Acc = 77.66%, Spikes = 0.0559\n",
            "Epoch 6, Batch 1570: Loss = 0.7854, Acc = 77.68%, Spikes = 0.0534\n",
            "Epoch 6, Batch 1580: Loss = 0.7505, Acc = 77.68%, Spikes = 0.0555\n",
            "Epoch 6, Batch 1590: Loss = 0.6392, Acc = 77.69%, Spikes = 0.0602\n",
            "Epoch 6, Batch 1600: Loss = 0.6032, Acc = 77.68%, Spikes = 0.0478\n",
            "Epoch 6, Batch 1610: Loss = 0.5784, Acc = 77.70%, Spikes = 0.0532\n",
            "Epoch 6, Batch 1620: Loss = 0.7246, Acc = 77.70%, Spikes = 0.0565\n",
            "Epoch 6, Batch 1630: Loss = 0.8168, Acc = 77.71%, Spikes = 0.0496\n",
            "Epoch 6, Batch 1640: Loss = 0.6912, Acc = 77.70%, Spikes = 0.0503\n",
            "Epoch 6, Batch 1650: Loss = 0.9845, Acc = 77.69%, Spikes = 0.0496\n",
            "Epoch 6, Batch 1660: Loss = 0.3877, Acc = 77.68%, Spikes = 0.0555\n",
            "Epoch 6, Batch 1670: Loss = 0.7584, Acc = 77.68%, Spikes = 0.0594\n",
            "Epoch 6, Batch 1680: Loss = 0.6896, Acc = 77.68%, Spikes = 0.0580\n",
            "Epoch 6, Batch 1690: Loss = 0.4421, Acc = 77.68%, Spikes = 0.0559\n",
            "Epoch 6, Batch 1700: Loss = 0.6896, Acc = 77.69%, Spikes = 0.0547\n",
            "Epoch 6, Batch 1710: Loss = 0.6157, Acc = 77.69%, Spikes = 0.0563\n",
            "Epoch 6, Batch 1720: Loss = 0.7003, Acc = 77.71%, Spikes = 0.0557\n",
            "Epoch 6, Batch 1730: Loss = 0.8563, Acc = 77.71%, Spikes = 0.0520\n",
            "Epoch 6, Batch 1740: Loss = 0.8270, Acc = 77.73%, Spikes = 0.0549\n",
            "Epoch 6, Batch 1750: Loss = 0.7154, Acc = 77.73%, Spikes = 0.0538\n",
            "Epoch 6, Batch 1760: Loss = 0.6109, Acc = 77.73%, Spikes = 0.0554\n",
            "Epoch 6, Batch 1770: Loss = 0.7051, Acc = 77.73%, Spikes = 0.0513\n",
            "Epoch 6, Batch 1780: Loss = 0.9584, Acc = 77.72%, Spikes = 0.0614\n",
            "Epoch 6, Batch 1790: Loss = 0.6579, Acc = 77.74%, Spikes = 0.0557\n",
            "Epoch 6, Batch 1800: Loss = 0.6987, Acc = 77.72%, Spikes = 0.0504\n",
            "Epoch 6, Batch 1810: Loss = 0.7297, Acc = 77.72%, Spikes = 0.0506\n",
            "Epoch 6, Batch 1820: Loss = 0.7021, Acc = 77.72%, Spikes = 0.0499\n",
            "Epoch 6, Batch 1830: Loss = 0.8445, Acc = 77.71%, Spikes = 0.0480\n",
            "Epoch 6, Batch 1840: Loss = 0.5651, Acc = 77.72%, Spikes = 0.0526\n",
            "Epoch 6, Batch 1850: Loss = 0.7461, Acc = 77.68%, Spikes = 0.0506\n",
            "Epoch 6, Batch 1860: Loss = 0.8071, Acc = 77.68%, Spikes = 0.0526\n",
            "Epoch 6, Batch 1870: Loss = 0.6485, Acc = 77.69%, Spikes = 0.0585\n",
            "Epoch 6/15:\n",
            "Train Loss: 0.7165 | Train Acc: 77.69% | Train Spikes: 0.0528\n",
            "Test Acc: 78.81% | Test Spikes: 0.0562\n",
            "------------------------------------------------------------\n",
            "Epoch 7, Batch 0: Loss = 0.3338, Acc = 93.75%, Spikes = 0.0598\n",
            "Epoch 7, Batch 10: Loss = 0.9130, Acc = 79.26%, Spikes = 0.0519\n",
            "Epoch 7, Batch 20: Loss = 0.3435, Acc = 77.98%, Spikes = 0.0618\n",
            "Epoch 7, Batch 30: Loss = 0.7689, Acc = 79.44%, Spikes = 0.0620\n",
            "Epoch 7, Batch 40: Loss = 0.8864, Acc = 78.89%, Spikes = 0.0488\n",
            "Epoch 7, Batch 50: Loss = 0.7341, Acc = 78.86%, Spikes = 0.0586\n",
            "Epoch 7, Batch 60: Loss = 0.7388, Acc = 78.53%, Spikes = 0.0572\n",
            "Epoch 7, Batch 70: Loss = 0.7099, Acc = 78.21%, Spikes = 0.0497\n",
            "Epoch 7, Batch 80: Loss = 0.5571, Acc = 78.36%, Spikes = 0.0584\n",
            "Epoch 7, Batch 90: Loss = 0.5176, Acc = 77.88%, Spikes = 0.0553\n",
            "Epoch 7, Batch 100: Loss = 0.4045, Acc = 78.09%, Spikes = 0.0561\n",
            "Epoch 7, Batch 110: Loss = 0.8132, Acc = 78.18%, Spikes = 0.0562\n",
            "Epoch 7, Batch 120: Loss = 0.5245, Acc = 78.07%, Spikes = 0.0528\n",
            "Epoch 7, Batch 130: Loss = 0.7302, Acc = 78.10%, Spikes = 0.0547\n",
            "Epoch 7, Batch 140: Loss = 0.4957, Acc = 78.15%, Spikes = 0.0581\n",
            "Epoch 7, Batch 150: Loss = 0.9170, Acc = 78.12%, Spikes = 0.0578\n",
            "Epoch 7, Batch 160: Loss = 0.7688, Acc = 78.22%, Spikes = 0.0552\n",
            "Epoch 7, Batch 170: Loss = 0.7292, Acc = 78.16%, Spikes = 0.0526\n",
            "Epoch 7, Batch 180: Loss = 0.6910, Acc = 78.26%, Spikes = 0.0604\n",
            "Epoch 7, Batch 190: Loss = 0.7198, Acc = 78.17%, Spikes = 0.0564\n",
            "Epoch 7, Batch 200: Loss = 0.5212, Acc = 78.00%, Spikes = 0.0618\n",
            "Epoch 7, Batch 210: Loss = 0.6931, Acc = 77.96%, Spikes = 0.0551\n",
            "Epoch 7, Batch 220: Loss = 0.5481, Acc = 78.03%, Spikes = 0.0571\n",
            "Epoch 7, Batch 230: Loss = 0.6532, Acc = 77.94%, Spikes = 0.0608\n",
            "Epoch 7, Batch 240: Loss = 0.7105, Acc = 77.72%, Spikes = 0.0480\n",
            "Epoch 7, Batch 250: Loss = 0.5885, Acc = 77.86%, Spikes = 0.0553\n",
            "Epoch 7, Batch 260: Loss = 0.7401, Acc = 77.96%, Spikes = 0.0512\n",
            "Epoch 7, Batch 270: Loss = 0.7079, Acc = 77.91%, Spikes = 0.0579\n",
            "Epoch 7, Batch 280: Loss = 0.5201, Acc = 77.90%, Spikes = 0.0560\n",
            "Epoch 7, Batch 290: Loss = 0.7584, Acc = 77.90%, Spikes = 0.0507\n",
            "Epoch 7, Batch 300: Loss = 0.5417, Acc = 78.02%, Spikes = 0.0596\n",
            "Epoch 7, Batch 310: Loss = 0.8915, Acc = 77.95%, Spikes = 0.0521\n",
            "Epoch 7, Batch 320: Loss = 0.5886, Acc = 78.05%, Spikes = 0.0578\n",
            "Epoch 7, Batch 330: Loss = 0.5619, Acc = 78.09%, Spikes = 0.0568\n",
            "Epoch 7, Batch 340: Loss = 0.9637, Acc = 78.09%, Spikes = 0.0562\n",
            "Epoch 7, Batch 350: Loss = 0.7619, Acc = 77.96%, Spikes = 0.0557\n",
            "Epoch 7, Batch 360: Loss = 0.4340, Acc = 78.06%, Spikes = 0.0586\n",
            "Epoch 7, Batch 370: Loss = 0.7075, Acc = 78.08%, Spikes = 0.0624\n",
            "Epoch 7, Batch 380: Loss = 0.9180, Acc = 78.00%, Spikes = 0.0565\n",
            "Epoch 7, Batch 390: Loss = 0.8998, Acc = 78.12%, Spikes = 0.0524\n",
            "Epoch 7, Batch 400: Loss = 0.5600, Acc = 78.09%, Spikes = 0.0545\n",
            "Epoch 7, Batch 410: Loss = 0.3565, Acc = 78.06%, Spikes = 0.0586\n",
            "Epoch 7, Batch 420: Loss = 0.6617, Acc = 78.15%, Spikes = 0.0567\n",
            "Epoch 7, Batch 430: Loss = 0.9221, Acc = 78.28%, Spikes = 0.0562\n",
            "Epoch 7, Batch 440: Loss = 0.7818, Acc = 78.33%, Spikes = 0.0627\n",
            "Epoch 7, Batch 450: Loss = 0.6636, Acc = 78.36%, Spikes = 0.0615\n",
            "Epoch 7, Batch 460: Loss = 0.6633, Acc = 78.38%, Spikes = 0.0572\n",
            "Epoch 7, Batch 470: Loss = 1.2392, Acc = 78.36%, Spikes = 0.0518\n",
            "Epoch 7, Batch 480: Loss = 0.4484, Acc = 78.42%, Spikes = 0.0567\n",
            "Epoch 7, Batch 490: Loss = 0.6868, Acc = 78.41%, Spikes = 0.0560\n",
            "Epoch 7, Batch 500: Loss = 0.3954, Acc = 78.41%, Spikes = 0.0549\n",
            "Epoch 7, Batch 510: Loss = 0.8402, Acc = 78.50%, Spikes = 0.0538\n",
            "Epoch 7, Batch 520: Loss = 0.8119, Acc = 78.48%, Spikes = 0.0570\n",
            "Epoch 7, Batch 530: Loss = 0.9016, Acc = 78.50%, Spikes = 0.0518\n",
            "Epoch 7, Batch 540: Loss = 1.0454, Acc = 78.44%, Spikes = 0.0505\n",
            "Epoch 7, Batch 550: Loss = 0.8723, Acc = 78.41%, Spikes = 0.0590\n",
            "Epoch 7, Batch 560: Loss = 0.5697, Acc = 78.40%, Spikes = 0.0574\n",
            "Epoch 7, Batch 570: Loss = 0.6455, Acc = 78.43%, Spikes = 0.0655\n",
            "Epoch 7, Batch 580: Loss = 0.7594, Acc = 78.39%, Spikes = 0.0576\n",
            "Epoch 7, Batch 590: Loss = 0.4962, Acc = 78.38%, Spikes = 0.0617\n",
            "Epoch 7, Batch 600: Loss = 0.5147, Acc = 78.42%, Spikes = 0.0556\n",
            "Epoch 7, Batch 610: Loss = 0.4892, Acc = 78.49%, Spikes = 0.0556\n",
            "Epoch 7, Batch 620: Loss = 0.6936, Acc = 78.51%, Spikes = 0.0591\n",
            "Epoch 7, Batch 630: Loss = 0.7170, Acc = 78.50%, Spikes = 0.0560\n",
            "Epoch 7, Batch 640: Loss = 0.7593, Acc = 78.49%, Spikes = 0.0613\n",
            "Epoch 7, Batch 650: Loss = 0.7782, Acc = 78.49%, Spikes = 0.0568\n",
            "Epoch 7, Batch 660: Loss = 0.4926, Acc = 78.50%, Spikes = 0.0574\n",
            "Epoch 7, Batch 670: Loss = 0.6062, Acc = 78.58%, Spikes = 0.0548\n",
            "Epoch 7, Batch 680: Loss = 0.5956, Acc = 78.60%, Spikes = 0.0501\n",
            "Epoch 7, Batch 690: Loss = 0.7337, Acc = 78.63%, Spikes = 0.0527\n",
            "Epoch 7, Batch 700: Loss = 0.5020, Acc = 78.66%, Spikes = 0.0542\n",
            "Epoch 7, Batch 710: Loss = 0.5316, Acc = 78.66%, Spikes = 0.0597\n",
            "Epoch 7, Batch 720: Loss = 0.5388, Acc = 78.66%, Spikes = 0.0587\n",
            "Epoch 7, Batch 730: Loss = 0.6734, Acc = 78.65%, Spikes = 0.0540\n",
            "Epoch 7, Batch 740: Loss = 0.7012, Acc = 78.64%, Spikes = 0.0622\n",
            "Epoch 7, Batch 750: Loss = 0.7111, Acc = 78.62%, Spikes = 0.0609\n",
            "Epoch 7, Batch 760: Loss = 0.9036, Acc = 78.65%, Spikes = 0.0580\n",
            "Epoch 7, Batch 770: Loss = 0.5548, Acc = 78.66%, Spikes = 0.0582\n",
            "Epoch 7, Batch 780: Loss = 0.6274, Acc = 78.64%, Spikes = 0.0589\n",
            "Epoch 7, Batch 790: Loss = 0.6492, Acc = 78.62%, Spikes = 0.0564\n",
            "Epoch 7, Batch 800: Loss = 0.7119, Acc = 78.59%, Spikes = 0.0609\n",
            "Epoch 7, Batch 810: Loss = 0.9086, Acc = 78.60%, Spikes = 0.0600\n",
            "Epoch 7, Batch 820: Loss = 0.8551, Acc = 78.60%, Spikes = 0.0567\n",
            "Epoch 7, Batch 830: Loss = 0.4307, Acc = 78.60%, Spikes = 0.0667\n",
            "Epoch 7, Batch 840: Loss = 0.4281, Acc = 78.60%, Spikes = 0.0585\n",
            "Epoch 7, Batch 850: Loss = 0.5409, Acc = 78.66%, Spikes = 0.0561\n",
            "Epoch 7, Batch 860: Loss = 0.6674, Acc = 78.65%, Spikes = 0.0596\n",
            "Epoch 7, Batch 870: Loss = 0.5753, Acc = 78.66%, Spikes = 0.0589\n",
            "Epoch 7, Batch 880: Loss = 0.9557, Acc = 78.63%, Spikes = 0.0565\n",
            "Epoch 7, Batch 890: Loss = 0.7717, Acc = 78.62%, Spikes = 0.0586\n",
            "Epoch 7, Batch 900: Loss = 0.4106, Acc = 78.61%, Spikes = 0.0576\n",
            "Epoch 7, Batch 910: Loss = 0.3869, Acc = 78.60%, Spikes = 0.0625\n",
            "Epoch 7, Batch 920: Loss = 0.3379, Acc = 78.60%, Spikes = 0.0660\n",
            "Epoch 7, Batch 930: Loss = 0.5663, Acc = 78.59%, Spikes = 0.0661\n",
            "Epoch 7, Batch 940: Loss = 0.4990, Acc = 78.58%, Spikes = 0.0621\n",
            "Epoch 7, Batch 950: Loss = 0.7299, Acc = 78.55%, Spikes = 0.0562\n",
            "Epoch 7, Batch 960: Loss = 0.3716, Acc = 78.54%, Spikes = 0.0622\n",
            "Epoch 7, Batch 970: Loss = 0.4944, Acc = 78.54%, Spikes = 0.0635\n",
            "Epoch 7, Batch 980: Loss = 0.5419, Acc = 78.55%, Spikes = 0.0578\n",
            "Epoch 7, Batch 990: Loss = 0.6410, Acc = 78.51%, Spikes = 0.0627\n",
            "Epoch 7, Batch 1000: Loss = 0.5185, Acc = 78.55%, Spikes = 0.0613\n",
            "Epoch 7, Batch 1010: Loss = 0.5601, Acc = 78.57%, Spikes = 0.0574\n",
            "Epoch 7, Batch 1020: Loss = 1.0223, Acc = 78.54%, Spikes = 0.0648\n",
            "Epoch 7, Batch 1030: Loss = 0.5470, Acc = 78.53%, Spikes = 0.0640\n",
            "Epoch 7, Batch 1040: Loss = 0.5738, Acc = 78.52%, Spikes = 0.0660\n",
            "Epoch 7, Batch 1050: Loss = 0.4727, Acc = 78.50%, Spikes = 0.0620\n",
            "Epoch 7, Batch 1060: Loss = 0.7626, Acc = 78.48%, Spikes = 0.0578\n",
            "Epoch 7, Batch 1070: Loss = 0.9213, Acc = 78.45%, Spikes = 0.0557\n",
            "Epoch 7, Batch 1080: Loss = 0.3278, Acc = 78.47%, Spikes = 0.0640\n",
            "Epoch 7, Batch 1090: Loss = 0.8265, Acc = 78.45%, Spikes = 0.0593\n",
            "Epoch 7, Batch 1100: Loss = 1.0083, Acc = 78.44%, Spikes = 0.0582\n",
            "Epoch 7, Batch 1110: Loss = 0.7376, Acc = 78.44%, Spikes = 0.0535\n",
            "Epoch 7, Batch 1120: Loss = 0.7303, Acc = 78.42%, Spikes = 0.0541\n",
            "Epoch 7, Batch 1130: Loss = 1.0246, Acc = 78.44%, Spikes = 0.0592\n",
            "Epoch 7, Batch 1140: Loss = 0.7705, Acc = 78.44%, Spikes = 0.0579\n",
            "Epoch 7, Batch 1150: Loss = 0.7736, Acc = 78.46%, Spikes = 0.0579\n",
            "Epoch 7, Batch 1160: Loss = 0.5582, Acc = 78.44%, Spikes = 0.0654\n",
            "Epoch 7, Batch 1170: Loss = 0.5497, Acc = 78.45%, Spikes = 0.0610\n",
            "Epoch 7, Batch 1180: Loss = 0.6645, Acc = 78.44%, Spikes = 0.0654\n",
            "Epoch 7, Batch 1190: Loss = 0.4801, Acc = 78.48%, Spikes = 0.0703\n",
            "Epoch 7, Batch 1200: Loss = 0.5265, Acc = 78.49%, Spikes = 0.0575\n",
            "Epoch 7, Batch 1210: Loss = 0.6786, Acc = 78.49%, Spikes = 0.0585\n",
            "Epoch 7, Batch 1220: Loss = 0.7977, Acc = 78.47%, Spikes = 0.0655\n",
            "Epoch 7, Batch 1230: Loss = 0.6817, Acc = 78.47%, Spikes = 0.0563\n",
            "Epoch 7, Batch 1240: Loss = 0.4872, Acc = 78.48%, Spikes = 0.0613\n",
            "Epoch 7, Batch 1250: Loss = 0.6076, Acc = 78.45%, Spikes = 0.0639\n",
            "Epoch 7, Batch 1260: Loss = 0.8207, Acc = 78.45%, Spikes = 0.0535\n",
            "Epoch 7, Batch 1270: Loss = 0.7593, Acc = 78.46%, Spikes = 0.0608\n",
            "Epoch 7, Batch 1280: Loss = 0.6969, Acc = 78.46%, Spikes = 0.0579\n",
            "Epoch 7, Batch 1290: Loss = 0.6420, Acc = 78.45%, Spikes = 0.0633\n",
            "Epoch 7, Batch 1300: Loss = 0.5739, Acc = 78.44%, Spikes = 0.0612\n",
            "Epoch 7, Batch 1310: Loss = 0.6458, Acc = 78.43%, Spikes = 0.0582\n",
            "Epoch 7, Batch 1320: Loss = 0.7980, Acc = 78.42%, Spikes = 0.0589\n",
            "Epoch 7, Batch 1330: Loss = 0.5270, Acc = 78.48%, Spikes = 0.0609\n",
            "Epoch 7, Batch 1340: Loss = 0.5474, Acc = 78.50%, Spikes = 0.0583\n",
            "Epoch 7, Batch 1350: Loss = 0.7942, Acc = 78.49%, Spikes = 0.0619\n",
            "Epoch 7, Batch 1360: Loss = 0.5464, Acc = 78.50%, Spikes = 0.0617\n",
            "Epoch 7, Batch 1370: Loss = 0.4889, Acc = 78.52%, Spikes = 0.0651\n",
            "Epoch 7, Batch 1380: Loss = 0.9208, Acc = 78.55%, Spikes = 0.0616\n",
            "Epoch 7, Batch 1390: Loss = 0.8723, Acc = 78.56%, Spikes = 0.0598\n",
            "Epoch 7, Batch 1400: Loss = 0.4579, Acc = 78.56%, Spikes = 0.0540\n",
            "Epoch 7, Batch 1410: Loss = 0.4640, Acc = 78.56%, Spikes = 0.0668\n",
            "Epoch 7, Batch 1420: Loss = 0.7332, Acc = 78.57%, Spikes = 0.0617\n",
            "Epoch 7, Batch 1430: Loss = 0.5447, Acc = 78.57%, Spikes = 0.0545\n",
            "Epoch 7, Batch 1440: Loss = 1.0666, Acc = 78.56%, Spikes = 0.0580\n",
            "Epoch 7, Batch 1450: Loss = 0.8485, Acc = 78.51%, Spikes = 0.0523\n",
            "Epoch 7, Batch 1460: Loss = 0.7699, Acc = 78.51%, Spikes = 0.0578\n",
            "Epoch 7, Batch 1470: Loss = 0.6666, Acc = 78.50%, Spikes = 0.0628\n",
            "Epoch 7, Batch 1480: Loss = 0.6353, Acc = 78.50%, Spikes = 0.0621\n",
            "Epoch 7, Batch 1490: Loss = 0.5636, Acc = 78.52%, Spikes = 0.0670\n",
            "Epoch 7, Batch 1500: Loss = 0.5736, Acc = 78.54%, Spikes = 0.0683\n",
            "Epoch 7, Batch 1510: Loss = 0.5595, Acc = 78.56%, Spikes = 0.0596\n",
            "Epoch 7, Batch 1520: Loss = 0.9027, Acc = 78.59%, Spikes = 0.0547\n",
            "Epoch 7, Batch 1530: Loss = 0.5557, Acc = 78.58%, Spikes = 0.0629\n",
            "Epoch 7, Batch 1540: Loss = 0.5498, Acc = 78.60%, Spikes = 0.0643\n",
            "Epoch 7, Batch 1550: Loss = 0.7534, Acc = 78.62%, Spikes = 0.0572\n",
            "Epoch 7, Batch 1560: Loss = 0.6322, Acc = 78.64%, Spikes = 0.0614\n",
            "Epoch 7, Batch 1570: Loss = 0.5892, Acc = 78.65%, Spikes = 0.0594\n",
            "Epoch 7, Batch 1580: Loss = 0.5965, Acc = 78.68%, Spikes = 0.0697\n",
            "Epoch 7, Batch 1590: Loss = 0.5519, Acc = 78.68%, Spikes = 0.0628\n",
            "Epoch 7, Batch 1600: Loss = 0.6184, Acc = 78.69%, Spikes = 0.0681\n",
            "Epoch 7, Batch 1610: Loss = 0.6952, Acc = 78.68%, Spikes = 0.0626\n",
            "Epoch 7, Batch 1620: Loss = 0.8163, Acc = 78.70%, Spikes = 0.0608\n",
            "Epoch 7, Batch 1630: Loss = 0.6835, Acc = 78.69%, Spikes = 0.0615\n",
            "Epoch 7, Batch 1640: Loss = 0.9193, Acc = 78.68%, Spikes = 0.0589\n",
            "Epoch 7, Batch 1650: Loss = 0.6640, Acc = 78.69%, Spikes = 0.0631\n",
            "Epoch 7, Batch 1660: Loss = 0.4496, Acc = 78.70%, Spikes = 0.0640\n",
            "Epoch 7, Batch 1670: Loss = 0.6575, Acc = 78.70%, Spikes = 0.0615\n",
            "Epoch 7, Batch 1680: Loss = 0.6550, Acc = 78.69%, Spikes = 0.0580\n",
            "Epoch 7, Batch 1690: Loss = 0.5633, Acc = 78.72%, Spikes = 0.0623\n",
            "Epoch 7, Batch 1700: Loss = 0.8659, Acc = 78.69%, Spikes = 0.0619\n",
            "Epoch 7, Batch 1710: Loss = 0.5770, Acc = 78.70%, Spikes = 0.0704\n",
            "Epoch 7, Batch 1720: Loss = 0.6592, Acc = 78.72%, Spikes = 0.0647\n",
            "Epoch 7, Batch 1730: Loss = 0.6609, Acc = 78.74%, Spikes = 0.0640\n",
            "Epoch 7, Batch 1740: Loss = 0.6606, Acc = 78.74%, Spikes = 0.0603\n",
            "Epoch 7, Batch 1750: Loss = 0.7017, Acc = 78.74%, Spikes = 0.0524\n",
            "Epoch 7, Batch 1760: Loss = 0.9759, Acc = 78.73%, Spikes = 0.0667\n",
            "Epoch 7, Batch 1770: Loss = 0.5472, Acc = 78.71%, Spikes = 0.0631\n",
            "Epoch 7, Batch 1780: Loss = 0.3074, Acc = 78.72%, Spikes = 0.0617\n",
            "Epoch 7, Batch 1790: Loss = 0.9007, Acc = 78.73%, Spikes = 0.0609\n",
            "Epoch 7, Batch 1800: Loss = 0.5991, Acc = 78.71%, Spikes = 0.0614\n",
            "Epoch 7, Batch 1810: Loss = 0.4198, Acc = 78.71%, Spikes = 0.0673\n",
            "Epoch 7, Batch 1820: Loss = 0.8362, Acc = 78.70%, Spikes = 0.0639\n",
            "Epoch 7, Batch 1830: Loss = 0.6133, Acc = 78.70%, Spikes = 0.0588\n",
            "Epoch 7, Batch 1840: Loss = 0.4428, Acc = 78.72%, Spikes = 0.0624\n",
            "Epoch 7, Batch 1850: Loss = 0.6423, Acc = 78.70%, Spikes = 0.0715\n",
            "Epoch 7, Batch 1860: Loss = 0.3962, Acc = 78.71%, Spikes = 0.0623\n",
            "Epoch 7, Batch 1870: Loss = 0.6548, Acc = 78.70%, Spikes = 0.0657\n",
            "Epoch 7/15:\n",
            "Train Loss: 0.6739 | Train Acc: 78.70% | Train Spikes: 0.0589\n",
            "Test Acc: 80.13% | Test Spikes: 0.0629\n",
            "------------------------------------------------------------\n",
            "Epoch 8, Batch 0: Loss = 0.4543, Acc = 84.38%, Spikes = 0.0631\n",
            "Epoch 8, Batch 10: Loss = 0.3290, Acc = 80.40%, Spikes = 0.0611\n",
            "Epoch 8, Batch 20: Loss = 0.6836, Acc = 79.02%, Spikes = 0.0566\n",
            "Epoch 8, Batch 30: Loss = 0.5772, Acc = 79.54%, Spikes = 0.0648\n",
            "Epoch 8, Batch 40: Loss = 0.6080, Acc = 79.57%, Spikes = 0.0636\n",
            "Epoch 8, Batch 50: Loss = 0.6945, Acc = 79.23%, Spikes = 0.0627\n",
            "Epoch 8, Batch 60: Loss = 0.6126, Acc = 78.79%, Spikes = 0.0580\n",
            "Epoch 8, Batch 70: Loss = 0.5335, Acc = 78.96%, Spikes = 0.0613\n",
            "Epoch 8, Batch 80: Loss = 0.6573, Acc = 78.82%, Spikes = 0.0629\n",
            "Epoch 8, Batch 90: Loss = 0.8659, Acc = 78.43%, Spikes = 0.0636\n",
            "Epoch 8, Batch 100: Loss = 0.9166, Acc = 78.68%, Spikes = 0.0590\n",
            "Epoch 8, Batch 110: Loss = 0.4834, Acc = 78.77%, Spikes = 0.0638\n",
            "Epoch 8, Batch 120: Loss = 0.6744, Acc = 78.77%, Spikes = 0.0615\n",
            "Epoch 8, Batch 130: Loss = 0.2746, Acc = 78.94%, Spikes = 0.0666\n",
            "Epoch 8, Batch 140: Loss = 0.6082, Acc = 78.88%, Spikes = 0.0658\n",
            "Epoch 8, Batch 150: Loss = 0.7540, Acc = 78.99%, Spikes = 0.0638\n",
            "Epoch 8, Batch 160: Loss = 0.7363, Acc = 78.90%, Spikes = 0.0614\n",
            "Epoch 8, Batch 170: Loss = 0.8032, Acc = 78.89%, Spikes = 0.0597\n",
            "Epoch 8, Batch 180: Loss = 0.6053, Acc = 78.90%, Spikes = 0.0613\n",
            "Epoch 8, Batch 190: Loss = 0.6030, Acc = 79.07%, Spikes = 0.0629\n",
            "Epoch 8, Batch 200: Loss = 0.7358, Acc = 79.04%, Spikes = 0.0595\n",
            "Epoch 8, Batch 210: Loss = 0.6670, Acc = 79.15%, Spikes = 0.0608\n",
            "Epoch 8, Batch 220: Loss = 1.0297, Acc = 79.06%, Spikes = 0.0575\n",
            "Epoch 8, Batch 230: Loss = 0.5273, Acc = 78.99%, Spikes = 0.0680\n",
            "Epoch 8, Batch 240: Loss = 0.4088, Acc = 79.01%, Spikes = 0.0678\n",
            "Epoch 8, Batch 250: Loss = 0.5647, Acc = 78.98%, Spikes = 0.0597\n",
            "Epoch 8, Batch 260: Loss = 0.6847, Acc = 78.90%, Spikes = 0.0646\n",
            "Epoch 8, Batch 270: Loss = 0.5149, Acc = 78.93%, Spikes = 0.0657\n",
            "Epoch 8, Batch 280: Loss = 0.7537, Acc = 78.96%, Spikes = 0.0591\n",
            "Epoch 8, Batch 290: Loss = 0.9211, Acc = 78.95%, Spikes = 0.0686\n",
            "Epoch 8, Batch 300: Loss = 0.5480, Acc = 78.93%, Spikes = 0.0605\n",
            "Epoch 8, Batch 310: Loss = 0.6971, Acc = 78.92%, Spikes = 0.0613\n",
            "Epoch 8, Batch 320: Loss = 0.8511, Acc = 79.08%, Spikes = 0.0636\n",
            "Epoch 8, Batch 330: Loss = 0.8213, Acc = 79.05%, Spikes = 0.0646\n",
            "Epoch 8, Batch 340: Loss = 0.5882, Acc = 79.08%, Spikes = 0.0601\n",
            "Epoch 8, Batch 350: Loss = 0.4928, Acc = 79.13%, Spikes = 0.0737\n",
            "Epoch 8, Batch 360: Loss = 0.8836, Acc = 79.10%, Spikes = 0.0609\n",
            "Epoch 8, Batch 370: Loss = 0.9162, Acc = 79.09%, Spikes = 0.0650\n",
            "Epoch 8, Batch 380: Loss = 0.7501, Acc = 79.18%, Spikes = 0.0584\n",
            "Epoch 8, Batch 390: Loss = 1.0550, Acc = 79.08%, Spikes = 0.0619\n",
            "Epoch 8, Batch 400: Loss = 0.8577, Acc = 79.04%, Spikes = 0.0622\n",
            "Epoch 8, Batch 410: Loss = 0.6032, Acc = 79.08%, Spikes = 0.0662\n",
            "Epoch 8, Batch 420: Loss = 0.7403, Acc = 79.06%, Spikes = 0.0636\n",
            "Epoch 8, Batch 430: Loss = 0.6279, Acc = 79.07%, Spikes = 0.0652\n",
            "Epoch 8, Batch 440: Loss = 0.7227, Acc = 79.02%, Spikes = 0.0604\n",
            "Epoch 8, Batch 450: Loss = 0.6731, Acc = 79.03%, Spikes = 0.0621\n",
            "Epoch 8, Batch 460: Loss = 0.3921, Acc = 79.09%, Spikes = 0.0703\n",
            "Epoch 8, Batch 470: Loss = 0.7568, Acc = 79.08%, Spikes = 0.0648\n",
            "Epoch 8, Batch 480: Loss = 0.7384, Acc = 79.05%, Spikes = 0.0652\n",
            "Epoch 8, Batch 490: Loss = 0.6555, Acc = 79.08%, Spikes = 0.0645\n",
            "Epoch 8, Batch 500: Loss = 0.5801, Acc = 79.08%, Spikes = 0.0659\n",
            "Epoch 8, Batch 510: Loss = 0.5371, Acc = 79.00%, Spikes = 0.0666\n",
            "Epoch 8, Batch 520: Loss = 0.8449, Acc = 78.99%, Spikes = 0.0626\n",
            "Epoch 8, Batch 530: Loss = 0.8122, Acc = 78.99%, Spikes = 0.0669\n",
            "Epoch 8, Batch 540: Loss = 0.7226, Acc = 79.08%, Spikes = 0.0635\n",
            "Epoch 8, Batch 550: Loss = 0.5721, Acc = 79.09%, Spikes = 0.0616\n",
            "Epoch 8, Batch 560: Loss = 0.5422, Acc = 79.06%, Spikes = 0.0630\n",
            "Epoch 8, Batch 570: Loss = 0.4406, Acc = 79.15%, Spikes = 0.0686\n",
            "Epoch 8, Batch 580: Loss = 0.4249, Acc = 79.15%, Spikes = 0.0658\n",
            "Epoch 8, Batch 590: Loss = 1.1711, Acc = 79.06%, Spikes = 0.0672\n",
            "Epoch 8, Batch 600: Loss = 0.6089, Acc = 79.07%, Spikes = 0.0638\n",
            "Epoch 8, Batch 610: Loss = 0.6488, Acc = 79.07%, Spikes = 0.0681\n",
            "Epoch 8, Batch 620: Loss = 0.7388, Acc = 79.13%, Spikes = 0.0648\n",
            "Epoch 8, Batch 630: Loss = 0.8047, Acc = 79.10%, Spikes = 0.0692\n",
            "Epoch 8, Batch 640: Loss = 0.3624, Acc = 79.12%, Spikes = 0.0725\n",
            "Epoch 8, Batch 650: Loss = 0.5976, Acc = 79.11%, Spikes = 0.0645\n",
            "Epoch 8, Batch 660: Loss = 0.3817, Acc = 79.13%, Spikes = 0.0752\n",
            "Epoch 8, Batch 670: Loss = 0.8241, Acc = 79.15%, Spikes = 0.0677\n",
            "Epoch 8, Batch 680: Loss = 0.6331, Acc = 79.15%, Spikes = 0.0615\n",
            "Epoch 8, Batch 690: Loss = 0.9760, Acc = 79.20%, Spikes = 0.0680\n",
            "Epoch 8, Batch 700: Loss = 0.5539, Acc = 79.21%, Spikes = 0.0648\n",
            "Epoch 8, Batch 710: Loss = 0.5140, Acc = 79.27%, Spikes = 0.0656\n",
            "Epoch 8, Batch 720: Loss = 0.8417, Acc = 79.25%, Spikes = 0.0584\n",
            "Epoch 8, Batch 730: Loss = 0.3938, Acc = 79.28%, Spikes = 0.0690\n",
            "Epoch 8, Batch 740: Loss = 0.6352, Acc = 79.29%, Spikes = 0.0629\n",
            "Epoch 8, Batch 750: Loss = 0.5219, Acc = 79.32%, Spikes = 0.0641\n",
            "Epoch 8, Batch 760: Loss = 0.6316, Acc = 79.31%, Spikes = 0.0679\n",
            "Epoch 8, Batch 770: Loss = 0.7696, Acc = 79.29%, Spikes = 0.0702\n",
            "Epoch 8, Batch 780: Loss = 0.5848, Acc = 79.31%, Spikes = 0.0702\n",
            "Epoch 8, Batch 790: Loss = 0.3441, Acc = 79.32%, Spikes = 0.0670\n",
            "Epoch 8, Batch 800: Loss = 0.5989, Acc = 79.34%, Spikes = 0.0684\n",
            "Epoch 8, Batch 810: Loss = 0.5091, Acc = 79.32%, Spikes = 0.0712\n",
            "Epoch 8, Batch 820: Loss = 0.6703, Acc = 79.32%, Spikes = 0.0734\n",
            "Epoch 8, Batch 830: Loss = 0.5671, Acc = 79.34%, Spikes = 0.0616\n",
            "Epoch 8, Batch 840: Loss = 0.8288, Acc = 79.31%, Spikes = 0.0668\n",
            "Epoch 8, Batch 850: Loss = 0.7817, Acc = 79.28%, Spikes = 0.0649\n",
            "Epoch 8, Batch 860: Loss = 0.7809, Acc = 79.25%, Spikes = 0.0658\n",
            "Epoch 8, Batch 870: Loss = 0.5133, Acc = 79.25%, Spikes = 0.0674\n",
            "Epoch 8, Batch 880: Loss = 0.6864, Acc = 79.24%, Spikes = 0.0693\n",
            "Epoch 8, Batch 890: Loss = 0.5459, Acc = 79.23%, Spikes = 0.0710\n",
            "Epoch 8, Batch 900: Loss = 0.9144, Acc = 79.26%, Spikes = 0.0643\n",
            "Epoch 8, Batch 910: Loss = 0.7211, Acc = 79.28%, Spikes = 0.0737\n",
            "Epoch 8, Batch 920: Loss = 0.7666, Acc = 79.33%, Spikes = 0.0683\n",
            "Epoch 8, Batch 930: Loss = 0.9594, Acc = 79.31%, Spikes = 0.0657\n",
            "Epoch 8, Batch 940: Loss = 0.5077, Acc = 79.32%, Spikes = 0.0706\n",
            "Epoch 8, Batch 950: Loss = 0.8281, Acc = 79.30%, Spikes = 0.0629\n",
            "Epoch 8, Batch 960: Loss = 0.7603, Acc = 79.26%, Spikes = 0.0649\n",
            "Epoch 8, Batch 970: Loss = 0.5096, Acc = 79.25%, Spikes = 0.0661\n",
            "Epoch 8, Batch 980: Loss = 0.3937, Acc = 79.27%, Spikes = 0.0665\n",
            "Epoch 8, Batch 990: Loss = 0.5066, Acc = 79.27%, Spikes = 0.0678\n",
            "Epoch 8, Batch 1000: Loss = 0.9019, Acc = 79.31%, Spikes = 0.0669\n",
            "Epoch 8, Batch 1010: Loss = 0.8026, Acc = 79.32%, Spikes = 0.0694\n",
            "Epoch 8, Batch 1020: Loss = 0.9455, Acc = 79.30%, Spikes = 0.0717\n",
            "Epoch 8, Batch 1030: Loss = 0.7742, Acc = 79.29%, Spikes = 0.0646\n",
            "Epoch 8, Batch 1040: Loss = 0.8487, Acc = 79.30%, Spikes = 0.0660\n",
            "Epoch 8, Batch 1050: Loss = 0.6978, Acc = 79.31%, Spikes = 0.0680\n",
            "Epoch 8, Batch 1060: Loss = 0.9146, Acc = 79.28%, Spikes = 0.0680\n",
            "Epoch 8, Batch 1070: Loss = 0.6769, Acc = 79.30%, Spikes = 0.0638\n",
            "Epoch 8, Batch 1080: Loss = 0.5154, Acc = 79.30%, Spikes = 0.0703\n",
            "Epoch 8, Batch 1090: Loss = 0.7018, Acc = 79.29%, Spikes = 0.0660\n",
            "Epoch 8, Batch 1100: Loss = 0.6786, Acc = 79.31%, Spikes = 0.0659\n",
            "Epoch 8, Batch 1110: Loss = 0.6200, Acc = 79.32%, Spikes = 0.0658\n",
            "Epoch 8, Batch 1120: Loss = 0.9710, Acc = 79.30%, Spikes = 0.0664\n",
            "Epoch 8, Batch 1130: Loss = 0.8222, Acc = 79.31%, Spikes = 0.0718\n",
            "Epoch 8, Batch 1140: Loss = 0.9978, Acc = 79.31%, Spikes = 0.0716\n",
            "Epoch 8, Batch 1150: Loss = 0.5077, Acc = 79.30%, Spikes = 0.0737\n",
            "Epoch 8, Batch 1160: Loss = 0.4629, Acc = 79.31%, Spikes = 0.0676\n",
            "Epoch 8, Batch 1170: Loss = 0.6015, Acc = 79.30%, Spikes = 0.0652\n",
            "Epoch 8, Batch 1180: Loss = 0.6373, Acc = 79.31%, Spikes = 0.0659\n",
            "Epoch 8, Batch 1190: Loss = 0.4845, Acc = 79.30%, Spikes = 0.0680\n",
            "Epoch 8, Batch 1200: Loss = 0.7278, Acc = 79.30%, Spikes = 0.0699\n",
            "Epoch 8, Batch 1210: Loss = 0.5397, Acc = 79.31%, Spikes = 0.0705\n",
            "Epoch 8, Batch 1220: Loss = 0.5703, Acc = 79.32%, Spikes = 0.0735\n",
            "Epoch 8, Batch 1230: Loss = 0.7848, Acc = 79.31%, Spikes = 0.0660\n",
            "Epoch 8, Batch 1240: Loss = 0.4812, Acc = 79.32%, Spikes = 0.0670\n",
            "Epoch 8, Batch 1250: Loss = 0.6807, Acc = 79.32%, Spikes = 0.0713\n",
            "Epoch 8, Batch 1260: Loss = 0.6746, Acc = 79.31%, Spikes = 0.0689\n",
            "Epoch 8, Batch 1270: Loss = 0.7730, Acc = 79.32%, Spikes = 0.0666\n",
            "Epoch 8, Batch 1280: Loss = 0.5124, Acc = 79.33%, Spikes = 0.0704\n",
            "Epoch 8, Batch 1290: Loss = 0.4358, Acc = 79.32%, Spikes = 0.0682\n",
            "Epoch 8, Batch 1300: Loss = 0.4261, Acc = 79.34%, Spikes = 0.0673\n",
            "Epoch 8, Batch 1310: Loss = 0.6697, Acc = 79.36%, Spikes = 0.0688\n",
            "Epoch 8, Batch 1320: Loss = 0.5622, Acc = 79.39%, Spikes = 0.0636\n",
            "Epoch 8, Batch 1330: Loss = 0.2650, Acc = 79.41%, Spikes = 0.0736\n",
            "Epoch 8, Batch 1340: Loss = 0.6586, Acc = 79.42%, Spikes = 0.0660\n",
            "Epoch 8, Batch 1350: Loss = 0.5154, Acc = 79.41%, Spikes = 0.0710\n",
            "Epoch 8, Batch 1360: Loss = 0.4250, Acc = 79.42%, Spikes = 0.0661\n",
            "Epoch 8, Batch 1370: Loss = 0.6396, Acc = 79.39%, Spikes = 0.0690\n",
            "Epoch 8, Batch 1380: Loss = 0.9226, Acc = 79.38%, Spikes = 0.0647\n",
            "Epoch 8, Batch 1390: Loss = 0.6436, Acc = 79.39%, Spikes = 0.0720\n",
            "Epoch 8, Batch 1400: Loss = 0.7629, Acc = 79.38%, Spikes = 0.0657\n",
            "Epoch 8, Batch 1410: Loss = 0.6622, Acc = 79.39%, Spikes = 0.0733\n",
            "Epoch 8, Batch 1420: Loss = 0.8020, Acc = 79.39%, Spikes = 0.0691\n",
            "Epoch 8, Batch 1430: Loss = 0.5109, Acc = 79.40%, Spikes = 0.0703\n",
            "Epoch 8, Batch 1440: Loss = 0.4084, Acc = 79.41%, Spikes = 0.0706\n",
            "Epoch 8, Batch 1450: Loss = 0.4813, Acc = 79.42%, Spikes = 0.0691\n",
            "Epoch 8, Batch 1460: Loss = 0.9509, Acc = 79.42%, Spikes = 0.0675\n",
            "Epoch 8, Batch 1470: Loss = 0.3729, Acc = 79.41%, Spikes = 0.0689\n",
            "Epoch 8, Batch 1480: Loss = 0.5593, Acc = 79.40%, Spikes = 0.0679\n",
            "Epoch 8, Batch 1490: Loss = 0.6565, Acc = 79.37%, Spikes = 0.0732\n",
            "Epoch 8, Batch 1500: Loss = 0.3885, Acc = 79.37%, Spikes = 0.0706\n",
            "Epoch 8, Batch 1510: Loss = 0.8234, Acc = 79.39%, Spikes = 0.0693\n",
            "Epoch 8, Batch 1520: Loss = 0.5753, Acc = 79.40%, Spikes = 0.0726\n",
            "Epoch 8, Batch 1530: Loss = 0.7567, Acc = 79.40%, Spikes = 0.0714\n",
            "Epoch 8, Batch 1540: Loss = 1.0641, Acc = 79.38%, Spikes = 0.0694\n",
            "Epoch 8, Batch 1550: Loss = 0.5248, Acc = 79.38%, Spikes = 0.0722\n",
            "Epoch 8, Batch 1560: Loss = 0.7949, Acc = 79.36%, Spikes = 0.0699\n",
            "Epoch 8, Batch 1570: Loss = 0.6143, Acc = 79.37%, Spikes = 0.0636\n",
            "Epoch 8, Batch 1580: Loss = 0.8705, Acc = 79.37%, Spikes = 0.0739\n",
            "Epoch 8, Batch 1590: Loss = 0.7637, Acc = 79.36%, Spikes = 0.0733\n",
            "Epoch 8, Batch 1600: Loss = 0.6708, Acc = 79.36%, Spikes = 0.0664\n",
            "Epoch 8, Batch 1610: Loss = 0.6166, Acc = 79.38%, Spikes = 0.0708\n",
            "Epoch 8, Batch 1620: Loss = 0.6364, Acc = 79.37%, Spikes = 0.0735\n",
            "Epoch 8, Batch 1630: Loss = 0.4012, Acc = 79.40%, Spikes = 0.0700\n",
            "Epoch 8, Batch 1640: Loss = 0.8671, Acc = 79.39%, Spikes = 0.0697\n",
            "Epoch 8, Batch 1650: Loss = 0.4466, Acc = 79.41%, Spikes = 0.0686\n",
            "Epoch 8, Batch 1660: Loss = 0.5630, Acc = 79.41%, Spikes = 0.0750\n",
            "Epoch 8, Batch 1670: Loss = 0.4533, Acc = 79.44%, Spikes = 0.0735\n",
            "Epoch 8, Batch 1680: Loss = 0.4584, Acc = 79.45%, Spikes = 0.0732\n",
            "Epoch 8, Batch 1690: Loss = 0.5156, Acc = 79.44%, Spikes = 0.0690\n",
            "Epoch 8, Batch 1700: Loss = 0.5225, Acc = 79.45%, Spikes = 0.0684\n",
            "Epoch 8, Batch 1710: Loss = 0.7656, Acc = 79.42%, Spikes = 0.0721\n",
            "Epoch 8, Batch 1720: Loss = 0.8032, Acc = 79.40%, Spikes = 0.0660\n",
            "Epoch 8, Batch 1730: Loss = 0.6426, Acc = 79.40%, Spikes = 0.0656\n",
            "Epoch 8, Batch 1740: Loss = 0.7605, Acc = 79.39%, Spikes = 0.0737\n",
            "Epoch 8, Batch 1750: Loss = 0.4148, Acc = 79.41%, Spikes = 0.0707\n",
            "Epoch 8, Batch 1760: Loss = 0.5333, Acc = 79.43%, Spikes = 0.0773\n",
            "Epoch 8, Batch 1770: Loss = 0.3165, Acc = 79.45%, Spikes = 0.0713\n",
            "Epoch 8, Batch 1780: Loss = 0.3800, Acc = 79.44%, Spikes = 0.0755\n",
            "Epoch 8, Batch 1790: Loss = 0.8860, Acc = 79.45%, Spikes = 0.0716\n",
            "Epoch 8, Batch 1800: Loss = 0.6103, Acc = 79.44%, Spikes = 0.0739\n",
            "Epoch 8, Batch 1810: Loss = 0.6915, Acc = 79.45%, Spikes = 0.0704\n",
            "Epoch 8, Batch 1820: Loss = 0.6884, Acc = 79.46%, Spikes = 0.0732\n",
            "Epoch 8, Batch 1830: Loss = 0.5695, Acc = 79.47%, Spikes = 0.0696\n",
            "Epoch 8, Batch 1840: Loss = 0.6077, Acc = 79.44%, Spikes = 0.0692\n",
            "Epoch 8, Batch 1850: Loss = 0.7630, Acc = 79.43%, Spikes = 0.0670\n",
            "Epoch 8, Batch 1860: Loss = 0.4676, Acc = 79.41%, Spikes = 0.0713\n",
            "Epoch 8, Batch 1870: Loss = 0.3352, Acc = 79.44%, Spikes = 0.0756\n",
            "Epoch 8/15:\n",
            "Train Loss: 0.6466 | Train Acc: 79.45% | Train Spikes: 0.0669\n",
            "Test Acc: 80.35% | Test Spikes: 0.0720\n",
            "------------------------------------------------------------\n",
            "Epoch 9, Batch 0: Loss = 0.8026, Acc = 78.12%, Spikes = 0.0725\n",
            "Epoch 9, Batch 10: Loss = 0.5444, Acc = 80.40%, Spikes = 0.0761\n",
            "Epoch 9, Batch 20: Loss = 0.7516, Acc = 81.40%, Spikes = 0.0699\n",
            "Epoch 9, Batch 30: Loss = 1.2549, Acc = 80.54%, Spikes = 0.0718\n",
            "Epoch 9, Batch 40: Loss = 0.9042, Acc = 80.95%, Spikes = 0.0696\n",
            "Epoch 9, Batch 50: Loss = 0.7810, Acc = 81.50%, Spikes = 0.0667\n",
            "Epoch 9, Batch 60: Loss = 0.4921, Acc = 81.45%, Spikes = 0.0676\n",
            "Epoch 9, Batch 70: Loss = 0.4898, Acc = 81.34%, Spikes = 0.0719\n",
            "Epoch 9, Batch 80: Loss = 0.4363, Acc = 81.17%, Spikes = 0.0752\n",
            "Epoch 9, Batch 90: Loss = 0.5754, Acc = 80.87%, Spikes = 0.0758\n",
            "Epoch 9, Batch 100: Loss = 0.5234, Acc = 81.13%, Spikes = 0.0751\n",
            "Epoch 9, Batch 110: Loss = 0.3637, Acc = 81.48%, Spikes = 0.0697\n",
            "Epoch 9, Batch 120: Loss = 0.5527, Acc = 81.20%, Spikes = 0.0737\n",
            "Epoch 9, Batch 130: Loss = 0.7897, Acc = 81.25%, Spikes = 0.0677\n",
            "Epoch 9, Batch 140: Loss = 0.7462, Acc = 81.03%, Spikes = 0.0694\n",
            "Epoch 9, Batch 150: Loss = 0.3625, Acc = 81.15%, Spikes = 0.0767\n",
            "Epoch 9, Batch 160: Loss = 0.3991, Acc = 81.11%, Spikes = 0.0705\n",
            "Epoch 9, Batch 170: Loss = 0.5340, Acc = 81.36%, Spikes = 0.0723\n",
            "Epoch 9, Batch 180: Loss = 0.7695, Acc = 81.34%, Spikes = 0.0693\n",
            "Epoch 9, Batch 190: Loss = 0.7672, Acc = 81.20%, Spikes = 0.0718\n",
            "Epoch 9, Batch 200: Loss = 0.7510, Acc = 81.31%, Spikes = 0.0742\n",
            "Epoch 9, Batch 210: Loss = 0.6546, Acc = 81.44%, Spikes = 0.0711\n",
            "Epoch 9, Batch 220: Loss = 0.5546, Acc = 81.18%, Spikes = 0.0720\n",
            "Epoch 9, Batch 230: Loss = 0.6087, Acc = 81.01%, Spikes = 0.0683\n",
            "Epoch 9, Batch 240: Loss = 0.4185, Acc = 80.86%, Spikes = 0.0816\n",
            "Epoch 9, Batch 250: Loss = 0.6558, Acc = 80.84%, Spikes = 0.0722\n",
            "Epoch 9, Batch 260: Loss = 0.7014, Acc = 80.85%, Spikes = 0.0708\n",
            "Epoch 9, Batch 270: Loss = 0.7211, Acc = 80.86%, Spikes = 0.0695\n",
            "Epoch 9, Batch 280: Loss = 0.3176, Acc = 80.82%, Spikes = 0.0742\n",
            "Epoch 9, Batch 290: Loss = 0.7049, Acc = 80.80%, Spikes = 0.0688\n",
            "Epoch 9, Batch 300: Loss = 0.7896, Acc = 80.71%, Spikes = 0.0773\n",
            "Epoch 9, Batch 310: Loss = 0.6538, Acc = 80.78%, Spikes = 0.0746\n",
            "Epoch 9, Batch 320: Loss = 0.7526, Acc = 80.68%, Spikes = 0.0696\n",
            "Epoch 9, Batch 330: Loss = 0.6470, Acc = 80.52%, Spikes = 0.0775\n",
            "Epoch 9, Batch 340: Loss = 0.5399, Acc = 80.40%, Spikes = 0.0740\n",
            "Epoch 9, Batch 350: Loss = 0.6691, Acc = 80.39%, Spikes = 0.0746\n",
            "Epoch 9, Batch 360: Loss = 0.3097, Acc = 80.41%, Spikes = 0.0730\n",
            "Epoch 9, Batch 370: Loss = 0.4943, Acc = 80.33%, Spikes = 0.0713\n",
            "Epoch 9, Batch 380: Loss = 0.8754, Acc = 80.34%, Spikes = 0.0731\n",
            "Epoch 9, Batch 390: Loss = 0.6213, Acc = 80.38%, Spikes = 0.0757\n",
            "Epoch 9, Batch 400: Loss = 0.7387, Acc = 80.27%, Spikes = 0.0722\n",
            "Epoch 9, Batch 410: Loss = 0.8989, Acc = 80.25%, Spikes = 0.0749\n",
            "Epoch 9, Batch 420: Loss = 0.4025, Acc = 80.23%, Spikes = 0.0696\n",
            "Epoch 9, Batch 430: Loss = 0.7973, Acc = 80.19%, Spikes = 0.0761\n",
            "Epoch 9, Batch 440: Loss = 0.4880, Acc = 80.12%, Spikes = 0.0731\n",
            "Epoch 9, Batch 450: Loss = 0.4781, Acc = 80.07%, Spikes = 0.0752\n",
            "Epoch 9, Batch 460: Loss = 0.7444, Acc = 80.08%, Spikes = 0.0744\n",
            "Epoch 9, Batch 470: Loss = 0.5339, Acc = 80.08%, Spikes = 0.0709\n",
            "Epoch 9, Batch 480: Loss = 0.7227, Acc = 80.03%, Spikes = 0.0729\n",
            "Epoch 9, Batch 490: Loss = 0.6413, Acc = 79.99%, Spikes = 0.0720\n",
            "Epoch 9, Batch 500: Loss = 0.6822, Acc = 79.95%, Spikes = 0.0764\n",
            "Epoch 9, Batch 510: Loss = 0.6769, Acc = 80.00%, Spikes = 0.0716\n",
            "Epoch 9, Batch 520: Loss = 0.7237, Acc = 80.00%, Spikes = 0.0718\n",
            "Epoch 9, Batch 530: Loss = 0.6266, Acc = 79.97%, Spikes = 0.0713\n",
            "Epoch 9, Batch 540: Loss = 0.7745, Acc = 79.93%, Spikes = 0.0734\n",
            "Epoch 9, Batch 550: Loss = 0.2692, Acc = 79.98%, Spikes = 0.0771\n",
            "Epoch 9, Batch 560: Loss = 0.4646, Acc = 79.97%, Spikes = 0.0738\n",
            "Epoch 9, Batch 570: Loss = 0.7822, Acc = 80.00%, Spikes = 0.0785\n",
            "Epoch 9, Batch 580: Loss = 0.8297, Acc = 79.93%, Spikes = 0.0743\n",
            "Epoch 9, Batch 590: Loss = 0.8037, Acc = 79.91%, Spikes = 0.0703\n",
            "Epoch 9, Batch 600: Loss = 0.8223, Acc = 79.91%, Spikes = 0.0767\n",
            "Epoch 9, Batch 610: Loss = 0.4813, Acc = 79.89%, Spikes = 0.0820\n",
            "Epoch 9, Batch 620: Loss = 1.0594, Acc = 79.87%, Spikes = 0.0704\n",
            "Epoch 9, Batch 630: Loss = 0.5002, Acc = 79.92%, Spikes = 0.0788\n",
            "Epoch 9, Batch 640: Loss = 1.1175, Acc = 79.90%, Spikes = 0.0690\n",
            "Epoch 9, Batch 650: Loss = 0.5330, Acc = 79.87%, Spikes = 0.0760\n",
            "Epoch 9, Batch 660: Loss = 0.7181, Acc = 79.85%, Spikes = 0.0778\n",
            "Epoch 9, Batch 670: Loss = 0.5383, Acc = 79.98%, Spikes = 0.0776\n",
            "Epoch 9, Batch 680: Loss = 0.8021, Acc = 80.03%, Spikes = 0.0738\n",
            "Epoch 9, Batch 690: Loss = 0.5476, Acc = 80.04%, Spikes = 0.0709\n",
            "Epoch 9, Batch 700: Loss = 0.6760, Acc = 80.03%, Spikes = 0.0743\n",
            "Epoch 9, Batch 710: Loss = 0.8113, Acc = 80.04%, Spikes = 0.0795\n",
            "Epoch 9, Batch 720: Loss = 0.5791, Acc = 80.07%, Spikes = 0.0683\n",
            "Epoch 9, Batch 730: Loss = 0.6305, Acc = 80.07%, Spikes = 0.0757\n",
            "Epoch 9, Batch 740: Loss = 0.5127, Acc = 80.02%, Spikes = 0.0779\n",
            "Epoch 9, Batch 750: Loss = 0.6930, Acc = 80.03%, Spikes = 0.0721\n",
            "Epoch 9, Batch 760: Loss = 0.7548, Acc = 80.01%, Spikes = 0.0754\n",
            "Epoch 9, Batch 770: Loss = 0.8678, Acc = 80.04%, Spikes = 0.0697\n",
            "Epoch 9, Batch 780: Loss = 0.3939, Acc = 80.05%, Spikes = 0.0748\n",
            "Epoch 9, Batch 790: Loss = 1.0688, Acc = 80.05%, Spikes = 0.0721\n",
            "Epoch 9, Batch 800: Loss = 0.6106, Acc = 79.98%, Spikes = 0.0750\n",
            "Epoch 9, Batch 810: Loss = 0.6713, Acc = 79.97%, Spikes = 0.0784\n",
            "Epoch 9, Batch 820: Loss = 0.6803, Acc = 80.00%, Spikes = 0.0768\n",
            "Epoch 9, Batch 830: Loss = 0.5924, Acc = 79.96%, Spikes = 0.0719\n",
            "Epoch 9, Batch 840: Loss = 0.8478, Acc = 79.95%, Spikes = 0.0672\n",
            "Epoch 9, Batch 850: Loss = 0.3616, Acc = 79.99%, Spikes = 0.0778\n",
            "Epoch 9, Batch 860: Loss = 0.8931, Acc = 79.98%, Spikes = 0.0707\n",
            "Epoch 9, Batch 870: Loss = 0.6938, Acc = 79.94%, Spikes = 0.0740\n",
            "Epoch 9, Batch 880: Loss = 0.6283, Acc = 79.89%, Spikes = 0.0792\n",
            "Epoch 9, Batch 890: Loss = 0.4962, Acc = 79.94%, Spikes = 0.0727\n",
            "Epoch 9, Batch 900: Loss = 0.6052, Acc = 79.95%, Spikes = 0.0775\n",
            "Epoch 9, Batch 910: Loss = 0.5388, Acc = 79.92%, Spikes = 0.0833\n",
            "Epoch 9, Batch 920: Loss = 0.3466, Acc = 79.95%, Spikes = 0.0770\n",
            "Epoch 9, Batch 930: Loss = 0.5999, Acc = 79.93%, Spikes = 0.0802\n",
            "Epoch 9, Batch 940: Loss = 0.5462, Acc = 79.91%, Spikes = 0.0802\n",
            "Epoch 9, Batch 950: Loss = 0.7573, Acc = 79.94%, Spikes = 0.0765\n",
            "Epoch 9, Batch 960: Loss = 0.5733, Acc = 79.95%, Spikes = 0.0711\n",
            "Epoch 9, Batch 970: Loss = 0.5451, Acc = 79.97%, Spikes = 0.0780\n",
            "Epoch 9, Batch 980: Loss = 0.8407, Acc = 79.97%, Spikes = 0.0761\n",
            "Epoch 9, Batch 990: Loss = 0.7333, Acc = 79.96%, Spikes = 0.0773\n",
            "Epoch 9, Batch 1000: Loss = 0.3913, Acc = 79.97%, Spikes = 0.0815\n",
            "Epoch 9, Batch 1010: Loss = 0.7678, Acc = 79.99%, Spikes = 0.0724\n",
            "Epoch 9, Batch 1020: Loss = 0.5827, Acc = 80.00%, Spikes = 0.0773\n",
            "Epoch 9, Batch 1030: Loss = 0.4626, Acc = 80.01%, Spikes = 0.0730\n",
            "Epoch 9, Batch 1040: Loss = 0.7274, Acc = 80.01%, Spikes = 0.0722\n",
            "Epoch 9, Batch 1050: Loss = 0.7742, Acc = 79.99%, Spikes = 0.0780\n",
            "Epoch 9, Batch 1060: Loss = 0.6205, Acc = 79.96%, Spikes = 0.0779\n",
            "Epoch 9, Batch 1070: Loss = 0.6221, Acc = 79.97%, Spikes = 0.0749\n",
            "Epoch 9, Batch 1080: Loss = 0.5289, Acc = 79.97%, Spikes = 0.0773\n",
            "Epoch 9, Batch 1090: Loss = 0.4005, Acc = 79.99%, Spikes = 0.0821\n",
            "Epoch 9, Batch 1100: Loss = 0.6851, Acc = 79.96%, Spikes = 0.0769\n",
            "Epoch 9, Batch 1110: Loss = 0.6394, Acc = 79.93%, Spikes = 0.0818\n",
            "Epoch 9, Batch 1120: Loss = 0.5129, Acc = 79.91%, Spikes = 0.0789\n",
            "Epoch 9, Batch 1130: Loss = 0.8318, Acc = 79.95%, Spikes = 0.0776\n",
            "Epoch 9, Batch 1140: Loss = 0.8683, Acc = 79.92%, Spikes = 0.0747\n",
            "Epoch 9, Batch 1150: Loss = 0.5753, Acc = 79.90%, Spikes = 0.0787\n",
            "Epoch 9, Batch 1160: Loss = 0.5807, Acc = 79.88%, Spikes = 0.0806\n",
            "Epoch 9, Batch 1170: Loss = 0.5635, Acc = 79.88%, Spikes = 0.0757\n",
            "Epoch 9, Batch 1180: Loss = 0.4980, Acc = 79.88%, Spikes = 0.0739\n",
            "Epoch 9, Batch 1190: Loss = 0.3572, Acc = 79.86%, Spikes = 0.0810\n",
            "Epoch 9, Batch 1200: Loss = 0.5856, Acc = 79.85%, Spikes = 0.0819\n",
            "Epoch 9, Batch 1210: Loss = 0.8437, Acc = 79.84%, Spikes = 0.0744\n",
            "Epoch 9, Batch 1220: Loss = 0.3088, Acc = 79.83%, Spikes = 0.0756\n",
            "Epoch 9, Batch 1230: Loss = 0.5968, Acc = 79.83%, Spikes = 0.0754\n",
            "Epoch 9, Batch 1240: Loss = 0.8521, Acc = 79.80%, Spikes = 0.0765\n",
            "Epoch 9, Batch 1250: Loss = 0.5149, Acc = 79.80%, Spikes = 0.0769\n",
            "Epoch 9, Batch 1260: Loss = 0.5565, Acc = 79.81%, Spikes = 0.0759\n",
            "Epoch 9, Batch 1270: Loss = 0.5947, Acc = 79.83%, Spikes = 0.0823\n",
            "Epoch 9, Batch 1280: Loss = 0.4618, Acc = 79.85%, Spikes = 0.0827\n",
            "Epoch 9, Batch 1290: Loss = 0.6034, Acc = 79.86%, Spikes = 0.0788\n",
            "Epoch 9, Batch 1300: Loss = 0.4478, Acc = 79.87%, Spikes = 0.0747\n",
            "Epoch 9, Batch 1310: Loss = 0.6930, Acc = 79.86%, Spikes = 0.0790\n",
            "Epoch 9, Batch 1320: Loss = 0.6024, Acc = 79.85%, Spikes = 0.0753\n",
            "Epoch 9, Batch 1330: Loss = 0.4798, Acc = 79.85%, Spikes = 0.0775\n",
            "Epoch 9, Batch 1340: Loss = 0.5590, Acc = 79.84%, Spikes = 0.0809\n",
            "Epoch 9, Batch 1350: Loss = 0.7813, Acc = 79.83%, Spikes = 0.0744\n",
            "Epoch 9, Batch 1360: Loss = 0.6853, Acc = 79.85%, Spikes = 0.0773\n",
            "Epoch 9, Batch 1370: Loss = 0.3768, Acc = 79.84%, Spikes = 0.0787\n",
            "Epoch 9, Batch 1380: Loss = 0.8871, Acc = 79.84%, Spikes = 0.0828\n",
            "Epoch 9, Batch 1390: Loss = 0.4868, Acc = 79.83%, Spikes = 0.0759\n",
            "Epoch 9, Batch 1400: Loss = 0.2623, Acc = 79.86%, Spikes = 0.0814\n",
            "Epoch 9, Batch 1410: Loss = 0.8410, Acc = 79.84%, Spikes = 0.0835\n",
            "Epoch 9, Batch 1420: Loss = 0.7331, Acc = 79.84%, Spikes = 0.0750\n",
            "Epoch 9, Batch 1430: Loss = 0.6826, Acc = 79.85%, Spikes = 0.0719\n",
            "Epoch 9, Batch 1440: Loss = 0.5154, Acc = 79.86%, Spikes = 0.0776\n",
            "Epoch 9, Batch 1450: Loss = 0.4092, Acc = 79.89%, Spikes = 0.0869\n",
            "Epoch 9, Batch 1460: Loss = 0.5724, Acc = 79.88%, Spikes = 0.0802\n",
            "Epoch 9, Batch 1470: Loss = 0.5425, Acc = 79.89%, Spikes = 0.0769\n",
            "Epoch 9, Batch 1480: Loss = 0.4516, Acc = 79.90%, Spikes = 0.0799\n",
            "Epoch 9, Batch 1490: Loss = 0.5675, Acc = 79.91%, Spikes = 0.0797\n",
            "Epoch 9, Batch 1500: Loss = 0.3774, Acc = 79.91%, Spikes = 0.0783\n",
            "Epoch 9, Batch 1510: Loss = 0.8508, Acc = 79.91%, Spikes = 0.0788\n",
            "Epoch 9, Batch 1520: Loss = 0.4066, Acc = 79.94%, Spikes = 0.0823\n",
            "Epoch 9, Batch 1530: Loss = 0.8204, Acc = 79.92%, Spikes = 0.0792\n",
            "Epoch 9, Batch 1540: Loss = 0.6796, Acc = 79.92%, Spikes = 0.0764\n",
            "Epoch 9, Batch 1550: Loss = 0.5072, Acc = 79.92%, Spikes = 0.0805\n",
            "Epoch 9, Batch 1560: Loss = 1.0281, Acc = 79.92%, Spikes = 0.0813\n",
            "Epoch 9, Batch 1570: Loss = 0.5825, Acc = 79.93%, Spikes = 0.0787\n",
            "Epoch 9, Batch 1580: Loss = 0.5328, Acc = 79.95%, Spikes = 0.0779\n",
            "Epoch 9, Batch 1590: Loss = 0.6015, Acc = 79.94%, Spikes = 0.0748\n",
            "Epoch 9, Batch 1600: Loss = 0.4893, Acc = 79.95%, Spikes = 0.0836\n",
            "Epoch 9, Batch 1610: Loss = 0.8251, Acc = 79.96%, Spikes = 0.0826\n",
            "Epoch 9, Batch 1620: Loss = 0.5209, Acc = 79.94%, Spikes = 0.0833\n",
            "Epoch 9, Batch 1630: Loss = 0.3554, Acc = 79.93%, Spikes = 0.0845\n",
            "Epoch 9, Batch 1640: Loss = 0.7149, Acc = 79.97%, Spikes = 0.0736\n",
            "Epoch 9, Batch 1650: Loss = 0.5847, Acc = 79.97%, Spikes = 0.0805\n",
            "Epoch 9, Batch 1660: Loss = 0.5939, Acc = 79.98%, Spikes = 0.0800\n",
            "Epoch 9, Batch 1670: Loss = 0.5201, Acc = 79.99%, Spikes = 0.0839\n",
            "Epoch 9, Batch 1680: Loss = 0.6404, Acc = 79.98%, Spikes = 0.0812\n",
            "Epoch 9, Batch 1690: Loss = 0.4982, Acc = 80.00%, Spikes = 0.0787\n",
            "Epoch 9, Batch 1700: Loss = 0.8270, Acc = 79.99%, Spikes = 0.0756\n",
            "Epoch 9, Batch 1710: Loss = 0.6725, Acc = 79.99%, Spikes = 0.0763\n",
            "Epoch 9, Batch 1720: Loss = 0.8457, Acc = 79.98%, Spikes = 0.0764\n",
            "Epoch 9, Batch 1730: Loss = 0.6638, Acc = 79.98%, Spikes = 0.0774\n",
            "Epoch 9, Batch 1740: Loss = 0.6083, Acc = 79.99%, Spikes = 0.0781\n",
            "Epoch 9, Batch 1750: Loss = 0.7936, Acc = 79.99%, Spikes = 0.0786\n",
            "Epoch 9, Batch 1760: Loss = 0.8261, Acc = 80.00%, Spikes = 0.0827\n",
            "Epoch 9, Batch 1770: Loss = 0.3419, Acc = 80.02%, Spikes = 0.0792\n",
            "Epoch 9, Batch 1780: Loss = 0.9048, Acc = 80.03%, Spikes = 0.0728\n",
            "Epoch 9, Batch 1790: Loss = 0.4055, Acc = 80.01%, Spikes = 0.0791\n",
            "Epoch 9, Batch 1800: Loss = 0.6680, Acc = 80.00%, Spikes = 0.0761\n",
            "Epoch 9, Batch 1810: Loss = 0.7879, Acc = 79.99%, Spikes = 0.0744\n",
            "Epoch 9, Batch 1820: Loss = 0.6083, Acc = 80.00%, Spikes = 0.0767\n",
            "Epoch 9, Batch 1830: Loss = 0.5652, Acc = 80.00%, Spikes = 0.0795\n",
            "Epoch 9, Batch 1840: Loss = 0.8692, Acc = 79.99%, Spikes = 0.0811\n",
            "Epoch 9, Batch 1850: Loss = 0.9718, Acc = 79.98%, Spikes = 0.0838\n",
            "Epoch 9, Batch 1860: Loss = 0.3980, Acc = 79.99%, Spikes = 0.0779\n",
            "Epoch 9, Batch 1870: Loss = 0.5679, Acc = 79.98%, Spikes = 0.0786\n",
            "Epoch 9/15:\n",
            "Train Loss: 0.6277 | Train Acc: 79.97% | Train Spikes: 0.0756\n",
            "Test Acc: 81.15% | Test Spikes: 0.0818\n",
            "------------------------------------------------------------\n",
            "Epoch 10, Batch 0: Loss = 0.6531, Acc = 81.25%, Spikes = 0.0733\n",
            "Epoch 10, Batch 10: Loss = 0.4812, Acc = 80.68%, Spikes = 0.0809\n",
            "Epoch 10, Batch 20: Loss = 0.9988, Acc = 79.02%, Spikes = 0.0792\n",
            "Epoch 10, Batch 30: Loss = 0.4600, Acc = 79.84%, Spikes = 0.0867\n",
            "Epoch 10, Batch 40: Loss = 0.9952, Acc = 79.73%, Spikes = 0.0807\n",
            "Epoch 10, Batch 50: Loss = 0.6749, Acc = 80.27%, Spikes = 0.0806\n",
            "Epoch 10, Batch 60: Loss = 0.5453, Acc = 80.02%, Spikes = 0.0857\n",
            "Epoch 10, Batch 70: Loss = 0.8676, Acc = 79.97%, Spikes = 0.0769\n",
            "Epoch 10, Batch 80: Loss = 0.8064, Acc = 79.98%, Spikes = 0.0772\n",
            "Epoch 10, Batch 90: Loss = 0.4509, Acc = 80.08%, Spikes = 0.0794\n",
            "Epoch 10, Batch 100: Loss = 0.4182, Acc = 79.95%, Spikes = 0.0838\n",
            "Epoch 10, Batch 110: Loss = 0.6678, Acc = 79.98%, Spikes = 0.0835\n",
            "Epoch 10, Batch 120: Loss = 0.4408, Acc = 80.09%, Spikes = 0.0911\n",
            "Epoch 10, Batch 130: Loss = 0.6384, Acc = 79.96%, Spikes = 0.0811\n",
            "Epoch 10, Batch 140: Loss = 0.6991, Acc = 79.83%, Spikes = 0.0789\n",
            "Epoch 10, Batch 150: Loss = 0.7208, Acc = 79.76%, Spikes = 0.0841\n",
            "Epoch 10, Batch 160: Loss = 0.7247, Acc = 79.81%, Spikes = 0.0798\n",
            "Epoch 10, Batch 170: Loss = 0.6463, Acc = 79.88%, Spikes = 0.0832\n",
            "Epoch 10, Batch 180: Loss = 0.5221, Acc = 80.11%, Spikes = 0.0825\n",
            "Epoch 10, Batch 190: Loss = 0.4726, Acc = 80.32%, Spikes = 0.0811\n",
            "Epoch 10, Batch 200: Loss = 0.4221, Acc = 80.35%, Spikes = 0.0853\n",
            "Epoch 10, Batch 210: Loss = 0.6591, Acc = 80.39%, Spikes = 0.0806\n",
            "Epoch 10, Batch 220: Loss = 0.4280, Acc = 80.46%, Spikes = 0.0791\n",
            "Epoch 10, Batch 230: Loss = 0.6391, Acc = 80.48%, Spikes = 0.0835\n",
            "Epoch 10, Batch 240: Loss = 0.4442, Acc = 80.50%, Spikes = 0.0826\n",
            "Epoch 10, Batch 250: Loss = 0.5611, Acc = 80.55%, Spikes = 0.0809\n",
            "Epoch 10, Batch 260: Loss = 1.0665, Acc = 80.38%, Spikes = 0.0779\n",
            "Epoch 10, Batch 270: Loss = 0.6510, Acc = 80.41%, Spikes = 0.0841\n",
            "Epoch 10, Batch 280: Loss = 0.4156, Acc = 80.57%, Spikes = 0.0883\n",
            "Epoch 10, Batch 290: Loss = 0.7097, Acc = 80.53%, Spikes = 0.0815\n",
            "Epoch 10, Batch 300: Loss = 0.6031, Acc = 80.54%, Spikes = 0.0864\n",
            "Epoch 10, Batch 310: Loss = 0.8448, Acc = 80.40%, Spikes = 0.0829\n",
            "Epoch 10, Batch 320: Loss = 0.6227, Acc = 80.25%, Spikes = 0.0832\n",
            "Epoch 10, Batch 330: Loss = 0.5198, Acc = 80.40%, Spikes = 0.0842\n",
            "Epoch 10, Batch 340: Loss = 0.5346, Acc = 80.46%, Spikes = 0.0830\n",
            "Epoch 10, Batch 350: Loss = 0.3860, Acc = 80.57%, Spikes = 0.0791\n",
            "Epoch 10, Batch 360: Loss = 0.4247, Acc = 80.51%, Spikes = 0.0819\n",
            "Epoch 10, Batch 370: Loss = 0.5883, Acc = 80.59%, Spikes = 0.0820\n",
            "Epoch 10, Batch 380: Loss = 0.7868, Acc = 80.66%, Spikes = 0.0822\n",
            "Epoch 10, Batch 390: Loss = 0.6521, Acc = 80.54%, Spikes = 0.0837\n",
            "Epoch 10, Batch 400: Loss = 0.7500, Acc = 80.51%, Spikes = 0.0826\n",
            "Epoch 10, Batch 410: Loss = 0.5303, Acc = 80.50%, Spikes = 0.0840\n",
            "Epoch 10, Batch 420: Loss = 0.3881, Acc = 80.56%, Spikes = 0.0843\n",
            "Epoch 10, Batch 430: Loss = 0.7585, Acc = 80.55%, Spikes = 0.0791\n",
            "Epoch 10, Batch 440: Loss = 0.3187, Acc = 80.63%, Spikes = 0.0843\n",
            "Epoch 10, Batch 450: Loss = 0.8341, Acc = 80.57%, Spikes = 0.0800\n",
            "Epoch 10, Batch 460: Loss = 0.4822, Acc = 80.63%, Spikes = 0.0849\n",
            "Epoch 10, Batch 470: Loss = 0.3515, Acc = 80.60%, Spikes = 0.0839\n",
            "Epoch 10, Batch 480: Loss = 0.5992, Acc = 80.57%, Spikes = 0.0811\n",
            "Epoch 10, Batch 490: Loss = 0.5847, Acc = 80.59%, Spikes = 0.0839\n",
            "Epoch 10, Batch 500: Loss = 0.3581, Acc = 80.61%, Spikes = 0.0864\n",
            "Epoch 10, Batch 510: Loss = 0.6841, Acc = 80.57%, Spikes = 0.0843\n",
            "Epoch 10, Batch 520: Loss = 0.6437, Acc = 80.61%, Spikes = 0.0816\n",
            "Epoch 10, Batch 530: Loss = 0.6538, Acc = 80.62%, Spikes = 0.0775\n",
            "Epoch 10, Batch 540: Loss = 0.7237, Acc = 80.63%, Spikes = 0.0825\n",
            "Epoch 10, Batch 550: Loss = 0.4476, Acc = 80.61%, Spikes = 0.0764\n",
            "Epoch 10, Batch 560: Loss = 0.4319, Acc = 80.67%, Spikes = 0.0834\n",
            "Epoch 10, Batch 570: Loss = 0.7664, Acc = 80.65%, Spikes = 0.0794\n",
            "Epoch 10, Batch 580: Loss = 0.4476, Acc = 80.66%, Spikes = 0.0848\n",
            "Epoch 10, Batch 590: Loss = 0.4892, Acc = 80.62%, Spikes = 0.0870\n",
            "Epoch 10, Batch 600: Loss = 0.5217, Acc = 80.61%, Spikes = 0.0767\n",
            "Epoch 10, Batch 610: Loss = 0.5697, Acc = 80.57%, Spikes = 0.0836\n",
            "Epoch 10, Batch 620: Loss = 0.4996, Acc = 80.55%, Spikes = 0.0832\n",
            "Epoch 10, Batch 630: Loss = 0.8167, Acc = 80.45%, Spikes = 0.0879\n",
            "Epoch 10, Batch 640: Loss = 0.6068, Acc = 80.45%, Spikes = 0.0759\n",
            "Epoch 10, Batch 650: Loss = 0.3316, Acc = 80.41%, Spikes = 0.0824\n",
            "Epoch 10, Batch 660: Loss = 0.5168, Acc = 80.36%, Spikes = 0.0819\n",
            "Epoch 10, Batch 670: Loss = 0.7388, Acc = 80.32%, Spikes = 0.0792\n",
            "Epoch 10, Batch 680: Loss = 0.5264, Acc = 80.30%, Spikes = 0.0786\n",
            "Epoch 10, Batch 690: Loss = 0.3348, Acc = 80.35%, Spikes = 0.0847\n",
            "Epoch 10, Batch 700: Loss = 0.4550, Acc = 80.32%, Spikes = 0.0812\n",
            "Epoch 10, Batch 710: Loss = 0.4433, Acc = 80.40%, Spikes = 0.0811\n",
            "Epoch 10, Batch 720: Loss = 0.6706, Acc = 80.34%, Spikes = 0.0843\n",
            "Epoch 10, Batch 730: Loss = 0.3982, Acc = 80.39%, Spikes = 0.0817\n",
            "Epoch 10, Batch 740: Loss = 0.3122, Acc = 80.39%, Spikes = 0.0842\n",
            "Epoch 10, Batch 750: Loss = 0.6930, Acc = 80.45%, Spikes = 0.0778\n",
            "Epoch 10, Batch 760: Loss = 0.7475, Acc = 80.44%, Spikes = 0.0812\n",
            "Epoch 10, Batch 770: Loss = 0.8724, Acc = 80.43%, Spikes = 0.0817\n",
            "Epoch 10, Batch 780: Loss = 0.4885, Acc = 80.44%, Spikes = 0.0775\n",
            "Epoch 10, Batch 790: Loss = 0.4490, Acc = 80.44%, Spikes = 0.0820\n",
            "Epoch 10, Batch 800: Loss = 0.8183, Acc = 80.39%, Spikes = 0.0751\n",
            "Epoch 10, Batch 810: Loss = 0.5457, Acc = 80.37%, Spikes = 0.0798\n",
            "Epoch 10, Batch 820: Loss = 0.6031, Acc = 80.41%, Spikes = 0.0811\n",
            "Epoch 10, Batch 830: Loss = 0.6189, Acc = 80.42%, Spikes = 0.0861\n",
            "Epoch 10, Batch 840: Loss = 0.3507, Acc = 80.42%, Spikes = 0.0790\n",
            "Epoch 10, Batch 850: Loss = 0.5618, Acc = 80.42%, Spikes = 0.0850\n",
            "Epoch 10, Batch 860: Loss = 0.5235, Acc = 80.44%, Spikes = 0.0851\n",
            "Epoch 10, Batch 870: Loss = 0.4301, Acc = 80.39%, Spikes = 0.0818\n",
            "Epoch 10, Batch 880: Loss = 0.4766, Acc = 80.41%, Spikes = 0.0876\n",
            "Epoch 10, Batch 890: Loss = 0.8526, Acc = 80.42%, Spikes = 0.0875\n",
            "Epoch 10, Batch 900: Loss = 0.4473, Acc = 80.41%, Spikes = 0.0819\n",
            "Epoch 10, Batch 910: Loss = 0.8968, Acc = 80.45%, Spikes = 0.0822\n",
            "Epoch 10, Batch 920: Loss = 0.6027, Acc = 80.46%, Spikes = 0.0894\n",
            "Epoch 10, Batch 930: Loss = 0.7079, Acc = 80.45%, Spikes = 0.0809\n",
            "Epoch 10, Batch 940: Loss = 0.7345, Acc = 80.44%, Spikes = 0.0734\n",
            "Epoch 10, Batch 950: Loss = 0.5676, Acc = 80.46%, Spikes = 0.0832\n",
            "Epoch 10, Batch 960: Loss = 1.2917, Acc = 80.44%, Spikes = 0.0785\n",
            "Epoch 10, Batch 970: Loss = 0.6324, Acc = 80.42%, Spikes = 0.0816\n",
            "Epoch 10, Batch 980: Loss = 0.4487, Acc = 80.43%, Spikes = 0.0846\n",
            "Epoch 10, Batch 990: Loss = 0.5810, Acc = 80.45%, Spikes = 0.0817\n",
            "Epoch 10, Batch 1000: Loss = 0.5452, Acc = 80.43%, Spikes = 0.0838\n",
            "Epoch 10, Batch 1010: Loss = 0.5237, Acc = 80.43%, Spikes = 0.0875\n",
            "Epoch 10, Batch 1020: Loss = 0.4520, Acc = 80.45%, Spikes = 0.0866\n",
            "Epoch 10, Batch 1030: Loss = 0.5935, Acc = 80.45%, Spikes = 0.0838\n",
            "Epoch 10, Batch 1040: Loss = 0.8999, Acc = 80.46%, Spikes = 0.0754\n",
            "Epoch 10, Batch 1050: Loss = 0.8750, Acc = 80.41%, Spikes = 0.0888\n",
            "Epoch 10, Batch 1060: Loss = 0.8226, Acc = 80.42%, Spikes = 0.0833\n",
            "Epoch 10, Batch 1070: Loss = 0.4945, Acc = 80.43%, Spikes = 0.0844\n",
            "Epoch 10, Batch 1080: Loss = 1.1567, Acc = 80.42%, Spikes = 0.0848\n",
            "Epoch 10, Batch 1090: Loss = 0.5366, Acc = 80.41%, Spikes = 0.0828\n",
            "Epoch 10, Batch 1100: Loss = 0.6255, Acc = 80.39%, Spikes = 0.0786\n",
            "Epoch 10, Batch 1110: Loss = 0.7169, Acc = 80.41%, Spikes = 0.0831\n",
            "Epoch 10, Batch 1120: Loss = 0.4259, Acc = 80.42%, Spikes = 0.0866\n",
            "Epoch 10, Batch 1130: Loss = 0.5096, Acc = 80.45%, Spikes = 0.0840\n",
            "Epoch 10, Batch 1140: Loss = 0.2433, Acc = 80.44%, Spikes = 0.0866\n",
            "Epoch 10, Batch 1150: Loss = 0.6427, Acc = 80.42%, Spikes = 0.0854\n",
            "Epoch 10, Batch 1160: Loss = 0.3699, Acc = 80.41%, Spikes = 0.0834\n",
            "Epoch 10, Batch 1170: Loss = 0.7106, Acc = 80.36%, Spikes = 0.0845\n",
            "Epoch 10, Batch 1180: Loss = 0.2743, Acc = 80.37%, Spikes = 0.0874\n",
            "Epoch 10, Batch 1190: Loss = 0.6212, Acc = 80.39%, Spikes = 0.0823\n",
            "Epoch 10, Batch 1200: Loss = 0.2732, Acc = 80.42%, Spikes = 0.0878\n",
            "Epoch 10, Batch 1210: Loss = 0.8136, Acc = 80.42%, Spikes = 0.0838\n",
            "Epoch 10, Batch 1220: Loss = 1.0464, Acc = 80.42%, Spikes = 0.0850\n",
            "Epoch 10, Batch 1230: Loss = 0.7406, Acc = 80.44%, Spikes = 0.0848\n",
            "Epoch 10, Batch 1240: Loss = 0.6779, Acc = 80.44%, Spikes = 0.0849\n",
            "Epoch 10, Batch 1250: Loss = 0.7568, Acc = 80.45%, Spikes = 0.0823\n",
            "Epoch 10, Batch 1260: Loss = 0.3701, Acc = 80.46%, Spikes = 0.0795\n",
            "Epoch 10, Batch 1270: Loss = 0.6496, Acc = 80.43%, Spikes = 0.0854\n",
            "Epoch 10, Batch 1280: Loss = 0.6579, Acc = 80.42%, Spikes = 0.0823\n",
            "Epoch 10, Batch 1290: Loss = 0.5706, Acc = 80.41%, Spikes = 0.0851\n",
            "Epoch 10, Batch 1300: Loss = 0.4393, Acc = 80.42%, Spikes = 0.0887\n",
            "Epoch 10, Batch 1310: Loss = 0.6780, Acc = 80.44%, Spikes = 0.0877\n",
            "Epoch 10, Batch 1320: Loss = 1.2283, Acc = 80.45%, Spikes = 0.0855\n",
            "Epoch 10, Batch 1330: Loss = 0.4302, Acc = 80.43%, Spikes = 0.0816\n",
            "Epoch 10, Batch 1340: Loss = 0.5870, Acc = 80.46%, Spikes = 0.0851\n",
            "Epoch 10, Batch 1350: Loss = 1.0132, Acc = 80.45%, Spikes = 0.0884\n",
            "Epoch 10, Batch 1360: Loss = 0.7580, Acc = 80.44%, Spikes = 0.0817\n",
            "Epoch 10, Batch 1370: Loss = 0.3883, Acc = 80.46%, Spikes = 0.0799\n",
            "Epoch 10, Batch 1380: Loss = 0.4625, Acc = 80.46%, Spikes = 0.0812\n",
            "Epoch 10, Batch 1390: Loss = 0.4471, Acc = 80.48%, Spikes = 0.0799\n",
            "Epoch 10, Batch 1400: Loss = 0.6567, Acc = 80.48%, Spikes = 0.0842\n",
            "Epoch 10, Batch 1410: Loss = 1.1910, Acc = 80.49%, Spikes = 0.0812\n",
            "Epoch 10, Batch 1420: Loss = 0.7816, Acc = 80.50%, Spikes = 0.0820\n",
            "Epoch 10, Batch 1430: Loss = 0.6963, Acc = 80.49%, Spikes = 0.0855\n",
            "Epoch 10, Batch 1440: Loss = 0.5759, Acc = 80.48%, Spikes = 0.0807\n",
            "Epoch 10, Batch 1450: Loss = 0.4004, Acc = 80.47%, Spikes = 0.0853\n",
            "Epoch 10, Batch 1460: Loss = 0.7258, Acc = 80.45%, Spikes = 0.0760\n",
            "Epoch 10, Batch 1470: Loss = 0.6839, Acc = 80.45%, Spikes = 0.0832\n",
            "Epoch 10, Batch 1480: Loss = 0.3473, Acc = 80.45%, Spikes = 0.0857\n",
            "Epoch 10, Batch 1490: Loss = 0.9712, Acc = 80.43%, Spikes = 0.0849\n",
            "Epoch 10, Batch 1500: Loss = 0.4670, Acc = 80.46%, Spikes = 0.0833\n",
            "Epoch 10, Batch 1510: Loss = 0.4598, Acc = 80.48%, Spikes = 0.0873\n",
            "Epoch 10, Batch 1520: Loss = 0.3446, Acc = 80.49%, Spikes = 0.0893\n",
            "Epoch 10, Batch 1530: Loss = 0.6172, Acc = 80.48%, Spikes = 0.0821\n",
            "Epoch 10, Batch 1540: Loss = 0.6466, Acc = 80.46%, Spikes = 0.0839\n",
            "Epoch 10, Batch 1550: Loss = 0.7119, Acc = 80.48%, Spikes = 0.0774\n",
            "Epoch 10, Batch 1560: Loss = 0.7121, Acc = 80.49%, Spikes = 0.0866\n",
            "Epoch 10, Batch 1570: Loss = 0.6295, Acc = 80.46%, Spikes = 0.0835\n",
            "Epoch 10, Batch 1580: Loss = 0.3202, Acc = 80.47%, Spikes = 0.0864\n",
            "Epoch 10, Batch 1590: Loss = 0.7813, Acc = 80.49%, Spikes = 0.0840\n",
            "Epoch 10, Batch 1600: Loss = 0.5275, Acc = 80.49%, Spikes = 0.0765\n",
            "Epoch 10, Batch 1610: Loss = 0.8425, Acc = 80.48%, Spikes = 0.0848\n",
            "Epoch 10, Batch 1620: Loss = 0.5351, Acc = 80.47%, Spikes = 0.0799\n",
            "Epoch 10, Batch 1630: Loss = 0.9525, Acc = 80.47%, Spikes = 0.0755\n",
            "Epoch 10, Batch 1640: Loss = 0.5758, Acc = 80.48%, Spikes = 0.0811\n",
            "Epoch 10, Batch 1650: Loss = 0.7112, Acc = 80.43%, Spikes = 0.0839\n",
            "Epoch 10, Batch 1660: Loss = 0.5052, Acc = 80.44%, Spikes = 0.0864\n",
            "Epoch 10, Batch 1670: Loss = 0.6322, Acc = 80.45%, Spikes = 0.0807\n",
            "Epoch 10, Batch 1680: Loss = 0.5787, Acc = 80.45%, Spikes = 0.0851\n",
            "Epoch 10, Batch 1690: Loss = 0.4185, Acc = 80.46%, Spikes = 0.0821\n",
            "Epoch 10, Batch 1700: Loss = 0.7064, Acc = 80.45%, Spikes = 0.0858\n",
            "Epoch 10, Batch 1710: Loss = 0.8480, Acc = 80.47%, Spikes = 0.0818\n",
            "Epoch 10, Batch 1720: Loss = 0.7695, Acc = 80.45%, Spikes = 0.0840\n",
            "Epoch 10, Batch 1730: Loss = 0.7114, Acc = 80.44%, Spikes = 0.0783\n",
            "Epoch 10, Batch 1740: Loss = 0.3480, Acc = 80.44%, Spikes = 0.0848\n",
            "Epoch 10, Batch 1750: Loss = 0.3748, Acc = 80.44%, Spikes = 0.0960\n",
            "Epoch 10, Batch 1760: Loss = 0.5716, Acc = 80.44%, Spikes = 0.0821\n",
            "Epoch 10, Batch 1770: Loss = 1.1443, Acc = 80.43%, Spikes = 0.0883\n",
            "Epoch 10, Batch 1780: Loss = 0.6700, Acc = 80.43%, Spikes = 0.0822\n",
            "Epoch 10, Batch 1790: Loss = 0.4771, Acc = 80.44%, Spikes = 0.0896\n",
            "Epoch 10, Batch 1800: Loss = 0.5233, Acc = 80.45%, Spikes = 0.0846\n",
            "Epoch 10, Batch 1810: Loss = 0.6018, Acc = 80.45%, Spikes = 0.0851\n",
            "Epoch 10, Batch 1820: Loss = 0.7566, Acc = 80.45%, Spikes = 0.0794\n",
            "Epoch 10, Batch 1830: Loss = 0.3760, Acc = 80.44%, Spikes = 0.0902\n",
            "Epoch 10, Batch 1840: Loss = 0.4034, Acc = 80.44%, Spikes = 0.0846\n",
            "Epoch 10, Batch 1850: Loss = 0.6779, Acc = 80.44%, Spikes = 0.0849\n",
            "Epoch 10, Batch 1860: Loss = 0.7225, Acc = 80.43%, Spikes = 0.0877\n",
            "Epoch 10, Batch 1870: Loss = 1.0142, Acc = 80.42%, Spikes = 0.0836\n",
            "Epoch 10/15:\n",
            "Train Loss: 0.6137 | Train Acc: 80.40% | Train Spikes: 0.0831\n",
            "Test Acc: 80.97% | Test Spikes: 0.0862\n",
            "------------------------------------------------------------\n",
            "Epoch 11, Batch 0: Loss = 0.4992, Acc = 81.25%, Spikes = 0.0882\n",
            "Epoch 11, Batch 10: Loss = 0.7263, Acc = 81.53%, Spikes = 0.0793\n",
            "Epoch 11, Batch 20: Loss = 0.5318, Acc = 82.89%, Spikes = 0.0812\n",
            "Epoch 11, Batch 30: Loss = 0.9340, Acc = 82.86%, Spikes = 0.0830\n",
            "Epoch 11, Batch 40: Loss = 0.4251, Acc = 82.47%, Spikes = 0.0889\n",
            "Epoch 11, Batch 50: Loss = 0.6354, Acc = 82.23%, Spikes = 0.0806\n",
            "Epoch 11, Batch 60: Loss = 0.8446, Acc = 82.58%, Spikes = 0.0820\n",
            "Epoch 11, Batch 70: Loss = 0.4767, Acc = 82.09%, Spikes = 0.0879\n",
            "Epoch 11, Batch 80: Loss = 0.6210, Acc = 81.52%, Spikes = 0.0801\n",
            "Epoch 11, Batch 90: Loss = 0.7822, Acc = 81.22%, Spikes = 0.0788\n",
            "Epoch 11, Batch 100: Loss = 1.0736, Acc = 81.06%, Spikes = 0.0848\n",
            "Epoch 11, Batch 110: Loss = 0.8042, Acc = 80.69%, Spikes = 0.0858\n",
            "Epoch 11, Batch 120: Loss = 0.5667, Acc = 80.42%, Spikes = 0.0847\n",
            "Epoch 11, Batch 130: Loss = 0.9036, Acc = 80.30%, Spikes = 0.0828\n",
            "Epoch 11, Batch 140: Loss = 0.7811, Acc = 80.03%, Spikes = 0.0866\n",
            "Epoch 11, Batch 150: Loss = 0.7844, Acc = 79.80%, Spikes = 0.0883\n",
            "Epoch 11, Batch 160: Loss = 0.6150, Acc = 79.70%, Spikes = 0.0859\n",
            "Epoch 11, Batch 170: Loss = 0.6703, Acc = 79.70%, Spikes = 0.0855\n",
            "Epoch 11, Batch 180: Loss = 0.5213, Acc = 79.64%, Spikes = 0.0881\n",
            "Epoch 11, Batch 190: Loss = 0.2595, Acc = 79.70%, Spikes = 0.0915\n",
            "Epoch 11, Batch 200: Loss = 0.4396, Acc = 79.57%, Spikes = 0.0861\n",
            "Epoch 11, Batch 210: Loss = 0.9339, Acc = 79.71%, Spikes = 0.0786\n",
            "Epoch 11, Batch 220: Loss = 0.4825, Acc = 79.84%, Spikes = 0.0796\n",
            "Epoch 11, Batch 230: Loss = 0.5495, Acc = 79.79%, Spikes = 0.0813\n",
            "Epoch 11, Batch 240: Loss = 0.7134, Acc = 79.85%, Spikes = 0.0855\n",
            "Epoch 11, Batch 250: Loss = 0.6532, Acc = 79.81%, Spikes = 0.0918\n",
            "Epoch 11, Batch 260: Loss = 0.8492, Acc = 79.68%, Spikes = 0.0839\n",
            "Epoch 11, Batch 270: Loss = 0.6503, Acc = 79.68%, Spikes = 0.0899\n",
            "Epoch 11, Batch 280: Loss = 0.6085, Acc = 79.79%, Spikes = 0.0835\n",
            "Epoch 11, Batch 290: Loss = 0.6391, Acc = 79.83%, Spikes = 0.0860\n",
            "Epoch 11, Batch 300: Loss = 0.3822, Acc = 79.97%, Spikes = 0.0834\n",
            "Epoch 11, Batch 310: Loss = 0.6799, Acc = 80.00%, Spikes = 0.0830\n",
            "Epoch 11, Batch 320: Loss = 0.5036, Acc = 80.13%, Spikes = 0.0821\n",
            "Epoch 11, Batch 330: Loss = 0.8557, Acc = 80.16%, Spikes = 0.0857\n",
            "Epoch 11, Batch 340: Loss = 0.2543, Acc = 80.26%, Spikes = 0.0863\n",
            "Epoch 11, Batch 350: Loss = 0.5236, Acc = 80.34%, Spikes = 0.0867\n",
            "Epoch 11, Batch 360: Loss = 0.8644, Acc = 80.36%, Spikes = 0.0839\n",
            "Epoch 11, Batch 370: Loss = 0.4722, Acc = 80.30%, Spikes = 0.0887\n",
            "Epoch 11, Batch 380: Loss = 0.6715, Acc = 80.40%, Spikes = 0.0893\n",
            "Epoch 11, Batch 390: Loss = 0.3867, Acc = 80.31%, Spikes = 0.0837\n",
            "Epoch 11, Batch 400: Loss = 0.5533, Acc = 80.29%, Spikes = 0.0873\n",
            "Epoch 11, Batch 410: Loss = 0.7076, Acc = 80.31%, Spikes = 0.0903\n",
            "Epoch 11, Batch 420: Loss = 0.4313, Acc = 80.37%, Spikes = 0.0868\n",
            "Epoch 11, Batch 430: Loss = 0.8384, Acc = 80.37%, Spikes = 0.0839\n",
            "Epoch 11, Batch 440: Loss = 0.3200, Acc = 80.38%, Spikes = 0.0921\n",
            "Epoch 11, Batch 450: Loss = 0.4957, Acc = 80.42%, Spikes = 0.0823\n",
            "Epoch 11, Batch 460: Loss = 0.7006, Acc = 80.41%, Spikes = 0.0823\n",
            "Epoch 11, Batch 470: Loss = 0.4613, Acc = 80.52%, Spikes = 0.0871\n",
            "Epoch 11, Batch 480: Loss = 0.8319, Acc = 80.52%, Spikes = 0.0801\n",
            "Epoch 11, Batch 490: Loss = 0.6647, Acc = 80.47%, Spikes = 0.0881\n",
            "Epoch 11, Batch 500: Loss = 0.2183, Acc = 80.44%, Spikes = 0.0895\n",
            "Epoch 11, Batch 510: Loss = 0.6840, Acc = 80.34%, Spikes = 0.0859\n",
            "Epoch 11, Batch 520: Loss = 0.4324, Acc = 80.42%, Spikes = 0.0863\n",
            "Epoch 11, Batch 530: Loss = 0.7332, Acc = 80.46%, Spikes = 0.0813\n",
            "Epoch 11, Batch 540: Loss = 0.8770, Acc = 80.44%, Spikes = 0.0811\n",
            "Epoch 11, Batch 550: Loss = 0.4623, Acc = 80.45%, Spikes = 0.0823\n",
            "Epoch 11, Batch 560: Loss = 0.3425, Acc = 80.43%, Spikes = 0.0862\n",
            "Epoch 11, Batch 570: Loss = 0.5974, Acc = 80.43%, Spikes = 0.0881\n",
            "Epoch 11, Batch 580: Loss = 0.4871, Acc = 80.45%, Spikes = 0.0892\n",
            "Epoch 11, Batch 590: Loss = 0.5855, Acc = 80.48%, Spikes = 0.0868\n",
            "Epoch 11, Batch 600: Loss = 0.5351, Acc = 80.44%, Spikes = 0.0849\n",
            "Epoch 11, Batch 610: Loss = 0.7511, Acc = 80.44%, Spikes = 0.0823\n",
            "Epoch 11, Batch 620: Loss = 0.6366, Acc = 80.48%, Spikes = 0.0891\n",
            "Epoch 11, Batch 630: Loss = 0.7989, Acc = 80.49%, Spikes = 0.0799\n",
            "Epoch 11, Batch 640: Loss = 0.3216, Acc = 80.51%, Spikes = 0.0893\n",
            "Epoch 11, Batch 650: Loss = 0.6132, Acc = 80.56%, Spikes = 0.0875\n",
            "Epoch 11, Batch 660: Loss = 0.5608, Acc = 80.56%, Spikes = 0.0876\n",
            "Epoch 11, Batch 670: Loss = 0.6973, Acc = 80.60%, Spikes = 0.0827\n",
            "Epoch 11, Batch 680: Loss = 0.4141, Acc = 80.54%, Spikes = 0.0899\n",
            "Epoch 11, Batch 690: Loss = 0.6475, Acc = 80.54%, Spikes = 0.0883\n",
            "Epoch 11, Batch 700: Loss = 0.6971, Acc = 80.50%, Spikes = 0.0877\n",
            "Epoch 11, Batch 710: Loss = 0.3303, Acc = 80.58%, Spikes = 0.0873\n",
            "Epoch 11, Batch 720: Loss = 0.6629, Acc = 80.57%, Spikes = 0.0784\n",
            "Epoch 11, Batch 730: Loss = 0.4932, Acc = 80.57%, Spikes = 0.0877\n",
            "Epoch 11, Batch 740: Loss = 0.6299, Acc = 80.53%, Spikes = 0.0815\n",
            "Epoch 11, Batch 750: Loss = 0.7620, Acc = 80.50%, Spikes = 0.0812\n",
            "Epoch 11, Batch 760: Loss = 0.5695, Acc = 80.51%, Spikes = 0.0843\n",
            "Epoch 11, Batch 770: Loss = 0.6030, Acc = 80.50%, Spikes = 0.0856\n",
            "Epoch 11, Batch 780: Loss = 0.8850, Acc = 80.47%, Spikes = 0.0831\n",
            "Epoch 11, Batch 790: Loss = 0.6960, Acc = 80.47%, Spikes = 0.0852\n",
            "Epoch 11, Batch 800: Loss = 0.4771, Acc = 80.41%, Spikes = 0.0927\n",
            "Epoch 11, Batch 810: Loss = 0.6503, Acc = 80.39%, Spikes = 0.0866\n",
            "Epoch 11, Batch 820: Loss = 0.6294, Acc = 80.40%, Spikes = 0.0872\n",
            "Epoch 11, Batch 830: Loss = 0.5068, Acc = 80.42%, Spikes = 0.0918\n",
            "Epoch 11, Batch 840: Loss = 0.8582, Acc = 80.38%, Spikes = 0.0853\n",
            "Epoch 11, Batch 850: Loss = 0.5644, Acc = 80.39%, Spikes = 0.0839\n",
            "Epoch 11, Batch 860: Loss = 0.6761, Acc = 80.37%, Spikes = 0.0888\n",
            "Epoch 11, Batch 870: Loss = 0.5222, Acc = 80.35%, Spikes = 0.0863\n",
            "Epoch 11, Batch 880: Loss = 0.7788, Acc = 80.36%, Spikes = 0.0834\n",
            "Epoch 11, Batch 890: Loss = 0.7956, Acc = 80.35%, Spikes = 0.0905\n",
            "Epoch 11, Batch 900: Loss = 0.2781, Acc = 80.34%, Spikes = 0.0891\n",
            "Epoch 11, Batch 910: Loss = 0.8133, Acc = 80.34%, Spikes = 0.0871\n",
            "Epoch 11, Batch 920: Loss = 0.5511, Acc = 80.34%, Spikes = 0.0865\n",
            "Epoch 11, Batch 930: Loss = 0.7841, Acc = 80.35%, Spikes = 0.0864\n",
            "Epoch 11, Batch 940: Loss = 0.3205, Acc = 80.32%, Spikes = 0.0893\n",
            "Epoch 11, Batch 950: Loss = 0.3873, Acc = 80.29%, Spikes = 0.0918\n",
            "Epoch 11, Batch 960: Loss = 0.4834, Acc = 80.31%, Spikes = 0.0891\n",
            "Epoch 11, Batch 970: Loss = 0.5784, Acc = 80.33%, Spikes = 0.0889\n",
            "Epoch 11, Batch 980: Loss = 0.9513, Acc = 80.32%, Spikes = 0.0883\n",
            "Epoch 11, Batch 990: Loss = 0.5719, Acc = 80.32%, Spikes = 0.0879\n",
            "Epoch 11, Batch 1000: Loss = 0.7383, Acc = 80.33%, Spikes = 0.0903\n",
            "Epoch 11, Batch 1010: Loss = 0.9736, Acc = 80.35%, Spikes = 0.0849\n",
            "Epoch 11, Batch 1020: Loss = 0.6403, Acc = 80.35%, Spikes = 0.0865\n",
            "Epoch 11, Batch 1030: Loss = 0.4325, Acc = 80.34%, Spikes = 0.0881\n",
            "Epoch 11, Batch 1040: Loss = 0.7106, Acc = 80.33%, Spikes = 0.0885\n",
            "Epoch 11, Batch 1050: Loss = 0.5376, Acc = 80.34%, Spikes = 0.0899\n",
            "Epoch 11, Batch 1060: Loss = 0.8918, Acc = 80.33%, Spikes = 0.0819\n",
            "Epoch 11, Batch 1070: Loss = 0.4897, Acc = 80.32%, Spikes = 0.0896\n",
            "Epoch 11, Batch 1080: Loss = 0.4830, Acc = 80.33%, Spikes = 0.0902\n",
            "Epoch 11, Batch 1090: Loss = 0.5865, Acc = 80.36%, Spikes = 0.0878\n",
            "Epoch 11, Batch 1100: Loss = 1.0078, Acc = 80.39%, Spikes = 0.0913\n",
            "Epoch 11, Batch 1110: Loss = 0.7602, Acc = 80.38%, Spikes = 0.0903\n",
            "Epoch 11, Batch 1120: Loss = 0.7303, Acc = 80.38%, Spikes = 0.0877\n",
            "Epoch 11, Batch 1130: Loss = 0.5944, Acc = 80.35%, Spikes = 0.0874\n",
            "Epoch 11, Batch 1140: Loss = 1.5920, Acc = 80.34%, Spikes = 0.0870\n",
            "Epoch 11, Batch 1150: Loss = 0.4999, Acc = 80.35%, Spikes = 0.0930\n",
            "Epoch 11, Batch 1160: Loss = 0.8213, Acc = 80.35%, Spikes = 0.0909\n",
            "Epoch 11, Batch 1170: Loss = 0.5947, Acc = 80.36%, Spikes = 0.0960\n",
            "Epoch 11, Batch 1180: Loss = 0.6688, Acc = 80.32%, Spikes = 0.0901\n",
            "Epoch 11, Batch 1190: Loss = 0.5225, Acc = 80.37%, Spikes = 0.0968\n",
            "Epoch 11, Batch 1200: Loss = 0.5595, Acc = 80.34%, Spikes = 0.0982\n",
            "Epoch 11, Batch 1210: Loss = 0.4218, Acc = 80.35%, Spikes = 0.0923\n",
            "Epoch 11, Batch 1220: Loss = 0.6048, Acc = 80.34%, Spikes = 0.0910\n",
            "Epoch 11, Batch 1230: Loss = 0.6556, Acc = 80.35%, Spikes = 0.0892\n",
            "Epoch 11, Batch 1240: Loss = 0.6127, Acc = 80.35%, Spikes = 0.0924\n",
            "Epoch 11, Batch 1250: Loss = 0.5419, Acc = 80.36%, Spikes = 0.0921\n",
            "Epoch 11, Batch 1260: Loss = 0.4204, Acc = 80.33%, Spikes = 0.0918\n",
            "Epoch 11, Batch 1270: Loss = 0.3966, Acc = 80.31%, Spikes = 0.0935\n",
            "Epoch 11, Batch 1280: Loss = 0.6775, Acc = 80.33%, Spikes = 0.0889\n",
            "Epoch 11, Batch 1290: Loss = 0.4758, Acc = 80.30%, Spikes = 0.0915\n",
            "Epoch 11, Batch 1300: Loss = 0.3446, Acc = 80.34%, Spikes = 0.0899\n",
            "Epoch 11, Batch 1310: Loss = 0.5988, Acc = 80.32%, Spikes = 0.0905\n",
            "Epoch 11, Batch 1320: Loss = 0.6366, Acc = 80.31%, Spikes = 0.0915\n",
            "Epoch 11, Batch 1330: Loss = 0.4392, Acc = 80.31%, Spikes = 0.0952\n",
            "Epoch 11, Batch 1340: Loss = 0.5176, Acc = 80.32%, Spikes = 0.0892\n",
            "Epoch 11, Batch 1350: Loss = 0.7136, Acc = 80.33%, Spikes = 0.0893\n",
            "Epoch 11, Batch 1360: Loss = 0.5699, Acc = 80.34%, Spikes = 0.0946\n",
            "Epoch 11, Batch 1370: Loss = 0.5091, Acc = 80.34%, Spikes = 0.0924\n",
            "Epoch 11, Batch 1380: Loss = 0.9834, Acc = 80.33%, Spikes = 0.0928\n",
            "Epoch 11, Batch 1390: Loss = 0.9568, Acc = 80.34%, Spikes = 0.0921\n",
            "Epoch 11, Batch 1400: Loss = 0.3383, Acc = 80.34%, Spikes = 0.0918\n",
            "Epoch 11, Batch 1410: Loss = 0.3488, Acc = 80.38%, Spikes = 0.0969\n",
            "Epoch 11, Batch 1420: Loss = 0.4627, Acc = 80.35%, Spikes = 0.0896\n",
            "Epoch 11, Batch 1430: Loss = 0.4927, Acc = 80.35%, Spikes = 0.0936\n",
            "Epoch 11, Batch 1440: Loss = 0.5675, Acc = 80.35%, Spikes = 0.0857\n",
            "Epoch 11, Batch 1450: Loss = 0.5555, Acc = 80.35%, Spikes = 0.0900\n",
            "Epoch 11, Batch 1460: Loss = 0.3954, Acc = 80.33%, Spikes = 0.0975\n",
            "Epoch 11, Batch 1470: Loss = 0.6723, Acc = 80.32%, Spikes = 0.0913\n",
            "Epoch 11, Batch 1480: Loss = 0.4825, Acc = 80.32%, Spikes = 0.0945\n",
            "Epoch 11, Batch 1490: Loss = 0.6881, Acc = 80.32%, Spikes = 0.0985\n",
            "Epoch 11, Batch 1500: Loss = 0.7630, Acc = 80.30%, Spikes = 0.0880\n",
            "Epoch 11, Batch 1510: Loss = 0.7460, Acc = 80.31%, Spikes = 0.0922\n",
            "Epoch 11, Batch 1520: Loss = 0.9787, Acc = 80.30%, Spikes = 0.0919\n",
            "Epoch 11, Batch 1530: Loss = 0.6737, Acc = 80.31%, Spikes = 0.0965\n",
            "Epoch 11, Batch 1540: Loss = 0.7086, Acc = 80.34%, Spikes = 0.0913\n",
            "Epoch 11, Batch 1550: Loss = 0.5496, Acc = 80.36%, Spikes = 0.0900\n",
            "Epoch 11, Batch 1560: Loss = 0.4717, Acc = 80.37%, Spikes = 0.0936\n",
            "Epoch 11, Batch 1570: Loss = 0.3716, Acc = 80.39%, Spikes = 0.0887\n",
            "Epoch 11, Batch 1580: Loss = 0.6106, Acc = 80.38%, Spikes = 0.0905\n",
            "Epoch 11, Batch 1590: Loss = 0.6482, Acc = 80.39%, Spikes = 0.0947\n",
            "Epoch 11, Batch 1600: Loss = 0.4344, Acc = 80.39%, Spikes = 0.0940\n",
            "Epoch 11, Batch 1610: Loss = 0.5974, Acc = 80.39%, Spikes = 0.0936\n",
            "Epoch 11, Batch 1620: Loss = 0.3800, Acc = 80.41%, Spikes = 0.0899\n",
            "Epoch 11, Batch 1630: Loss = 0.5193, Acc = 80.39%, Spikes = 0.0925\n",
            "Epoch 11, Batch 1640: Loss = 0.7152, Acc = 80.37%, Spikes = 0.0975\n",
            "Epoch 11, Batch 1650: Loss = 0.8006, Acc = 80.39%, Spikes = 0.0987\n",
            "Epoch 11, Batch 1660: Loss = 0.3212, Acc = 80.40%, Spikes = 0.0933\n",
            "Epoch 11, Batch 1670: Loss = 0.5291, Acc = 80.41%, Spikes = 0.0923\n",
            "Epoch 11, Batch 1680: Loss = 0.9658, Acc = 80.41%, Spikes = 0.0897\n",
            "Epoch 11, Batch 1690: Loss = 0.6652, Acc = 80.41%, Spikes = 0.0933\n",
            "Epoch 11, Batch 1700: Loss = 0.3217, Acc = 80.39%, Spikes = 0.0921\n",
            "Epoch 11, Batch 1710: Loss = 0.6255, Acc = 80.42%, Spikes = 0.0889\n",
            "Epoch 11, Batch 1720: Loss = 0.6406, Acc = 80.41%, Spikes = 0.0944\n",
            "Epoch 11, Batch 1730: Loss = 1.0478, Acc = 80.40%, Spikes = 0.0921\n",
            "Epoch 11, Batch 1740: Loss = 0.3869, Acc = 80.42%, Spikes = 0.0970\n",
            "Epoch 11, Batch 1750: Loss = 0.6987, Acc = 80.41%, Spikes = 0.0915\n",
            "Epoch 11, Batch 1760: Loss = 0.5172, Acc = 80.41%, Spikes = 0.0889\n",
            "Epoch 11, Batch 1770: Loss = 0.4377, Acc = 80.39%, Spikes = 0.0899\n",
            "Epoch 11, Batch 1780: Loss = 0.5632, Acc = 80.43%, Spikes = 0.0921\n",
            "Epoch 11, Batch 1790: Loss = 0.9577, Acc = 80.43%, Spikes = 0.0905\n",
            "Epoch 11, Batch 1800: Loss = 0.6012, Acc = 80.42%, Spikes = 0.0928\n",
            "Epoch 11, Batch 1810: Loss = 0.3940, Acc = 80.42%, Spikes = 0.0858\n",
            "Epoch 11, Batch 1820: Loss = 0.6100, Acc = 80.41%, Spikes = 0.0885\n",
            "Epoch 11, Batch 1830: Loss = 0.4352, Acc = 80.43%, Spikes = 0.0954\n",
            "Epoch 11, Batch 1840: Loss = 0.6189, Acc = 80.42%, Spikes = 0.0899\n",
            "Epoch 11, Batch 1850: Loss = 0.6698, Acc = 80.41%, Spikes = 0.0888\n",
            "Epoch 11, Batch 1860: Loss = 0.9703, Acc = 80.41%, Spikes = 0.0874\n",
            "Epoch 11, Batch 1870: Loss = 0.4296, Acc = 80.41%, Spikes = 0.0918\n",
            "Epoch 11/15:\n",
            "Train Loss: 0.6098 | Train Acc: 80.40% | Train Spikes: 0.0888\n",
            "Test Acc: 81.30% | Test Spikes: 0.0929\n",
            "------------------------------------------------------------\n",
            "Epoch 12, Batch 0: Loss = 0.4098, Acc = 84.38%, Spikes = 0.0963\n",
            "Epoch 12, Batch 10: Loss = 0.7545, Acc = 78.98%, Spikes = 0.0906\n",
            "Epoch 12, Batch 20: Loss = 0.6363, Acc = 81.70%, Spikes = 0.0907\n",
            "Epoch 12, Batch 30: Loss = 0.5742, Acc = 80.75%, Spikes = 0.0887\n",
            "Epoch 12, Batch 40: Loss = 0.3655, Acc = 81.25%, Spikes = 0.0988\n",
            "Epoch 12, Batch 50: Loss = 0.8033, Acc = 80.88%, Spikes = 0.0932\n",
            "Epoch 12, Batch 60: Loss = 0.4357, Acc = 81.05%, Spikes = 0.1002\n",
            "Epoch 12, Batch 70: Loss = 0.7435, Acc = 80.59%, Spikes = 0.0931\n",
            "Epoch 12, Batch 80: Loss = 0.6009, Acc = 80.59%, Spikes = 0.0908\n",
            "Epoch 12, Batch 90: Loss = 0.5572, Acc = 80.56%, Spikes = 0.0946\n",
            "Epoch 12, Batch 100: Loss = 0.7069, Acc = 80.48%, Spikes = 0.0962\n",
            "Epoch 12, Batch 110: Loss = 0.4124, Acc = 80.55%, Spikes = 0.0950\n",
            "Epoch 12, Batch 120: Loss = 0.8436, Acc = 80.35%, Spikes = 0.0928\n",
            "Epoch 12, Batch 130: Loss = 0.7316, Acc = 80.34%, Spikes = 0.0936\n",
            "Epoch 12, Batch 140: Loss = 0.5059, Acc = 80.41%, Spikes = 0.0955\n",
            "Epoch 12, Batch 150: Loss = 0.6443, Acc = 80.59%, Spikes = 0.0882\n",
            "Epoch 12, Batch 160: Loss = 0.7291, Acc = 80.40%, Spikes = 0.0937\n",
            "Epoch 12, Batch 170: Loss = 0.8466, Acc = 80.45%, Spikes = 0.0979\n",
            "Epoch 12, Batch 180: Loss = 0.8941, Acc = 80.15%, Spikes = 0.0935\n",
            "Epoch 12, Batch 190: Loss = 0.2692, Acc = 80.33%, Spikes = 0.0978\n",
            "Epoch 12, Batch 200: Loss = 0.6947, Acc = 80.41%, Spikes = 0.1014\n",
            "Epoch 12, Batch 210: Loss = 0.7957, Acc = 80.52%, Spikes = 0.0967\n",
            "Epoch 12, Batch 220: Loss = 0.4804, Acc = 80.57%, Spikes = 0.0962\n",
            "Epoch 12, Batch 230: Loss = 1.0509, Acc = 80.53%, Spikes = 0.0907\n",
            "Epoch 12, Batch 240: Loss = 0.6748, Acc = 80.69%, Spikes = 0.0912\n",
            "Epoch 12, Batch 250: Loss = 0.5417, Acc = 80.63%, Spikes = 0.0892\n",
            "Epoch 12, Batch 260: Loss = 0.2890, Acc = 80.76%, Spikes = 0.0970\n",
            "Epoch 12, Batch 270: Loss = 0.5677, Acc = 80.75%, Spikes = 0.0914\n",
            "Epoch 12, Batch 280: Loss = 0.5058, Acc = 80.76%, Spikes = 0.0912\n",
            "Epoch 12, Batch 290: Loss = 0.5603, Acc = 80.75%, Spikes = 0.0904\n",
            "Epoch 12, Batch 300: Loss = 0.5607, Acc = 80.80%, Spikes = 0.0909\n",
            "Epoch 12, Batch 310: Loss = 1.0046, Acc = 80.79%, Spikes = 0.0952\n",
            "Epoch 12, Batch 320: Loss = 0.8397, Acc = 80.89%, Spikes = 0.0981\n",
            "Epoch 12, Batch 330: Loss = 0.5779, Acc = 80.86%, Spikes = 0.0958\n",
            "Epoch 12, Batch 340: Loss = 0.4320, Acc = 80.91%, Spikes = 0.0948\n",
            "Epoch 12, Batch 350: Loss = 1.0258, Acc = 80.88%, Spikes = 0.0938\n",
            "Epoch 12, Batch 360: Loss = 0.5660, Acc = 80.93%, Spikes = 0.0902\n",
            "Epoch 12, Batch 370: Loss = 0.3737, Acc = 80.94%, Spikes = 0.0909\n",
            "Epoch 12, Batch 380: Loss = 0.5433, Acc = 80.93%, Spikes = 0.0952\n",
            "Epoch 12, Batch 390: Loss = 0.4264, Acc = 80.88%, Spikes = 0.0957\n",
            "Epoch 12, Batch 400: Loss = 0.4827, Acc = 80.88%, Spikes = 0.1000\n",
            "Epoch 12, Batch 410: Loss = 0.6572, Acc = 80.83%, Spikes = 0.0934\n",
            "Epoch 12, Batch 420: Loss = 0.6366, Acc = 80.84%, Spikes = 0.0948\n",
            "Epoch 12, Batch 430: Loss = 0.8907, Acc = 80.88%, Spikes = 0.0881\n",
            "Epoch 12, Batch 440: Loss = 0.7031, Acc = 80.82%, Spikes = 0.0921\n",
            "Epoch 12, Batch 450: Loss = 0.7632, Acc = 80.76%, Spikes = 0.0953\n",
            "Epoch 12, Batch 460: Loss = 0.4919, Acc = 80.73%, Spikes = 0.0957\n",
            "Epoch 12, Batch 470: Loss = 0.9269, Acc = 80.75%, Spikes = 0.0918\n",
            "Epoch 12, Batch 480: Loss = 0.4129, Acc = 80.83%, Spikes = 0.1002\n",
            "Epoch 12, Batch 490: Loss = 0.6687, Acc = 80.80%, Spikes = 0.0974\n",
            "Epoch 12, Batch 500: Loss = 0.5052, Acc = 80.79%, Spikes = 0.0942\n",
            "Epoch 12, Batch 510: Loss = 0.5452, Acc = 80.87%, Spikes = 0.0932\n",
            "Epoch 12, Batch 520: Loss = 0.4271, Acc = 80.90%, Spikes = 0.0910\n",
            "Epoch 12, Batch 530: Loss = 0.5482, Acc = 80.83%, Spikes = 0.0972\n",
            "Epoch 12, Batch 540: Loss = 0.7970, Acc = 80.79%, Spikes = 0.1004\n",
            "Epoch 12, Batch 550: Loss = 0.8554, Acc = 80.82%, Spikes = 0.1033\n",
            "Epoch 12, Batch 560: Loss = 0.8205, Acc = 80.75%, Spikes = 0.1003\n",
            "Epoch 12, Batch 570: Loss = 0.4928, Acc = 80.73%, Spikes = 0.0921\n",
            "Epoch 12, Batch 580: Loss = 0.8115, Acc = 80.76%, Spikes = 0.0999\n",
            "Epoch 12, Batch 590: Loss = 0.5377, Acc = 80.75%, Spikes = 0.0949\n",
            "Epoch 12, Batch 600: Loss = 0.4643, Acc = 80.78%, Spikes = 0.0980\n",
            "Epoch 12, Batch 610: Loss = 0.5165, Acc = 80.76%, Spikes = 0.0910\n",
            "Epoch 12, Batch 620: Loss = 0.4819, Acc = 80.76%, Spikes = 0.0943\n",
            "Epoch 12, Batch 630: Loss = 0.5686, Acc = 80.72%, Spikes = 0.0949\n",
            "Epoch 12, Batch 640: Loss = 0.6375, Acc = 80.67%, Spikes = 0.1002\n",
            "Epoch 12, Batch 650: Loss = 0.6068, Acc = 80.68%, Spikes = 0.0986\n",
            "Epoch 12, Batch 660: Loss = 0.5953, Acc = 80.67%, Spikes = 0.0981\n",
            "Epoch 12, Batch 670: Loss = 0.3999, Acc = 80.66%, Spikes = 0.0928\n",
            "Epoch 12, Batch 680: Loss = 1.0495, Acc = 80.64%, Spikes = 0.0999\n",
            "Epoch 12, Batch 690: Loss = 0.9755, Acc = 80.60%, Spikes = 0.0961\n",
            "Epoch 12, Batch 700: Loss = 0.5864, Acc = 80.59%, Spikes = 0.0936\n",
            "Epoch 12, Batch 710: Loss = 0.5327, Acc = 80.64%, Spikes = 0.0918\n",
            "Epoch 12, Batch 720: Loss = 0.3414, Acc = 80.65%, Spikes = 0.0967\n",
            "Epoch 12, Batch 730: Loss = 0.7210, Acc = 80.65%, Spikes = 0.0949\n",
            "Epoch 12, Batch 740: Loss = 0.6139, Acc = 80.62%, Spikes = 0.0988\n",
            "Epoch 12, Batch 750: Loss = 0.5165, Acc = 80.68%, Spikes = 0.0980\n",
            "Epoch 12, Batch 760: Loss = 0.6335, Acc = 80.66%, Spikes = 0.1010\n",
            "Epoch 12, Batch 770: Loss = 0.4098, Acc = 80.65%, Spikes = 0.0955\n",
            "Epoch 12, Batch 780: Loss = 0.7338, Acc = 80.63%, Spikes = 0.0991\n",
            "Epoch 12, Batch 790: Loss = 0.6149, Acc = 80.67%, Spikes = 0.0981\n",
            "Epoch 12, Batch 800: Loss = 0.7108, Acc = 80.67%, Spikes = 0.0959\n",
            "Epoch 12, Batch 810: Loss = 0.4817, Acc = 80.64%, Spikes = 0.0993\n",
            "Epoch 12, Batch 820: Loss = 0.6738, Acc = 80.66%, Spikes = 0.1027\n",
            "Epoch 12, Batch 830: Loss = 0.7069, Acc = 80.69%, Spikes = 0.0983\n",
            "Epoch 12, Batch 840: Loss = 0.9583, Acc = 80.67%, Spikes = 0.0973\n",
            "Epoch 12, Batch 850: Loss = 0.4216, Acc = 80.71%, Spikes = 0.0932\n",
            "Epoch 12, Batch 860: Loss = 1.0344, Acc = 80.71%, Spikes = 0.0983\n",
            "Epoch 12, Batch 870: Loss = 0.5279, Acc = 80.68%, Spikes = 0.1013\n",
            "Epoch 12, Batch 880: Loss = 0.4222, Acc = 80.71%, Spikes = 0.0979\n",
            "Epoch 12, Batch 890: Loss = 0.8378, Acc = 80.70%, Spikes = 0.0952\n",
            "Epoch 12, Batch 900: Loss = 0.5545, Acc = 80.70%, Spikes = 0.0960\n",
            "Epoch 12, Batch 910: Loss = 0.6473, Acc = 80.65%, Spikes = 0.1000\n",
            "Epoch 12, Batch 920: Loss = 0.6933, Acc = 80.61%, Spikes = 0.0997\n",
            "Epoch 12, Batch 930: Loss = 0.5960, Acc = 80.58%, Spikes = 0.0999\n",
            "Epoch 12, Batch 940: Loss = 0.8526, Acc = 80.58%, Spikes = 0.0973\n",
            "Epoch 12, Batch 950: Loss = 0.6305, Acc = 80.58%, Spikes = 0.0914\n",
            "Epoch 12, Batch 960: Loss = 0.3410, Acc = 80.60%, Spikes = 0.0950\n",
            "Epoch 12, Batch 970: Loss = 0.3635, Acc = 80.63%, Spikes = 0.1054\n",
            "Epoch 12, Batch 980: Loss = 0.2268, Acc = 80.61%, Spikes = 0.0995\n",
            "Epoch 12, Batch 990: Loss = 0.5831, Acc = 80.64%, Spikes = 0.0963\n",
            "Epoch 12, Batch 1000: Loss = 0.5663, Acc = 80.64%, Spikes = 0.1009\n",
            "Epoch 12, Batch 1010: Loss = 0.5756, Acc = 80.64%, Spikes = 0.0948\n",
            "Epoch 12, Batch 1020: Loss = 0.4152, Acc = 80.66%, Spikes = 0.0958\n",
            "Epoch 12, Batch 1030: Loss = 0.5391, Acc = 80.64%, Spikes = 0.0974\n",
            "Epoch 12, Batch 1040: Loss = 0.4340, Acc = 80.60%, Spikes = 0.0993\n",
            "Epoch 12, Batch 1050: Loss = 0.4474, Acc = 80.60%, Spikes = 0.0985\n",
            "Epoch 12, Batch 1060: Loss = 0.6407, Acc = 80.57%, Spikes = 0.0958\n",
            "Epoch 12, Batch 1070: Loss = 0.6394, Acc = 80.57%, Spikes = 0.0973\n",
            "Epoch 12, Batch 1080: Loss = 0.6727, Acc = 80.59%, Spikes = 0.0923\n",
            "Epoch 12, Batch 1090: Loss = 0.9347, Acc = 80.58%, Spikes = 0.0993\n",
            "Epoch 12, Batch 1100: Loss = 0.6179, Acc = 80.60%, Spikes = 0.0983\n",
            "Epoch 12, Batch 1110: Loss = 0.5970, Acc = 80.60%, Spikes = 0.0933\n",
            "Epoch 12, Batch 1120: Loss = 0.3382, Acc = 80.64%, Spikes = 0.0945\n",
            "Epoch 12, Batch 1130: Loss = 0.5048, Acc = 80.65%, Spikes = 0.0944\n",
            "Epoch 12, Batch 1140: Loss = 0.4131, Acc = 80.67%, Spikes = 0.0941\n",
            "Epoch 12, Batch 1150: Loss = 0.4996, Acc = 80.65%, Spikes = 0.0939\n",
            "Epoch 12, Batch 1160: Loss = 0.4477, Acc = 80.66%, Spikes = 0.0951\n",
            "Epoch 12, Batch 1170: Loss = 0.5162, Acc = 80.67%, Spikes = 0.1008\n",
            "Epoch 12, Batch 1180: Loss = 0.3847, Acc = 80.68%, Spikes = 0.0943\n",
            "Epoch 12, Batch 1190: Loss = 1.1994, Acc = 80.68%, Spikes = 0.0926\n",
            "Epoch 12, Batch 1200: Loss = 0.3982, Acc = 80.68%, Spikes = 0.0949\n",
            "Epoch 12, Batch 1210: Loss = 0.7403, Acc = 80.67%, Spikes = 0.0980\n",
            "Epoch 12, Batch 1220: Loss = 0.5949, Acc = 80.69%, Spikes = 0.0951\n",
            "Epoch 12, Batch 1230: Loss = 0.6929, Acc = 80.69%, Spikes = 0.0917\n",
            "Epoch 12, Batch 1240: Loss = 0.3656, Acc = 80.69%, Spikes = 0.1014\n",
            "Epoch 12, Batch 1250: Loss = 0.6461, Acc = 80.70%, Spikes = 0.0937\n",
            "Epoch 12, Batch 1260: Loss = 0.6888, Acc = 80.69%, Spikes = 0.0991\n",
            "Epoch 12, Batch 1270: Loss = 0.5077, Acc = 80.69%, Spikes = 0.1038\n",
            "Epoch 12, Batch 1280: Loss = 0.6126, Acc = 80.67%, Spikes = 0.0931\n",
            "Epoch 12, Batch 1290: Loss = 0.3949, Acc = 80.66%, Spikes = 0.0963\n",
            "Epoch 12, Batch 1300: Loss = 0.5363, Acc = 80.67%, Spikes = 0.0988\n",
            "Epoch 12, Batch 1310: Loss = 0.7412, Acc = 80.68%, Spikes = 0.0991\n",
            "Epoch 12, Batch 1320: Loss = 0.4806, Acc = 80.67%, Spikes = 0.0919\n",
            "Epoch 12, Batch 1330: Loss = 0.5107, Acc = 80.67%, Spikes = 0.1047\n",
            "Epoch 12, Batch 1340: Loss = 0.4225, Acc = 80.68%, Spikes = 0.1006\n",
            "Epoch 12, Batch 1350: Loss = 0.7022, Acc = 80.66%, Spikes = 0.0991\n",
            "Epoch 12, Batch 1360: Loss = 0.7077, Acc = 80.63%, Spikes = 0.0921\n",
            "Epoch 12, Batch 1370: Loss = 0.3385, Acc = 80.65%, Spikes = 0.0957\n",
            "Epoch 12, Batch 1380: Loss = 0.7306, Acc = 80.65%, Spikes = 0.0981\n",
            "Epoch 12, Batch 1390: Loss = 0.4543, Acc = 80.67%, Spikes = 0.0969\n",
            "Epoch 12, Batch 1400: Loss = 0.3704, Acc = 80.67%, Spikes = 0.0940\n",
            "Epoch 12, Batch 1410: Loss = 0.7188, Acc = 80.69%, Spikes = 0.0942\n",
            "Epoch 12, Batch 1420: Loss = 0.5724, Acc = 80.69%, Spikes = 0.0980\n",
            "Epoch 12, Batch 1430: Loss = 0.2455, Acc = 80.70%, Spikes = 0.1004\n",
            "Epoch 12, Batch 1440: Loss = 0.9037, Acc = 80.71%, Spikes = 0.0912\n",
            "Epoch 12, Batch 1450: Loss = 0.6178, Acc = 80.71%, Spikes = 0.0962\n",
            "Epoch 12, Batch 1460: Loss = 0.4157, Acc = 80.72%, Spikes = 0.0962\n",
            "Epoch 12, Batch 1470: Loss = 0.7807, Acc = 80.70%, Spikes = 0.0975\n",
            "Epoch 12, Batch 1480: Loss = 0.6163, Acc = 80.71%, Spikes = 0.0970\n",
            "Epoch 12, Batch 1490: Loss = 0.6496, Acc = 80.72%, Spikes = 0.0981\n",
            "Epoch 12, Batch 1500: Loss = 0.3268, Acc = 80.74%, Spikes = 0.0988\n",
            "Epoch 12, Batch 1510: Loss = 0.4502, Acc = 80.75%, Spikes = 0.0969\n",
            "Epoch 12, Batch 1520: Loss = 0.6711, Acc = 80.76%, Spikes = 0.0977\n",
            "Epoch 12, Batch 1530: Loss = 0.7398, Acc = 80.76%, Spikes = 0.1002\n",
            "Epoch 12, Batch 1540: Loss = 0.5470, Acc = 80.77%, Spikes = 0.0973\n",
            "Epoch 12, Batch 1550: Loss = 0.3587, Acc = 80.78%, Spikes = 0.1031\n",
            "Epoch 12, Batch 1560: Loss = 0.4509, Acc = 80.79%, Spikes = 0.1020\n",
            "Epoch 12, Batch 1570: Loss = 0.8237, Acc = 80.80%, Spikes = 0.0962\n",
            "Epoch 12, Batch 1580: Loss = 0.7811, Acc = 80.79%, Spikes = 0.0939\n",
            "Epoch 12, Batch 1590: Loss = 0.4169, Acc = 80.79%, Spikes = 0.1031\n",
            "Epoch 12, Batch 1600: Loss = 1.0758, Acc = 80.78%, Spikes = 0.0973\n",
            "Epoch 12, Batch 1610: Loss = 1.0326, Acc = 80.78%, Spikes = 0.0968\n",
            "Epoch 12, Batch 1620: Loss = 0.6264, Acc = 80.80%, Spikes = 0.0992\n",
            "Epoch 12, Batch 1630: Loss = 0.5921, Acc = 80.80%, Spikes = 0.0980\n",
            "Epoch 12, Batch 1640: Loss = 0.5498, Acc = 80.81%, Spikes = 0.0963\n",
            "Epoch 12, Batch 1650: Loss = 0.4760, Acc = 80.79%, Spikes = 0.1016\n",
            "Epoch 12, Batch 1660: Loss = 0.3861, Acc = 80.80%, Spikes = 0.1029\n",
            "Epoch 12, Batch 1670: Loss = 0.7097, Acc = 80.80%, Spikes = 0.0938\n",
            "Epoch 12, Batch 1680: Loss = 0.3868, Acc = 80.81%, Spikes = 0.0990\n",
            "Epoch 12, Batch 1690: Loss = 0.5545, Acc = 80.81%, Spikes = 0.0965\n",
            "Epoch 12, Batch 1700: Loss = 0.5627, Acc = 80.80%, Spikes = 0.1019\n",
            "Epoch 12, Batch 1710: Loss = 0.4763, Acc = 80.81%, Spikes = 0.1009\n",
            "Epoch 12, Batch 1720: Loss = 0.4039, Acc = 80.83%, Spikes = 0.0960\n",
            "Epoch 12, Batch 1730: Loss = 0.4147, Acc = 80.82%, Spikes = 0.0991\n",
            "Epoch 12, Batch 1740: Loss = 0.7696, Acc = 80.81%, Spikes = 0.1007\n",
            "Epoch 12, Batch 1750: Loss = 0.4542, Acc = 80.83%, Spikes = 0.0977\n",
            "Epoch 12, Batch 1760: Loss = 0.3614, Acc = 80.83%, Spikes = 0.1065\n",
            "Epoch 12, Batch 1770: Loss = 0.3199, Acc = 80.83%, Spikes = 0.0993\n",
            "Epoch 12, Batch 1780: Loss = 0.6048, Acc = 80.82%, Spikes = 0.0965\n",
            "Epoch 12, Batch 1790: Loss = 0.5285, Acc = 80.81%, Spikes = 0.0990\n",
            "Epoch 12, Batch 1800: Loss = 0.4995, Acc = 80.80%, Spikes = 0.0970\n",
            "Epoch 12, Batch 1810: Loss = 0.4983, Acc = 80.79%, Spikes = 0.0981\n",
            "Epoch 12, Batch 1820: Loss = 0.5374, Acc = 80.80%, Spikes = 0.0975\n",
            "Epoch 12, Batch 1830: Loss = 0.7535, Acc = 80.79%, Spikes = 0.1079\n",
            "Epoch 12, Batch 1840: Loss = 0.8211, Acc = 80.79%, Spikes = 0.1005\n",
            "Epoch 12, Batch 1850: Loss = 0.6980, Acc = 80.80%, Spikes = 0.0932\n",
            "Epoch 12, Batch 1860: Loss = 0.8142, Acc = 80.81%, Spikes = 0.0962\n",
            "Epoch 12, Batch 1870: Loss = 0.4874, Acc = 80.81%, Spikes = 0.0980\n",
            "Epoch 12/15:\n",
            "Train Loss: 0.5984 | Train Acc: 80.82% | Train Spikes: 0.0964\n",
            "Test Acc: 81.38% | Test Spikes: 0.0994\n",
            "------------------------------------------------------------\n",
            "Epoch 13, Batch 0: Loss = 0.5970, Acc = 78.12%, Spikes = 0.0962\n",
            "Epoch 13, Batch 10: Loss = 0.4228, Acc = 81.82%, Spikes = 0.0988\n",
            "Epoch 13, Batch 20: Loss = 0.5842, Acc = 80.80%, Spikes = 0.0973\n",
            "Epoch 13, Batch 30: Loss = 0.4232, Acc = 80.85%, Spikes = 0.0990\n",
            "Epoch 13, Batch 40: Loss = 0.4647, Acc = 80.18%, Spikes = 0.0942\n",
            "Epoch 13, Batch 50: Loss = 0.3972, Acc = 80.70%, Spikes = 0.0970\n",
            "Epoch 13, Batch 60: Loss = 0.7454, Acc = 81.35%, Spikes = 0.0980\n",
            "Epoch 13, Batch 70: Loss = 0.7721, Acc = 81.34%, Spikes = 0.0974\n",
            "Epoch 13, Batch 80: Loss = 0.4634, Acc = 81.37%, Spikes = 0.0961\n",
            "Epoch 13, Batch 90: Loss = 0.5069, Acc = 81.42%, Spikes = 0.1023\n",
            "Epoch 13, Batch 100: Loss = 0.3854, Acc = 81.13%, Spikes = 0.0999\n",
            "Epoch 13, Batch 110: Loss = 0.4139, Acc = 81.05%, Spikes = 0.1012\n",
            "Epoch 13, Batch 120: Loss = 0.6187, Acc = 81.33%, Spikes = 0.0980\n",
            "Epoch 13, Batch 130: Loss = 0.7019, Acc = 81.23%, Spikes = 0.0911\n",
            "Epoch 13, Batch 140: Loss = 0.7269, Acc = 81.41%, Spikes = 0.0943\n",
            "Epoch 13, Batch 150: Loss = 0.7937, Acc = 81.23%, Spikes = 0.0935\n",
            "Epoch 13, Batch 160: Loss = 0.4015, Acc = 81.02%, Spikes = 0.0961\n",
            "Epoch 13, Batch 170: Loss = 0.8027, Acc = 81.05%, Spikes = 0.0950\n",
            "Epoch 13, Batch 180: Loss = 0.4822, Acc = 81.03%, Spikes = 0.1010\n",
            "Epoch 13, Batch 190: Loss = 0.6209, Acc = 80.92%, Spikes = 0.0978\n",
            "Epoch 13, Batch 200: Loss = 0.4433, Acc = 80.89%, Spikes = 0.1026\n",
            "Epoch 13, Batch 210: Loss = 0.8849, Acc = 80.84%, Spikes = 0.1021\n",
            "Epoch 13, Batch 220: Loss = 0.4198, Acc = 80.90%, Spikes = 0.1019\n",
            "Epoch 13, Batch 230: Loss = 0.5246, Acc = 81.03%, Spikes = 0.1009\n",
            "Epoch 13, Batch 240: Loss = 0.7156, Acc = 81.09%, Spikes = 0.0921\n",
            "Epoch 13, Batch 250: Loss = 0.6633, Acc = 81.21%, Spikes = 0.0957\n",
            "Epoch 13, Batch 260: Loss = 0.6342, Acc = 81.25%, Spikes = 0.0966\n",
            "Epoch 13, Batch 270: Loss = 0.7554, Acc = 81.32%, Spikes = 0.0930\n",
            "Epoch 13, Batch 280: Loss = 0.6552, Acc = 81.32%, Spikes = 0.1014\n",
            "Epoch 13, Batch 290: Loss = 0.3078, Acc = 81.35%, Spikes = 0.0989\n",
            "Epoch 13, Batch 300: Loss = 0.3387, Acc = 81.34%, Spikes = 0.1057\n",
            "Epoch 13, Batch 310: Loss = 0.3422, Acc = 81.43%, Spikes = 0.0984\n",
            "Epoch 13, Batch 320: Loss = 0.6506, Acc = 81.47%, Spikes = 0.0953\n",
            "Epoch 13, Batch 330: Loss = 0.5150, Acc = 81.46%, Spikes = 0.1000\n",
            "Epoch 13, Batch 340: Loss = 0.4767, Acc = 81.34%, Spikes = 0.0988\n",
            "Epoch 13, Batch 350: Loss = 0.3866, Acc = 81.43%, Spikes = 0.0991\n",
            "Epoch 13, Batch 360: Loss = 0.8884, Acc = 81.37%, Spikes = 0.0997\n",
            "Epoch 13, Batch 370: Loss = 0.6308, Acc = 81.49%, Spikes = 0.0964\n",
            "Epoch 13, Batch 380: Loss = 0.3624, Acc = 81.57%, Spikes = 0.1004\n",
            "Epoch 13, Batch 390: Loss = 0.4642, Acc = 81.61%, Spikes = 0.0931\n",
            "Epoch 13, Batch 400: Loss = 1.2062, Acc = 81.48%, Spikes = 0.0914\n",
            "Epoch 13, Batch 410: Loss = 0.3300, Acc = 81.42%, Spikes = 0.1050\n",
            "Epoch 13, Batch 420: Loss = 0.6228, Acc = 81.33%, Spikes = 0.0921\n",
            "Epoch 13, Batch 430: Loss = 0.4370, Acc = 81.27%, Spikes = 0.0958\n",
            "Epoch 13, Batch 440: Loss = 0.8911, Acc = 81.19%, Spikes = 0.0962\n",
            "Epoch 13, Batch 450: Loss = 0.8897, Acc = 81.21%, Spikes = 0.0961\n",
            "Epoch 13, Batch 460: Loss = 0.6075, Acc = 81.14%, Spikes = 0.1010\n",
            "Epoch 13, Batch 470: Loss = 0.6823, Acc = 81.15%, Spikes = 0.0987\n",
            "Epoch 13, Batch 480: Loss = 0.7821, Acc = 81.10%, Spikes = 0.0963\n",
            "Epoch 13, Batch 490: Loss = 0.5213, Acc = 81.18%, Spikes = 0.0949\n",
            "Epoch 13, Batch 500: Loss = 0.7619, Acc = 81.14%, Spikes = 0.0973\n",
            "Epoch 13, Batch 510: Loss = 0.8833, Acc = 81.15%, Spikes = 0.0957\n",
            "Epoch 13, Batch 520: Loss = 0.7543, Acc = 81.16%, Spikes = 0.1020\n",
            "Epoch 13, Batch 530: Loss = 0.7117, Acc = 81.19%, Spikes = 0.0986\n",
            "Epoch 13, Batch 540: Loss = 0.8505, Acc = 81.19%, Spikes = 0.0993\n",
            "Epoch 13, Batch 550: Loss = 0.4336, Acc = 81.22%, Spikes = 0.0931\n",
            "Epoch 13, Batch 560: Loss = 0.8050, Acc = 81.14%, Spikes = 0.0946\n",
            "Epoch 13, Batch 570: Loss = 0.8397, Acc = 81.11%, Spikes = 0.0974\n",
            "Epoch 13, Batch 580: Loss = 0.5930, Acc = 81.16%, Spikes = 0.0942\n",
            "Epoch 13, Batch 590: Loss = 0.6313, Acc = 81.18%, Spikes = 0.1004\n",
            "Epoch 13, Batch 600: Loss = 0.6584, Acc = 81.16%, Spikes = 0.0956\n",
            "Epoch 13, Batch 610: Loss = 0.7332, Acc = 81.16%, Spikes = 0.0945\n",
            "Epoch 13, Batch 620: Loss = 0.9110, Acc = 81.13%, Spikes = 0.0974\n",
            "Epoch 13, Batch 630: Loss = 0.5813, Acc = 81.12%, Spikes = 0.0990\n",
            "Epoch 13, Batch 640: Loss = 0.7547, Acc = 81.10%, Spikes = 0.0945\n",
            "Epoch 13, Batch 650: Loss = 0.3827, Acc = 81.11%, Spikes = 0.0986\n",
            "Epoch 13, Batch 660: Loss = 0.8686, Acc = 81.11%, Spikes = 0.0929\n",
            "Epoch 13, Batch 670: Loss = 0.8785, Acc = 81.13%, Spikes = 0.0986\n",
            "Epoch 13, Batch 680: Loss = 0.7888, Acc = 81.14%, Spikes = 0.1019\n",
            "Epoch 13, Batch 690: Loss = 0.7622, Acc = 81.18%, Spikes = 0.1012\n",
            "Epoch 13, Batch 700: Loss = 0.4448, Acc = 81.13%, Spikes = 0.0942\n",
            "Epoch 13, Batch 710: Loss = 0.7179, Acc = 81.08%, Spikes = 0.0925\n",
            "Epoch 13, Batch 720: Loss = 0.4691, Acc = 81.09%, Spikes = 0.0950\n",
            "Epoch 13, Batch 730: Loss = 0.7246, Acc = 81.08%, Spikes = 0.0975\n",
            "Epoch 13, Batch 740: Loss = 0.7398, Acc = 81.06%, Spikes = 0.0985\n",
            "Epoch 13, Batch 750: Loss = 0.4847, Acc = 81.05%, Spikes = 0.0959\n",
            "Epoch 13, Batch 760: Loss = 0.5937, Acc = 81.03%, Spikes = 0.0961\n",
            "Epoch 13, Batch 770: Loss = 0.4107, Acc = 81.01%, Spikes = 0.0998\n",
            "Epoch 13, Batch 780: Loss = 0.5469, Acc = 81.07%, Spikes = 0.1010\n",
            "Epoch 13, Batch 790: Loss = 0.8046, Acc = 81.04%, Spikes = 0.0908\n",
            "Epoch 13, Batch 800: Loss = 0.8368, Acc = 81.04%, Spikes = 0.0908\n",
            "Epoch 13, Batch 810: Loss = 0.9539, Acc = 81.02%, Spikes = 0.0971\n",
            "Epoch 13, Batch 820: Loss = 0.4815, Acc = 80.97%, Spikes = 0.0935\n",
            "Epoch 13, Batch 830: Loss = 0.5345, Acc = 80.96%, Spikes = 0.0998\n",
            "Epoch 13, Batch 840: Loss = 0.4999, Acc = 80.98%, Spikes = 0.1030\n",
            "Epoch 13, Batch 850: Loss = 0.3788, Acc = 81.02%, Spikes = 0.0993\n",
            "Epoch 13, Batch 860: Loss = 0.6844, Acc = 81.02%, Spikes = 0.0947\n",
            "Epoch 13, Batch 870: Loss = 0.7776, Acc = 81.02%, Spikes = 0.0929\n",
            "Epoch 13, Batch 880: Loss = 0.4123, Acc = 81.04%, Spikes = 0.0993\n",
            "Epoch 13, Batch 890: Loss = 0.6187, Acc = 81.06%, Spikes = 0.1007\n",
            "Epoch 13, Batch 900: Loss = 0.6095, Acc = 81.08%, Spikes = 0.0969\n",
            "Epoch 13, Batch 910: Loss = 0.4050, Acc = 81.11%, Spikes = 0.0990\n",
            "Epoch 13, Batch 920: Loss = 0.7044, Acc = 81.10%, Spikes = 0.0972\n",
            "Epoch 13, Batch 930: Loss = 0.4415, Acc = 81.11%, Spikes = 0.0910\n",
            "Epoch 13, Batch 940: Loss = 0.5122, Acc = 81.07%, Spikes = 0.0953\n",
            "Epoch 13, Batch 950: Loss = 0.7273, Acc = 81.05%, Spikes = 0.0954\n",
            "Epoch 13, Batch 960: Loss = 0.5813, Acc = 81.05%, Spikes = 0.0950\n",
            "Epoch 13, Batch 970: Loss = 0.5647, Acc = 81.04%, Spikes = 0.0958\n",
            "Epoch 13, Batch 980: Loss = 0.3264, Acc = 81.04%, Spikes = 0.1014\n",
            "Epoch 13, Batch 990: Loss = 0.8564, Acc = 81.02%, Spikes = 0.0935\n",
            "Epoch 13, Batch 1000: Loss = 0.6740, Acc = 81.01%, Spikes = 0.0938\n",
            "Epoch 13, Batch 1010: Loss = 0.4659, Acc = 80.99%, Spikes = 0.0968\n",
            "Epoch 13, Batch 1020: Loss = 0.7593, Acc = 80.96%, Spikes = 0.0958\n",
            "Epoch 13, Batch 1030: Loss = 0.6485, Acc = 80.98%, Spikes = 0.0936\n",
            "Epoch 13, Batch 1040: Loss = 0.3787, Acc = 80.96%, Spikes = 0.0932\n",
            "Epoch 13, Batch 1050: Loss = 0.6351, Acc = 80.95%, Spikes = 0.0985\n",
            "Epoch 13, Batch 1060: Loss = 0.5044, Acc = 80.92%, Spikes = 0.0993\n",
            "Epoch 13, Batch 1070: Loss = 0.8067, Acc = 80.96%, Spikes = 0.0927\n",
            "Epoch 13, Batch 1080: Loss = 0.5648, Acc = 80.95%, Spikes = 0.0946\n",
            "Epoch 13, Batch 1090: Loss = 0.5278, Acc = 80.95%, Spikes = 0.0949\n",
            "Epoch 13, Batch 1100: Loss = 0.5893, Acc = 80.98%, Spikes = 0.0963\n",
            "Epoch 13, Batch 1110: Loss = 0.6503, Acc = 80.98%, Spikes = 0.0981\n",
            "Epoch 13, Batch 1120: Loss = 0.3449, Acc = 80.98%, Spikes = 0.0991\n",
            "Epoch 13, Batch 1130: Loss = 0.6804, Acc = 80.98%, Spikes = 0.0983\n",
            "Epoch 13, Batch 1140: Loss = 0.3395, Acc = 81.00%, Spikes = 0.0967\n",
            "Epoch 13, Batch 1150: Loss = 0.6915, Acc = 80.96%, Spikes = 0.0956\n",
            "Epoch 13, Batch 1160: Loss = 0.3754, Acc = 80.96%, Spikes = 0.0971\n",
            "Epoch 13, Batch 1170: Loss = 0.6874, Acc = 80.94%, Spikes = 0.0907\n",
            "Epoch 13, Batch 1180: Loss = 0.8264, Acc = 80.97%, Spikes = 0.0950\n",
            "Epoch 13, Batch 1190: Loss = 0.7741, Acc = 80.95%, Spikes = 0.0977\n",
            "Epoch 13, Batch 1200: Loss = 0.2955, Acc = 80.95%, Spikes = 0.0948\n",
            "Epoch 13, Batch 1210: Loss = 0.7936, Acc = 80.99%, Spikes = 0.0885\n",
            "Epoch 13, Batch 1220: Loss = 0.4881, Acc = 80.98%, Spikes = 0.0991\n",
            "Epoch 13, Batch 1230: Loss = 0.8472, Acc = 80.96%, Spikes = 0.0976\n",
            "Epoch 13, Batch 1240: Loss = 0.7248, Acc = 80.99%, Spikes = 0.0959\n",
            "Epoch 13, Batch 1250: Loss = 0.6845, Acc = 80.98%, Spikes = 0.0977\n",
            "Epoch 13, Batch 1260: Loss = 0.6698, Acc = 80.96%, Spikes = 0.0922\n",
            "Epoch 13, Batch 1270: Loss = 0.4657, Acc = 80.94%, Spikes = 0.0916\n",
            "Epoch 13, Batch 1280: Loss = 0.5502, Acc = 80.92%, Spikes = 0.0971\n",
            "Epoch 13, Batch 1290: Loss = 0.4637, Acc = 80.90%, Spikes = 0.0975\n",
            "Epoch 13, Batch 1300: Loss = 0.8737, Acc = 80.92%, Spikes = 0.0960\n",
            "Epoch 13, Batch 1310: Loss = 0.6358, Acc = 80.91%, Spikes = 0.0973\n",
            "Epoch 13, Batch 1320: Loss = 0.4926, Acc = 80.93%, Spikes = 0.0970\n",
            "Epoch 13, Batch 1330: Loss = 0.7103, Acc = 80.93%, Spikes = 0.0967\n",
            "Epoch 13, Batch 1340: Loss = 0.3631, Acc = 80.91%, Spikes = 0.1013\n",
            "Epoch 13, Batch 1350: Loss = 0.3654, Acc = 80.94%, Spikes = 0.0979\n",
            "Epoch 13, Batch 1360: Loss = 0.5077, Acc = 80.96%, Spikes = 0.0914\n",
            "Epoch 13, Batch 1370: Loss = 0.4058, Acc = 80.99%, Spikes = 0.0973\n",
            "Epoch 13, Batch 1380: Loss = 0.6056, Acc = 80.95%, Spikes = 0.0989\n",
            "Epoch 13, Batch 1390: Loss = 0.5160, Acc = 80.96%, Spikes = 0.0965\n",
            "Epoch 13, Batch 1400: Loss = 0.7538, Acc = 80.96%, Spikes = 0.0981\n",
            "Epoch 13, Batch 1410: Loss = 0.4602, Acc = 80.97%, Spikes = 0.0959\n",
            "Epoch 13, Batch 1420: Loss = 0.7197, Acc = 80.98%, Spikes = 0.0969\n",
            "Epoch 13, Batch 1430: Loss = 0.7241, Acc = 80.97%, Spikes = 0.0928\n",
            "Epoch 13, Batch 1440: Loss = 0.5901, Acc = 80.99%, Spikes = 0.0964\n",
            "Epoch 13, Batch 1450: Loss = 0.6798, Acc = 80.96%, Spikes = 0.0887\n",
            "Epoch 13, Batch 1460: Loss = 0.6494, Acc = 80.97%, Spikes = 0.0939\n",
            "Epoch 13, Batch 1470: Loss = 0.4992, Acc = 80.97%, Spikes = 0.0970\n",
            "Epoch 13, Batch 1480: Loss = 0.4710, Acc = 80.97%, Spikes = 0.0988\n",
            "Epoch 13, Batch 1490: Loss = 0.6574, Acc = 80.95%, Spikes = 0.0916\n",
            "Epoch 13, Batch 1500: Loss = 0.5471, Acc = 80.93%, Spikes = 0.0874\n",
            "Epoch 13, Batch 1510: Loss = 0.3335, Acc = 80.92%, Spikes = 0.0964\n",
            "Epoch 13, Batch 1520: Loss = 0.4999, Acc = 80.91%, Spikes = 0.0975\n",
            "Epoch 13, Batch 1530: Loss = 0.3551, Acc = 80.91%, Spikes = 0.0899\n",
            "Epoch 13, Batch 1540: Loss = 0.5314, Acc = 80.89%, Spikes = 0.0923\n",
            "Epoch 13, Batch 1550: Loss = 0.6603, Acc = 80.88%, Spikes = 0.0979\n",
            "Epoch 13, Batch 1560: Loss = 0.9007, Acc = 80.87%, Spikes = 0.0936\n",
            "Epoch 13, Batch 1570: Loss = 0.4361, Acc = 80.87%, Spikes = 0.0970\n",
            "Epoch 13, Batch 1580: Loss = 0.6925, Acc = 80.87%, Spikes = 0.0986\n",
            "Epoch 13, Batch 1590: Loss = 1.0889, Acc = 80.88%, Spikes = 0.0964\n",
            "Epoch 13, Batch 1600: Loss = 0.7630, Acc = 80.88%, Spikes = 0.0953\n",
            "Epoch 13, Batch 1610: Loss = 0.4142, Acc = 80.88%, Spikes = 0.0954\n",
            "Epoch 13, Batch 1620: Loss = 0.3322, Acc = 80.88%, Spikes = 0.0959\n",
            "Epoch 13, Batch 1630: Loss = 0.3734, Acc = 80.87%, Spikes = 0.1012\n",
            "Epoch 13, Batch 1640: Loss = 0.5333, Acc = 80.87%, Spikes = 0.0926\n",
            "Epoch 13, Batch 1650: Loss = 0.4352, Acc = 80.87%, Spikes = 0.0952\n",
            "Epoch 13, Batch 1660: Loss = 0.5786, Acc = 80.84%, Spikes = 0.0977\n",
            "Epoch 13, Batch 1670: Loss = 0.3884, Acc = 80.85%, Spikes = 0.0934\n",
            "Epoch 13, Batch 1680: Loss = 0.5043, Acc = 80.84%, Spikes = 0.0942\n",
            "Epoch 13, Batch 1690: Loss = 0.6819, Acc = 80.84%, Spikes = 0.0957\n",
            "Epoch 13, Batch 1700: Loss = 0.9424, Acc = 80.84%, Spikes = 0.0987\n",
            "Epoch 13, Batch 1710: Loss = 0.6432, Acc = 80.82%, Spikes = 0.0912\n",
            "Epoch 13, Batch 1720: Loss = 0.7272, Acc = 80.83%, Spikes = 0.0921\n",
            "Epoch 13, Batch 1730: Loss = 0.6173, Acc = 80.84%, Spikes = 0.0981\n",
            "Epoch 13, Batch 1740: Loss = 0.7415, Acc = 80.83%, Spikes = 0.0926\n",
            "Epoch 13, Batch 1750: Loss = 0.6588, Acc = 80.83%, Spikes = 0.0982\n",
            "Epoch 13, Batch 1760: Loss = 0.6838, Acc = 80.84%, Spikes = 0.0924\n",
            "Epoch 13, Batch 1770: Loss = 0.3072, Acc = 80.84%, Spikes = 0.0996\n",
            "Epoch 13, Batch 1780: Loss = 0.6356, Acc = 80.84%, Spikes = 0.0987\n",
            "Epoch 13, Batch 1790: Loss = 0.4777, Acc = 80.85%, Spikes = 0.0956\n",
            "Epoch 13, Batch 1800: Loss = 0.3056, Acc = 80.84%, Spikes = 0.0987\n",
            "Epoch 13, Batch 1810: Loss = 0.5911, Acc = 80.82%, Spikes = 0.0958\n",
            "Epoch 13, Batch 1820: Loss = 0.5529, Acc = 80.80%, Spikes = 0.0999\n",
            "Epoch 13, Batch 1830: Loss = 0.4460, Acc = 80.78%, Spikes = 0.1002\n",
            "Epoch 13, Batch 1840: Loss = 0.6144, Acc = 80.78%, Spikes = 0.0929\n",
            "Epoch 13, Batch 1850: Loss = 0.3001, Acc = 80.80%, Spikes = 0.0945\n",
            "Epoch 13, Batch 1860: Loss = 0.7217, Acc = 80.80%, Spikes = 0.0908\n",
            "Epoch 13, Batch 1870: Loss = 0.4852, Acc = 80.78%, Spikes = 0.1005\n",
            "Epoch 13/15:\n",
            "Train Loss: 0.5965 | Train Acc: 80.79% | Train Spikes: 0.0966\n",
            "Test Acc: 81.70% | Test Spikes: 0.0959\n",
            "------------------------------------------------------------\n",
            "Epoch 14, Batch 0: Loss = 0.5414, Acc = 87.50%, Spikes = 0.0950\n",
            "Epoch 14, Batch 10: Loss = 0.8907, Acc = 80.97%, Spikes = 0.0935\n",
            "Epoch 14, Batch 20: Loss = 0.3684, Acc = 80.95%, Spikes = 0.0984\n",
            "Epoch 14, Batch 30: Loss = 0.5775, Acc = 80.85%, Spikes = 0.0915\n",
            "Epoch 14, Batch 40: Loss = 0.4923, Acc = 79.73%, Spikes = 0.1009\n",
            "Epoch 14, Batch 50: Loss = 0.8119, Acc = 79.90%, Spikes = 0.0920\n",
            "Epoch 14, Batch 60: Loss = 0.6572, Acc = 79.56%, Spikes = 0.0981\n",
            "Epoch 14, Batch 70: Loss = 0.4226, Acc = 80.37%, Spikes = 0.0968\n",
            "Epoch 14, Batch 80: Loss = 0.8518, Acc = 80.21%, Spikes = 0.0977\n",
            "Epoch 14, Batch 90: Loss = 0.8141, Acc = 79.88%, Spikes = 0.0936\n",
            "Epoch 14, Batch 100: Loss = 0.7183, Acc = 80.29%, Spikes = 0.0945\n",
            "Epoch 14, Batch 110: Loss = 0.3446, Acc = 80.29%, Spikes = 0.0922\n",
            "Epoch 14, Batch 120: Loss = 0.7862, Acc = 80.24%, Spikes = 0.0907\n",
            "Epoch 14, Batch 130: Loss = 0.4972, Acc = 80.51%, Spikes = 0.0975\n",
            "Epoch 14, Batch 140: Loss = 0.3186, Acc = 80.34%, Spikes = 0.0953\n",
            "Epoch 14, Batch 150: Loss = 1.0829, Acc = 80.38%, Spikes = 0.0928\n",
            "Epoch 14, Batch 160: Loss = 0.6182, Acc = 80.36%, Spikes = 0.0982\n",
            "Epoch 14, Batch 170: Loss = 0.8447, Acc = 80.50%, Spikes = 0.0941\n",
            "Epoch 14, Batch 180: Loss = 0.7741, Acc = 80.35%, Spikes = 0.0940\n",
            "Epoch 14, Batch 190: Loss = 0.5129, Acc = 80.38%, Spikes = 0.0971\n",
            "Epoch 14, Batch 200: Loss = 1.0647, Acc = 80.32%, Spikes = 0.0958\n",
            "Epoch 14, Batch 210: Loss = 0.8720, Acc = 80.26%, Spikes = 0.0932\n",
            "Epoch 14, Batch 220: Loss = 0.5670, Acc = 80.33%, Spikes = 0.0940\n",
            "Epoch 14, Batch 230: Loss = 0.2642, Acc = 80.36%, Spikes = 0.1012\n",
            "Epoch 14, Batch 240: Loss = 0.5140, Acc = 80.37%, Spikes = 0.0957\n",
            "Epoch 14, Batch 250: Loss = 0.5885, Acc = 80.32%, Spikes = 0.1012\n",
            "Epoch 14, Batch 260: Loss = 0.6009, Acc = 80.33%, Spikes = 0.0993\n",
            "Epoch 14, Batch 270: Loss = 0.6096, Acc = 80.45%, Spikes = 0.1000\n",
            "Epoch 14, Batch 280: Loss = 0.8658, Acc = 80.65%, Spikes = 0.0896\n",
            "Epoch 14, Batch 290: Loss = 0.5033, Acc = 80.59%, Spikes = 0.0960\n",
            "Epoch 14, Batch 300: Loss = 1.0101, Acc = 80.52%, Spikes = 0.0913\n",
            "Epoch 14, Batch 310: Loss = 0.4894, Acc = 80.55%, Spikes = 0.0943\n",
            "Epoch 14, Batch 320: Loss = 0.5248, Acc = 80.59%, Spikes = 0.0966\n",
            "Epoch 14, Batch 330: Loss = 0.5365, Acc = 80.58%, Spikes = 0.0947\n",
            "Epoch 14, Batch 340: Loss = 0.7056, Acc = 80.57%, Spikes = 0.0936\n",
            "Epoch 14, Batch 350: Loss = 0.8427, Acc = 80.49%, Spikes = 0.0942\n",
            "Epoch 14, Batch 360: Loss = 0.5098, Acc = 80.44%, Spikes = 0.0973\n",
            "Epoch 14, Batch 370: Loss = 0.3534, Acc = 80.52%, Spikes = 0.1022\n",
            "Epoch 14, Batch 380: Loss = 0.4835, Acc = 80.45%, Spikes = 0.0960\n",
            "Epoch 14, Batch 390: Loss = 0.5120, Acc = 80.41%, Spikes = 0.0931\n",
            "Epoch 14, Batch 400: Loss = 0.3821, Acc = 80.48%, Spikes = 0.0951\n",
            "Epoch 14, Batch 410: Loss = 0.8515, Acc = 80.48%, Spikes = 0.0911\n",
            "Epoch 14, Batch 420: Loss = 0.2803, Acc = 80.52%, Spikes = 0.1011\n",
            "Epoch 14, Batch 430: Loss = 0.6418, Acc = 80.53%, Spikes = 0.0931\n",
            "Epoch 14, Batch 440: Loss = 0.3971, Acc = 80.55%, Spikes = 0.0948\n",
            "Epoch 14, Batch 450: Loss = 0.8422, Acc = 80.57%, Spikes = 0.0968\n",
            "Epoch 14, Batch 460: Loss = 0.5213, Acc = 80.57%, Spikes = 0.0934\n",
            "Epoch 14, Batch 470: Loss = 0.6186, Acc = 80.59%, Spikes = 0.1003\n",
            "Epoch 14, Batch 480: Loss = 0.5787, Acc = 80.57%, Spikes = 0.0969\n",
            "Epoch 14, Batch 490: Loss = 0.4370, Acc = 80.58%, Spikes = 0.0951\n",
            "Epoch 14, Batch 500: Loss = 1.0657, Acc = 80.54%, Spikes = 0.0950\n",
            "Epoch 14, Batch 510: Loss = 0.4422, Acc = 80.55%, Spikes = 0.1021\n",
            "Epoch 14, Batch 520: Loss = 0.6382, Acc = 80.58%, Spikes = 0.0941\n",
            "Epoch 14, Batch 530: Loss = 0.5344, Acc = 80.60%, Spikes = 0.0984\n",
            "Epoch 14, Batch 540: Loss = 0.6030, Acc = 80.53%, Spikes = 0.0928\n",
            "Epoch 14, Batch 550: Loss = 0.5298, Acc = 80.55%, Spikes = 0.0972\n",
            "Epoch 14, Batch 560: Loss = 0.6525, Acc = 80.59%, Spikes = 0.0971\n",
            "Epoch 14, Batch 570: Loss = 0.6547, Acc = 80.54%, Spikes = 0.0990\n",
            "Epoch 14, Batch 580: Loss = 0.7327, Acc = 80.47%, Spikes = 0.0969\n",
            "Epoch 14, Batch 590: Loss = 0.3523, Acc = 80.49%, Spikes = 0.0909\n",
            "Epoch 14, Batch 600: Loss = 0.4468, Acc = 80.50%, Spikes = 0.0951\n",
            "Epoch 14, Batch 610: Loss = 0.7305, Acc = 80.48%, Spikes = 0.0960\n",
            "Epoch 14, Batch 620: Loss = 0.8508, Acc = 80.50%, Spikes = 0.0987\n",
            "Epoch 14, Batch 630: Loss = 0.2982, Acc = 80.54%, Spikes = 0.0981\n",
            "Epoch 14, Batch 640: Loss = 1.0410, Acc = 80.63%, Spikes = 0.0963\n",
            "Epoch 14, Batch 650: Loss = 0.8894, Acc = 80.65%, Spikes = 0.0947\n",
            "Epoch 14, Batch 660: Loss = 0.5510, Acc = 80.67%, Spikes = 0.0972\n",
            "Epoch 14, Batch 670: Loss = 0.5148, Acc = 80.71%, Spikes = 0.0964\n",
            "Epoch 14, Batch 680: Loss = 0.5365, Acc = 80.75%, Spikes = 0.0954\n",
            "Epoch 14, Batch 690: Loss = 0.4783, Acc = 80.82%, Spikes = 0.0978\n",
            "Epoch 14, Batch 700: Loss = 0.4940, Acc = 80.86%, Spikes = 0.1037\n",
            "Epoch 14, Batch 710: Loss = 0.4048, Acc = 80.89%, Spikes = 0.1026\n",
            "Epoch 14, Batch 720: Loss = 0.6873, Acc = 80.82%, Spikes = 0.0903\n",
            "Epoch 14, Batch 730: Loss = 0.7189, Acc = 80.84%, Spikes = 0.0965\n",
            "Epoch 14, Batch 740: Loss = 0.6179, Acc = 80.78%, Spikes = 0.0955\n",
            "Epoch 14, Batch 750: Loss = 0.5615, Acc = 80.78%, Spikes = 0.1021\n",
            "Epoch 14, Batch 760: Loss = 0.7491, Acc = 80.78%, Spikes = 0.0995\n",
            "Epoch 14, Batch 770: Loss = 0.3954, Acc = 80.78%, Spikes = 0.0979\n",
            "Epoch 14, Batch 780: Loss = 0.6167, Acc = 80.85%, Spikes = 0.0927\n",
            "Epoch 14, Batch 790: Loss = 0.7479, Acc = 80.85%, Spikes = 0.0945\n",
            "Epoch 14, Batch 800: Loss = 0.5008, Acc = 80.87%, Spikes = 0.0929\n",
            "Epoch 14, Batch 810: Loss = 0.6193, Acc = 80.83%, Spikes = 0.1013\n",
            "Epoch 14, Batch 820: Loss = 0.7428, Acc = 80.84%, Spikes = 0.0959\n",
            "Epoch 14, Batch 830: Loss = 0.3835, Acc = 80.85%, Spikes = 0.0949\n",
            "Epoch 14, Batch 840: Loss = 0.8901, Acc = 80.90%, Spikes = 0.0965\n",
            "Epoch 14, Batch 850: Loss = 0.5188, Acc = 80.94%, Spikes = 0.0951\n",
            "Epoch 14, Batch 860: Loss = 0.5578, Acc = 80.94%, Spikes = 0.0955\n",
            "Epoch 14, Batch 870: Loss = 1.2151, Acc = 80.95%, Spikes = 0.0935\n",
            "Epoch 14, Batch 880: Loss = 0.7346, Acc = 80.97%, Spikes = 0.0937\n",
            "Epoch 14, Batch 890: Loss = 0.4752, Acc = 81.00%, Spikes = 0.0927\n",
            "Epoch 14, Batch 900: Loss = 0.3452, Acc = 81.02%, Spikes = 0.0963\n",
            "Epoch 14, Batch 910: Loss = 0.8459, Acc = 81.01%, Spikes = 0.0940\n",
            "Epoch 14, Batch 920: Loss = 0.7135, Acc = 81.00%, Spikes = 0.0941\n",
            "Epoch 14, Batch 930: Loss = 0.3595, Acc = 80.99%, Spikes = 0.0935\n",
            "Epoch 14, Batch 940: Loss = 0.8370, Acc = 80.99%, Spikes = 0.0903\n",
            "Epoch 14, Batch 950: Loss = 1.0098, Acc = 80.95%, Spikes = 0.0889\n",
            "Epoch 14, Batch 960: Loss = 0.5051, Acc = 80.96%, Spikes = 0.0936\n",
            "Epoch 14, Batch 970: Loss = 0.4392, Acc = 80.96%, Spikes = 0.0921\n",
            "Epoch 14, Batch 980: Loss = 0.4401, Acc = 80.98%, Spikes = 0.0899\n",
            "Epoch 14, Batch 990: Loss = 0.5666, Acc = 80.99%, Spikes = 0.0944\n",
            "Epoch 14, Batch 1000: Loss = 0.5986, Acc = 81.00%, Spikes = 0.0909\n",
            "Epoch 14, Batch 1010: Loss = 0.7929, Acc = 81.01%, Spikes = 0.0957\n",
            "Epoch 14, Batch 1020: Loss = 0.4672, Acc = 81.01%, Spikes = 0.0926\n",
            "Epoch 14, Batch 1030: Loss = 0.5574, Acc = 80.98%, Spikes = 0.0942\n",
            "Epoch 14, Batch 1040: Loss = 0.8677, Acc = 80.97%, Spikes = 0.0928\n",
            "Epoch 14, Batch 1050: Loss = 1.3766, Acc = 80.97%, Spikes = 0.0924\n",
            "Epoch 14, Batch 1060: Loss = 0.3584, Acc = 80.99%, Spikes = 0.0991\n",
            "Epoch 14, Batch 1070: Loss = 0.4077, Acc = 80.98%, Spikes = 0.0984\n",
            "Epoch 14, Batch 1080: Loss = 0.3606, Acc = 81.00%, Spikes = 0.0965\n",
            "Epoch 14, Batch 1090: Loss = 0.7485, Acc = 81.01%, Spikes = 0.0939\n",
            "Epoch 14, Batch 1100: Loss = 0.6800, Acc = 81.02%, Spikes = 0.0954\n",
            "Epoch 14, Batch 1110: Loss = 0.3474, Acc = 81.00%, Spikes = 0.0993\n",
            "Epoch 14, Batch 1120: Loss = 0.7838, Acc = 81.00%, Spikes = 0.0946\n",
            "Epoch 14, Batch 1130: Loss = 0.3577, Acc = 80.98%, Spikes = 0.0917\n",
            "Epoch 14, Batch 1140: Loss = 0.5980, Acc = 80.99%, Spikes = 0.0969\n",
            "Epoch 14, Batch 1150: Loss = 0.4611, Acc = 80.99%, Spikes = 0.1010\n",
            "Epoch 14, Batch 1160: Loss = 0.5088, Acc = 81.00%, Spikes = 0.0893\n",
            "Epoch 14, Batch 1170: Loss = 0.3158, Acc = 81.00%, Spikes = 0.0988\n",
            "Epoch 14, Batch 1180: Loss = 0.3596, Acc = 81.03%, Spikes = 0.0965\n",
            "Epoch 14, Batch 1190: Loss = 0.3892, Acc = 81.02%, Spikes = 0.0966\n",
            "Epoch 14, Batch 1200: Loss = 0.6096, Acc = 80.99%, Spikes = 0.0881\n",
            "Epoch 14, Batch 1210: Loss = 0.5690, Acc = 80.98%, Spikes = 0.0975\n",
            "Epoch 14, Batch 1220: Loss = 0.6868, Acc = 80.96%, Spikes = 0.0877\n",
            "Epoch 14, Batch 1230: Loss = 0.3274, Acc = 80.95%, Spikes = 0.0959\n",
            "Epoch 14, Batch 1240: Loss = 1.1260, Acc = 80.94%, Spikes = 0.0985\n",
            "Epoch 14, Batch 1250: Loss = 0.4413, Acc = 80.94%, Spikes = 0.0959\n",
            "Epoch 14, Batch 1260: Loss = 0.5931, Acc = 80.97%, Spikes = 0.0964\n",
            "Epoch 14, Batch 1270: Loss = 0.5798, Acc = 80.95%, Spikes = 0.0941\n",
            "Epoch 14, Batch 1280: Loss = 0.4057, Acc = 80.95%, Spikes = 0.1002\n",
            "Epoch 14, Batch 1290: Loss = 0.3386, Acc = 80.95%, Spikes = 0.0957\n",
            "Epoch 14, Batch 1300: Loss = 0.6399, Acc = 80.95%, Spikes = 0.0936\n",
            "Epoch 14, Batch 1310: Loss = 0.7016, Acc = 80.96%, Spikes = 0.0925\n",
            "Epoch 14, Batch 1320: Loss = 0.4300, Acc = 80.96%, Spikes = 0.0957\n",
            "Epoch 14, Batch 1330: Loss = 0.7652, Acc = 80.98%, Spikes = 0.0881\n",
            "Epoch 14, Batch 1340: Loss = 0.7118, Acc = 80.98%, Spikes = 0.0972\n",
            "Epoch 14, Batch 1350: Loss = 0.6696, Acc = 80.95%, Spikes = 0.0997\n",
            "Epoch 14, Batch 1360: Loss = 0.4110, Acc = 80.93%, Spikes = 0.0899\n",
            "Epoch 14, Batch 1370: Loss = 0.3931, Acc = 80.92%, Spikes = 0.1032\n",
            "Epoch 14, Batch 1380: Loss = 0.3688, Acc = 80.94%, Spikes = 0.0951\n",
            "Epoch 14, Batch 1390: Loss = 0.3151, Acc = 80.94%, Spikes = 0.0972\n",
            "Epoch 14, Batch 1400: Loss = 0.5390, Acc = 80.96%, Spikes = 0.0933\n",
            "Epoch 14, Batch 1410: Loss = 0.8492, Acc = 80.93%, Spikes = 0.0945\n",
            "Epoch 14, Batch 1420: Loss = 0.5700, Acc = 80.92%, Spikes = 0.0966\n",
            "Epoch 14, Batch 1430: Loss = 0.6580, Acc = 80.89%, Spikes = 0.0914\n",
            "Epoch 14, Batch 1440: Loss = 0.4122, Acc = 80.89%, Spikes = 0.0979\n",
            "Epoch 14, Batch 1450: Loss = 0.6388, Acc = 80.86%, Spikes = 0.0857\n",
            "Epoch 14, Batch 1460: Loss = 0.3662, Acc = 80.86%, Spikes = 0.0941\n",
            "Epoch 14, Batch 1470: Loss = 0.5180, Acc = 80.87%, Spikes = 0.0899\n",
            "Epoch 14, Batch 1480: Loss = 0.5619, Acc = 80.87%, Spikes = 0.0909\n",
            "Epoch 14, Batch 1490: Loss = 0.7079, Acc = 80.85%, Spikes = 0.0921\n",
            "Epoch 14, Batch 1500: Loss = 0.8884, Acc = 80.84%, Spikes = 0.0886\n",
            "Epoch 14, Batch 1510: Loss = 0.5961, Acc = 80.83%, Spikes = 0.0935\n",
            "Epoch 14, Batch 1520: Loss = 0.6823, Acc = 80.85%, Spikes = 0.0920\n",
            "Epoch 14, Batch 1530: Loss = 0.6276, Acc = 80.85%, Spikes = 0.0928\n",
            "Epoch 14, Batch 1540: Loss = 0.7470, Acc = 80.85%, Spikes = 0.0879\n",
            "Epoch 14, Batch 1550: Loss = 0.9233, Acc = 80.85%, Spikes = 0.0941\n",
            "Epoch 14, Batch 1560: Loss = 0.3964, Acc = 80.83%, Spikes = 0.0931\n",
            "Epoch 14, Batch 1570: Loss = 0.4231, Acc = 80.84%, Spikes = 0.0908\n",
            "Epoch 14, Batch 1580: Loss = 0.5187, Acc = 80.86%, Spikes = 0.0921\n",
            "Epoch 14, Batch 1590: Loss = 0.3684, Acc = 80.87%, Spikes = 0.0949\n",
            "Epoch 14, Batch 1600: Loss = 0.4064, Acc = 80.88%, Spikes = 0.0908\n",
            "Epoch 14, Batch 1610: Loss = 0.4064, Acc = 80.92%, Spikes = 0.0949\n",
            "Epoch 14, Batch 1620: Loss = 0.6766, Acc = 80.90%, Spikes = 0.0930\n",
            "Epoch 14, Batch 1630: Loss = 0.6431, Acc = 80.91%, Spikes = 0.0921\n",
            "Epoch 14, Batch 1640: Loss = 0.2292, Acc = 80.93%, Spikes = 0.0985\n",
            "Epoch 14, Batch 1650: Loss = 0.4155, Acc = 80.93%, Spikes = 0.0897\n",
            "Epoch 14, Batch 1660: Loss = 0.7666, Acc = 80.91%, Spikes = 0.0905\n",
            "Epoch 14, Batch 1670: Loss = 0.5917, Acc = 80.91%, Spikes = 0.0905\n",
            "Epoch 14, Batch 1680: Loss = 0.5013, Acc = 80.93%, Spikes = 0.0985\n",
            "Epoch 14, Batch 1690: Loss = 0.7514, Acc = 80.92%, Spikes = 0.0930\n",
            "Epoch 14, Batch 1700: Loss = 0.4563, Acc = 80.92%, Spikes = 0.0920\n",
            "Epoch 14, Batch 1710: Loss = 0.4452, Acc = 80.92%, Spikes = 0.0948\n",
            "Epoch 14, Batch 1720: Loss = 0.5359, Acc = 80.91%, Spikes = 0.0880\n",
            "Epoch 14, Batch 1730: Loss = 0.7050, Acc = 80.91%, Spikes = 0.0913\n",
            "Epoch 14, Batch 1740: Loss = 0.3577, Acc = 80.91%, Spikes = 0.0919\n",
            "Epoch 14, Batch 1750: Loss = 0.4634, Acc = 80.92%, Spikes = 0.0947\n",
            "Epoch 14, Batch 1760: Loss = 0.5894, Acc = 80.93%, Spikes = 0.0905\n",
            "Epoch 14, Batch 1770: Loss = 0.5549, Acc = 80.93%, Spikes = 0.0947\n",
            "Epoch 14, Batch 1780: Loss = 0.3074, Acc = 80.94%, Spikes = 0.0869\n",
            "Epoch 14, Batch 1790: Loss = 0.7917, Acc = 80.91%, Spikes = 0.0879\n",
            "Epoch 14, Batch 1800: Loss = 0.4356, Acc = 80.92%, Spikes = 0.0902\n",
            "Epoch 14, Batch 1810: Loss = 0.4345, Acc = 80.93%, Spikes = 0.0957\n",
            "Epoch 14, Batch 1820: Loss = 0.6196, Acc = 80.94%, Spikes = 0.0900\n",
            "Epoch 14, Batch 1830: Loss = 0.4695, Acc = 80.94%, Spikes = 0.0892\n",
            "Epoch 14, Batch 1840: Loss = 0.3824, Acc = 80.95%, Spikes = 0.0923\n",
            "Epoch 14, Batch 1850: Loss = 0.7707, Acc = 80.95%, Spikes = 0.0940\n",
            "Epoch 14, Batch 1860: Loss = 0.5569, Acc = 80.94%, Spikes = 0.0944\n",
            "Epoch 14, Batch 1870: Loss = 0.4564, Acc = 80.93%, Spikes = 0.0875\n",
            "Epoch 14/15:\n",
            "Train Loss: 0.5951 | Train Acc: 80.92% | Train Spikes: 0.0944\n",
            "Test Acc: 81.60% | Test Spikes: 0.0921\n",
            "------------------------------------------------------------\n",
            "Epoch 15, Batch 0: Loss = 0.6022, Acc = 84.38%, Spikes = 0.0884\n",
            "Epoch 15, Batch 10: Loss = 0.6937, Acc = 78.98%, Spikes = 0.0911\n",
            "Epoch 15, Batch 20: Loss = 0.6679, Acc = 78.27%, Spikes = 0.0866\n",
            "Epoch 15, Batch 30: Loss = 0.7802, Acc = 79.03%, Spikes = 0.0899\n",
            "Epoch 15, Batch 40: Loss = 0.6614, Acc = 78.96%, Spikes = 0.0965\n",
            "Epoch 15, Batch 50: Loss = 0.6697, Acc = 79.47%, Spikes = 0.0871\n",
            "Epoch 15, Batch 60: Loss = 0.6007, Acc = 79.66%, Spikes = 0.0911\n",
            "Epoch 15, Batch 70: Loss = 0.5440, Acc = 79.84%, Spikes = 0.0937\n",
            "Epoch 15, Batch 80: Loss = 0.4249, Acc = 79.55%, Spikes = 0.0891\n",
            "Epoch 15, Batch 90: Loss = 0.6213, Acc = 79.88%, Spikes = 0.0931\n",
            "Epoch 15, Batch 100: Loss = 0.8015, Acc = 79.76%, Spikes = 0.0888\n",
            "Epoch 15, Batch 110: Loss = 0.7544, Acc = 79.70%, Spikes = 0.0896\n",
            "Epoch 15, Batch 120: Loss = 0.7668, Acc = 79.73%, Spikes = 0.0900\n",
            "Epoch 15, Batch 130: Loss = 0.5291, Acc = 79.84%, Spikes = 0.0929\n",
            "Epoch 15, Batch 140: Loss = 0.8021, Acc = 79.72%, Spikes = 0.0915\n",
            "Epoch 15, Batch 150: Loss = 0.5131, Acc = 79.90%, Spikes = 0.0866\n",
            "Epoch 15, Batch 160: Loss = 0.4606, Acc = 79.74%, Spikes = 0.0896\n",
            "Epoch 15, Batch 170: Loss = 0.6307, Acc = 79.53%, Spikes = 0.0914\n",
            "Epoch 15, Batch 180: Loss = 0.5826, Acc = 79.56%, Spikes = 0.0905\n",
            "Epoch 15, Batch 190: Loss = 0.6509, Acc = 79.55%, Spikes = 0.0978\n",
            "Epoch 15, Batch 200: Loss = 0.5082, Acc = 79.59%, Spikes = 0.0875\n",
            "Epoch 15, Batch 210: Loss = 0.7268, Acc = 79.71%, Spikes = 0.0992\n",
            "Epoch 15, Batch 220: Loss = 0.2894, Acc = 79.91%, Spikes = 0.0993\n",
            "Epoch 15, Batch 230: Loss = 0.7989, Acc = 79.76%, Spikes = 0.0853\n",
            "Epoch 15, Batch 240: Loss = 0.6574, Acc = 79.86%, Spikes = 0.0949\n",
            "Epoch 15, Batch 250: Loss = 0.5174, Acc = 80.02%, Spikes = 0.0909\n",
            "Epoch 15, Batch 260: Loss = 0.4459, Acc = 80.05%, Spikes = 0.0935\n",
            "Epoch 15, Batch 270: Loss = 0.7310, Acc = 79.91%, Spikes = 0.0957\n",
            "Epoch 15, Batch 280: Loss = 0.7975, Acc = 79.90%, Spikes = 0.0915\n",
            "Epoch 15, Batch 290: Loss = 0.3451, Acc = 80.05%, Spikes = 0.0925\n",
            "Epoch 15, Batch 300: Loss = 0.5064, Acc = 80.06%, Spikes = 0.0933\n",
            "Epoch 15, Batch 310: Loss = 0.8494, Acc = 80.02%, Spikes = 0.0996\n",
            "Epoch 15, Batch 320: Loss = 0.7571, Acc = 80.08%, Spikes = 0.0884\n",
            "Epoch 15, Batch 330: Loss = 0.6802, Acc = 80.12%, Spikes = 0.0929\n",
            "Epoch 15, Batch 340: Loss = 0.7914, Acc = 80.22%, Spikes = 0.0911\n",
            "Epoch 15, Batch 350: Loss = 0.4437, Acc = 80.24%, Spikes = 0.0925\n",
            "Epoch 15, Batch 360: Loss = 0.2767, Acc = 80.37%, Spikes = 0.0900\n",
            "Epoch 15, Batch 370: Loss = 0.6655, Acc = 80.39%, Spikes = 0.0839\n",
            "Epoch 15, Batch 380: Loss = 0.6665, Acc = 80.35%, Spikes = 0.0871\n",
            "Epoch 15, Batch 390: Loss = 0.8294, Acc = 80.33%, Spikes = 0.0884\n",
            "Epoch 15, Batch 400: Loss = 0.4107, Acc = 80.33%, Spikes = 0.0921\n",
            "Epoch 15, Batch 410: Loss = 0.4062, Acc = 80.42%, Spikes = 0.0906\n",
            "Epoch 15, Batch 420: Loss = 0.7400, Acc = 80.49%, Spikes = 0.0905\n",
            "Epoch 15, Batch 430: Loss = 0.7657, Acc = 80.46%, Spikes = 0.0873\n",
            "Epoch 15, Batch 440: Loss = 0.4102, Acc = 80.51%, Spikes = 0.0909\n",
            "Epoch 15, Batch 450: Loss = 0.4185, Acc = 80.49%, Spikes = 0.0916\n",
            "Epoch 15, Batch 460: Loss = 0.5659, Acc = 80.48%, Spikes = 0.0949\n",
            "Epoch 15, Batch 470: Loss = 0.5130, Acc = 80.47%, Spikes = 0.0947\n",
            "Epoch 15, Batch 480: Loss = 0.3891, Acc = 80.52%, Spikes = 0.0953\n",
            "Epoch 15, Batch 490: Loss = 0.5485, Acc = 80.54%, Spikes = 0.0872\n",
            "Epoch 15, Batch 500: Loss = 0.5137, Acc = 80.63%, Spikes = 0.0873\n",
            "Epoch 15, Batch 510: Loss = 0.3212, Acc = 80.64%, Spikes = 0.0919\n",
            "Epoch 15, Batch 520: Loss = 0.3866, Acc = 80.67%, Spikes = 0.0925\n",
            "Epoch 15, Batch 530: Loss = 0.7467, Acc = 80.65%, Spikes = 0.0955\n",
            "Epoch 15, Batch 540: Loss = 0.3728, Acc = 80.67%, Spikes = 0.0922\n",
            "Epoch 15, Batch 550: Loss = 0.5695, Acc = 80.69%, Spikes = 0.0904\n",
            "Epoch 15, Batch 560: Loss = 0.4379, Acc = 80.73%, Spikes = 0.0919\n",
            "Epoch 15, Batch 570: Loss = 0.9799, Acc = 80.70%, Spikes = 0.0881\n",
            "Epoch 15, Batch 580: Loss = 0.8251, Acc = 80.70%, Spikes = 0.0946\n",
            "Epoch 15, Batch 590: Loss = 0.8873, Acc = 80.67%, Spikes = 0.0875\n",
            "Epoch 15, Batch 600: Loss = 0.5834, Acc = 80.65%, Spikes = 0.0873\n",
            "Epoch 15, Batch 610: Loss = 0.5982, Acc = 80.61%, Spikes = 0.0878\n",
            "Epoch 15, Batch 620: Loss = 0.5561, Acc = 80.66%, Spikes = 0.0886\n",
            "Epoch 15, Batch 630: Loss = 0.5655, Acc = 80.68%, Spikes = 0.0874\n",
            "Epoch 15, Batch 640: Loss = 0.6874, Acc = 80.65%, Spikes = 0.0915\n",
            "Epoch 15, Batch 650: Loss = 0.5587, Acc = 80.61%, Spikes = 0.0982\n",
            "Epoch 15, Batch 660: Loss = 0.7410, Acc = 80.61%, Spikes = 0.0955\n",
            "Epoch 15, Batch 670: Loss = 0.5707, Acc = 80.58%, Spikes = 0.1005\n",
            "Epoch 15, Batch 680: Loss = 0.5995, Acc = 80.64%, Spikes = 0.0929\n",
            "Epoch 15, Batch 690: Loss = 0.8447, Acc = 80.61%, Spikes = 0.0901\n",
            "Epoch 15, Batch 700: Loss = 0.3983, Acc = 80.63%, Spikes = 0.0862\n",
            "Epoch 15, Batch 710: Loss = 0.6416, Acc = 80.60%, Spikes = 0.0856\n",
            "Epoch 15, Batch 720: Loss = 0.5664, Acc = 80.63%, Spikes = 0.0859\n",
            "Epoch 15, Batch 730: Loss = 0.5364, Acc = 80.65%, Spikes = 0.0917\n",
            "Epoch 15, Batch 740: Loss = 0.3792, Acc = 80.68%, Spikes = 0.0934\n",
            "Epoch 15, Batch 750: Loss = 0.5759, Acc = 80.73%, Spikes = 0.0852\n",
            "Epoch 15, Batch 760: Loss = 0.4411, Acc = 80.73%, Spikes = 0.0939\n",
            "Epoch 15, Batch 770: Loss = 0.6198, Acc = 80.74%, Spikes = 0.0897\n",
            "Epoch 15, Batch 780: Loss = 0.2070, Acc = 80.72%, Spikes = 0.0988\n",
            "Epoch 15, Batch 790: Loss = 0.5584, Acc = 80.67%, Spikes = 0.0932\n",
            "Epoch 15, Batch 800: Loss = 0.6238, Acc = 80.69%, Spikes = 0.0934\n",
            "Epoch 15, Batch 810: Loss = 0.5262, Acc = 80.72%, Spikes = 0.0926\n",
            "Epoch 15, Batch 820: Loss = 0.7850, Acc = 80.72%, Spikes = 0.0934\n",
            "Epoch 15, Batch 830: Loss = 0.3697, Acc = 80.71%, Spikes = 0.0932\n",
            "Epoch 15, Batch 840: Loss = 0.5330, Acc = 80.71%, Spikes = 0.0933\n",
            "Epoch 15, Batch 850: Loss = 0.8186, Acc = 80.72%, Spikes = 0.0911\n",
            "Epoch 15, Batch 860: Loss = 0.5179, Acc = 80.70%, Spikes = 0.0936\n",
            "Epoch 15, Batch 870: Loss = 0.5812, Acc = 80.68%, Spikes = 0.0906\n",
            "Epoch 15, Batch 880: Loss = 0.7168, Acc = 80.68%, Spikes = 0.0863\n",
            "Epoch 15, Batch 890: Loss = 0.6720, Acc = 80.67%, Spikes = 0.0937\n",
            "Epoch 15, Batch 900: Loss = 0.5025, Acc = 80.72%, Spikes = 0.0875\n",
            "Epoch 15, Batch 910: Loss = 0.5963, Acc = 80.74%, Spikes = 0.0968\n",
            "Epoch 15, Batch 920: Loss = 0.6319, Acc = 80.72%, Spikes = 0.0938\n",
            "Epoch 15, Batch 930: Loss = 0.3891, Acc = 80.74%, Spikes = 0.0871\n",
            "Epoch 15, Batch 940: Loss = 1.3054, Acc = 80.67%, Spikes = 0.0817\n",
            "Epoch 15, Batch 950: Loss = 0.4605, Acc = 80.67%, Spikes = 0.0968\n",
            "Epoch 15, Batch 960: Loss = 0.5829, Acc = 80.67%, Spikes = 0.0890\n",
            "Epoch 15, Batch 970: Loss = 0.9237, Acc = 80.69%, Spikes = 0.0906\n",
            "Epoch 15, Batch 980: Loss = 0.5123, Acc = 80.69%, Spikes = 0.0918\n",
            "Epoch 15, Batch 990: Loss = 0.4491, Acc = 80.69%, Spikes = 0.0923\n",
            "Epoch 15, Batch 1000: Loss = 0.7065, Acc = 80.70%, Spikes = 0.0924\n",
            "Epoch 15, Batch 1010: Loss = 0.5591, Acc = 80.68%, Spikes = 0.0929\n",
            "Epoch 15, Batch 1020: Loss = 0.6429, Acc = 80.69%, Spikes = 0.0890\n",
            "Epoch 15, Batch 1030: Loss = 0.9326, Acc = 80.68%, Spikes = 0.0933\n",
            "Epoch 15, Batch 1040: Loss = 0.6709, Acc = 80.65%, Spikes = 0.0909\n",
            "Epoch 15, Batch 1050: Loss = 0.8210, Acc = 80.63%, Spikes = 0.0885\n",
            "Epoch 15, Batch 1060: Loss = 0.3989, Acc = 80.65%, Spikes = 0.1002\n",
            "Epoch 15, Batch 1070: Loss = 0.4411, Acc = 80.68%, Spikes = 0.0959\n",
            "Epoch 15, Batch 1080: Loss = 0.4753, Acc = 80.70%, Spikes = 0.0913\n",
            "Epoch 15, Batch 1090: Loss = 0.5614, Acc = 80.68%, Spikes = 0.0941\n",
            "Epoch 15, Batch 1100: Loss = 0.5184, Acc = 80.69%, Spikes = 0.0885\n",
            "Epoch 15, Batch 1110: Loss = 0.5941, Acc = 80.68%, Spikes = 0.0932\n",
            "Epoch 15, Batch 1120: Loss = 0.3798, Acc = 80.71%, Spikes = 0.0956\n",
            "Epoch 15, Batch 1130: Loss = 0.4410, Acc = 80.73%, Spikes = 0.0892\n",
            "Epoch 15, Batch 1140: Loss = 0.4824, Acc = 80.76%, Spikes = 0.0949\n",
            "Epoch 15, Batch 1150: Loss = 0.7323, Acc = 80.76%, Spikes = 0.0918\n",
            "Epoch 15, Batch 1160: Loss = 0.3268, Acc = 80.80%, Spikes = 0.0957\n",
            "Epoch 15, Batch 1170: Loss = 0.8301, Acc = 80.79%, Spikes = 0.0910\n",
            "Epoch 15, Batch 1180: Loss = 0.4604, Acc = 80.78%, Spikes = 0.0909\n",
            "Epoch 15, Batch 1190: Loss = 0.3690, Acc = 80.77%, Spikes = 0.0845\n",
            "Epoch 15, Batch 1200: Loss = 0.6713, Acc = 80.76%, Spikes = 0.0924\n",
            "Epoch 15, Batch 1210: Loss = 0.6509, Acc = 80.76%, Spikes = 0.0906\n",
            "Epoch 15, Batch 1220: Loss = 0.5347, Acc = 80.77%, Spikes = 0.0948\n",
            "Epoch 15, Batch 1230: Loss = 0.7790, Acc = 80.79%, Spikes = 0.0863\n",
            "Epoch 15, Batch 1240: Loss = 0.4704, Acc = 80.79%, Spikes = 0.0941\n",
            "Epoch 15, Batch 1250: Loss = 0.4666, Acc = 80.79%, Spikes = 0.0924\n",
            "Epoch 15, Batch 1260: Loss = 0.6831, Acc = 80.80%, Spikes = 0.0944\n",
            "Epoch 15, Batch 1270: Loss = 0.9160, Acc = 80.82%, Spikes = 0.0885\n",
            "Epoch 15, Batch 1280: Loss = 0.4846, Acc = 80.78%, Spikes = 0.0905\n",
            "Epoch 15, Batch 1290: Loss = 0.8110, Acc = 80.78%, Spikes = 0.0921\n",
            "Epoch 15, Batch 1300: Loss = 0.5951, Acc = 80.77%, Spikes = 0.0881\n",
            "Epoch 15, Batch 1310: Loss = 0.7780, Acc = 80.75%, Spikes = 0.0873\n",
            "Epoch 15, Batch 1320: Loss = 0.5345, Acc = 80.75%, Spikes = 0.0885\n",
            "Epoch 15, Batch 1330: Loss = 1.1002, Acc = 80.74%, Spikes = 0.0900\n",
            "Epoch 15, Batch 1340: Loss = 0.7259, Acc = 80.77%, Spikes = 0.0872\n",
            "Epoch 15, Batch 1350: Loss = 0.4292, Acc = 80.78%, Spikes = 0.0960\n",
            "Epoch 15, Batch 1360: Loss = 0.4691, Acc = 80.80%, Spikes = 0.0942\n",
            "Epoch 15, Batch 1370: Loss = 0.4149, Acc = 80.80%, Spikes = 0.0916\n",
            "Epoch 15, Batch 1380: Loss = 0.5838, Acc = 80.79%, Spikes = 0.0894\n",
            "Epoch 15, Batch 1390: Loss = 0.4637, Acc = 80.80%, Spikes = 0.0847\n",
            "Epoch 15, Batch 1400: Loss = 0.4556, Acc = 80.79%, Spikes = 0.0895\n",
            "Epoch 15, Batch 1410: Loss = 0.7673, Acc = 80.80%, Spikes = 0.0864\n",
            "Epoch 15, Batch 1420: Loss = 0.6829, Acc = 80.82%, Spikes = 0.0894\n",
            "Epoch 15, Batch 1430: Loss = 0.4002, Acc = 80.83%, Spikes = 0.0845\n",
            "Epoch 15, Batch 1440: Loss = 0.4812, Acc = 80.84%, Spikes = 0.0904\n",
            "Epoch 15, Batch 1450: Loss = 0.7514, Acc = 80.82%, Spikes = 0.0896\n",
            "Epoch 15, Batch 1460: Loss = 0.4358, Acc = 80.83%, Spikes = 0.0879\n",
            "Epoch 15, Batch 1470: Loss = 0.4951, Acc = 80.84%, Spikes = 0.0912\n",
            "Epoch 15, Batch 1480: Loss = 0.5406, Acc = 80.84%, Spikes = 0.0898\n",
            "Epoch 15, Batch 1490: Loss = 0.4794, Acc = 80.84%, Spikes = 0.0875\n",
            "Epoch 15, Batch 1500: Loss = 0.6907, Acc = 80.85%, Spikes = 0.0834\n",
            "Epoch 15, Batch 1510: Loss = 0.8019, Acc = 80.83%, Spikes = 0.0925\n",
            "Epoch 15, Batch 1520: Loss = 0.5616, Acc = 80.81%, Spikes = 0.0908\n",
            "Epoch 15, Batch 1530: Loss = 0.6376, Acc = 80.82%, Spikes = 0.0870\n",
            "Epoch 15, Batch 1540: Loss = 0.8963, Acc = 80.83%, Spikes = 0.0818\n",
            "Epoch 15, Batch 1550: Loss = 0.5258, Acc = 80.84%, Spikes = 0.0833\n",
            "Epoch 15, Batch 1560: Loss = 0.6190, Acc = 80.87%, Spikes = 0.0879\n",
            "Epoch 15, Batch 1570: Loss = 0.4179, Acc = 80.86%, Spikes = 0.0857\n",
            "Epoch 15, Batch 1580: Loss = 0.4903, Acc = 80.88%, Spikes = 0.0869\n",
            "Epoch 15, Batch 1590: Loss = 0.9083, Acc = 80.89%, Spikes = 0.0875\n",
            "Epoch 15, Batch 1600: Loss = 0.9370, Acc = 80.89%, Spikes = 0.0855\n",
            "Epoch 15, Batch 1610: Loss = 0.7481, Acc = 80.90%, Spikes = 0.0925\n",
            "Epoch 15, Batch 1620: Loss = 0.4163, Acc = 80.92%, Spikes = 0.0866\n",
            "Epoch 15, Batch 1630: Loss = 0.4013, Acc = 80.93%, Spikes = 0.0980\n",
            "Epoch 15, Batch 1640: Loss = 0.6012, Acc = 80.92%, Spikes = 0.0925\n",
            "Epoch 15, Batch 1650: Loss = 0.5976, Acc = 80.92%, Spikes = 0.0846\n",
            "Epoch 15, Batch 1660: Loss = 0.6830, Acc = 80.92%, Spikes = 0.0835\n",
            "Epoch 15, Batch 1670: Loss = 0.4151, Acc = 80.91%, Spikes = 0.0848\n",
            "Epoch 15, Batch 1680: Loss = 0.7147, Acc = 80.91%, Spikes = 0.0909\n",
            "Epoch 15, Batch 1690: Loss = 0.6104, Acc = 80.92%, Spikes = 0.0857\n",
            "Epoch 15, Batch 1700: Loss = 0.7961, Acc = 80.90%, Spikes = 0.0918\n",
            "Epoch 15, Batch 1710: Loss = 0.8187, Acc = 80.88%, Spikes = 0.0866\n",
            "Epoch 15, Batch 1720: Loss = 0.4785, Acc = 80.87%, Spikes = 0.0838\n",
            "Epoch 15, Batch 1730: Loss = 0.3347, Acc = 80.87%, Spikes = 0.0915\n",
            "Epoch 15, Batch 1740: Loss = 0.2891, Acc = 80.87%, Spikes = 0.0883\n",
            "Epoch 15, Batch 1750: Loss = 0.7515, Acc = 80.88%, Spikes = 0.0870\n",
            "Epoch 15, Batch 1760: Loss = 0.5121, Acc = 80.86%, Spikes = 0.0910\n",
            "Epoch 15, Batch 1770: Loss = 0.2697, Acc = 80.86%, Spikes = 0.0988\n",
            "Epoch 15, Batch 1780: Loss = 0.4673, Acc = 80.88%, Spikes = 0.0895\n",
            "Epoch 15, Batch 1790: Loss = 0.4936, Acc = 80.90%, Spikes = 0.0908\n",
            "Epoch 15, Batch 1800: Loss = 1.0621, Acc = 80.91%, Spikes = 0.0926\n",
            "Epoch 15, Batch 1810: Loss = 0.7656, Acc = 80.91%, Spikes = 0.0882\n",
            "Epoch 15, Batch 1820: Loss = 0.9450, Acc = 80.91%, Spikes = 0.0848\n",
            "Epoch 15, Batch 1830: Loss = 0.3697, Acc = 80.91%, Spikes = 0.0857\n",
            "Epoch 15, Batch 1840: Loss = 0.5123, Acc = 80.93%, Spikes = 0.0917\n",
            "Epoch 15, Batch 1850: Loss = 0.9451, Acc = 80.92%, Spikes = 0.0899\n",
            "Epoch 15, Batch 1860: Loss = 0.4483, Acc = 80.92%, Spikes = 0.0852\n",
            "Epoch 15, Batch 1870: Loss = 0.5685, Acc = 80.92%, Spikes = 0.0862\n",
            "Epoch 15/15:\n",
            "Train Loss: 0.5988 | Train Acc: 80.92% | Train Spikes: 0.0907\n",
            "Test Acc: 81.40% | Test Spikes: 0.0885\n",
            "------------------------------------------------------------\n",
            "\n",
            "Training completed in 870.06 seconds\n",
            "Final train accuracy: 80.92%\n",
            "Final test accuracy: 81.40%\n",
            "Average spikes per neuron: 0.0885\n",
            "Best accuracy: 81.70%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to snn_model.pth\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}